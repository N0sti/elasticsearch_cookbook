{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD SIEM : Suricata, Filebeat, Elasticsearch et Kibana\n",
    "\n",
    "## Objectifs du TD\n",
    "\n",
    "Ce TD vous permettra de :\n",
    "- Configurer Suricata (syst√®me de d√©tection d'intrusion)\n",
    "- Utiliser Filebeat pour collecter et envoyer les logs vers Elasticsearch\n",
    "- Explorer et analyser les donn√©es dans Elasticsearch\n",
    "- Cr√©er des visualisations dans Kibana\n",
    "- Configurer des alertes pour la d√©tection de menaces\n",
    "- Utiliser la d√©tection d'anomalies avec Machine Learning\n",
    "\n",
    "## Architecture SIEM\n",
    "\n",
    "```\n",
    "Suricata ‚Üí Filebeat ‚Üí Elasticsearch ‚Üí Kibana\n",
    "   (IDS)    (Collecteur)   (Stockage)   (Visualisation/Alerting)\n",
    "```\n",
    "\n",
    "## Pr√©requis\n",
    "\n",
    "### 1. Installation des d√©pendances\n",
    "\n",
    "Assurez-vous d'avoir install√© les d√©pendances du projet :\n",
    "```bash\n",
    "uv sync\n",
    "```\n",
    "\n",
    "### 2. D√©marrage de la stack compl√®te SIEM\n",
    "\n",
    "Le fichier `docker-compose-siem.yml` inclut toute la stack n√©cessaire pour ce TD :\n",
    "- Cluster Elasticsearch (3 n≈ìuds)\n",
    "- Kibana\n",
    "- Suricata (IDS/IPS)\n",
    "- Filebeat (collecteur de logs)\n",
    "\n",
    "**D√©marrage de la stack compl√®te :**\n",
    "```bash\n",
    "docker-compose -f docker-compose-siem.yml up -d\n",
    "```\n",
    "\n",
    "**V√©rification :**\n",
    "- Elasticsearch : `https://localhost:9200` (ou le port configur√© dans `.env`)\n",
    "- Kibana : `http://localhost:5601` (ou le port configur√© dans `.env`)\n",
    "\n",
    "**Note :** Si vous utilisez un cluster avec s√©curit√© activ√©e, vous devrez utiliser les identifiants d√©finis dans le fichier `.env` (ELASTIC_PASSWORD).\n",
    "\n",
    "### 3. Pr√©paration des r√©pertoires\n",
    "\n",
    "Avant de d√©marrer la stack, cr√©ez les r√©pertoires n√©cessaires pour Suricata :\n",
    "\n",
    "```bash\n",
    "mkdir -p suricata/{logs,config,rules}\n",
    "mkdir -p suricata_logs\n",
    "```\n",
    "\n",
    "**Note :** Tous les services (Elasticsearch, Kibana, Suricata, Filebeat) sont d√©j√† configur√©s dans le fichier `docker-compose.yml` et seront d√©marr√©s ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. V√©rification de la stack\n",
    "\n",
    "La cellule suivante v√©rifie que tous les services sont correctement d√©marr√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:39.271628Z",
     "iopub.status.busy": "2026-01-17T14:32:39.271292Z",
     "iopub.status.idle": "2026-01-17T14:32:39.788237Z",
     "shell.execute_reply": "2026-01-17T14:32:39.786629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Docker est install√©\n",
      "‚úÖ Docker Compose est disponible\n",
      "\n",
      "üì¶ Statut des services:\n",
      "   ‚úÖ es01: en cours d'ex√©cution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úÖ es02: en cours d'ex√©cution\n",
      "   ‚úÖ es03: en cours d'ex√©cution\n",
      "   ‚úÖ kibana: en cours d'ex√©cution\n",
      "   ‚úÖ suricata: en cours d'ex√©cution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚ö†Ô∏è  filebeat: arr√™t√©\n",
      "\n",
      "üìù Pour d√©marrer la stack compl√®te:\n",
      "   docker-compose up -d\n",
      "\n",
      "üìù Pour arr√™ter:\n",
      "   docker-compose down\n"
     ]
    }
   ],
   "source": [
    "# V√©rification de la stack Docker\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def check_docker_container(container_name):\n",
    "    \"\"\"V√©rifie si un conteneur Docker est en cours d'ex√©cution\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['docker', 'ps', '--filter', f'name={container_name}', '--format', '{{.Names}}'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        return container_name in result.stdout\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def check_docker_compose():\n",
    "    \"\"\"V√©rifie si docker-compose est disponible\"\"\"\n",
    "    try:\n",
    "        subprocess.run(['docker', 'compose', 'version'], capture_output=True, check=True, timeout=5)\n",
    "        return True\n",
    "    except:\n",
    "        try:\n",
    "            subprocess.run(['docker-compose', 'version'], capture_output=True, check=True, timeout=5)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "# V√©rifier Docker\n",
    "try:\n",
    "    subprocess.run(['docker', '--version'], capture_output=True, check=True, timeout=5)\n",
    "    print(\"‚úÖ Docker est install√©\")\n",
    "except (FileNotFoundError, subprocess.CalledProcessError):\n",
    "    print(\"‚ùå Docker n'est pas install√©\")\n",
    "    print(\"   Installez Docker: https://docs.docker.com/get-docker/\")\n",
    "    exit(1)\n",
    "\n",
    "# V√©rifier docker-compose\n",
    "if check_docker_compose():\n",
    "    print(\"‚úÖ Docker Compose est disponible\")\n",
    "else:\n",
    "    print(\"‚ùå Docker Compose n'est pas disponible\")\n",
    "\n",
    "# V√©rifier les conteneurs\n",
    "services = ['es01', 'es02', 'es03', 'kibana', 'suricata', 'filebeat']\n",
    "print(\"\\nüì¶ Statut des services:\")\n",
    "for service in services:\n",
    "    if check_docker_container(service):\n",
    "        print(f\"   ‚úÖ {service}: en cours d'ex√©cution\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  {service}: arr√™t√©\")\n",
    "\n",
    "print(\"\\nüìù Pour d√©marrer la stack compl√®te:\")\n",
    "print(\"   docker-compose up -d\")\n",
    "print(\"\\nüìù Pour arr√™ter:\")\n",
    "print(\"   docker-compose down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:39.791483Z",
     "iopub.status.busy": "2026-01-17T14:32:39.791149Z",
     "iopub.status.idle": "2026-01-17T14:32:40.092396Z",
     "shell.execute_reply": "2026-01-17T14:32:40.089342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Connexion √©tablie avec Elasticsearch\n",
      "   Statut du cluster: green\n",
      "   Nombre de n≈ìuds: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/elasticsearch/_sync/client/__init__.py:313: SecurityWarning: Connecting to 'https://localhost:9200' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n",
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import des librairies n√©cessaires\n",
    "from elasticsearch import Elasticsearch\n",
    "from pprint import pprint\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration de la connexion Elasticsearch\n",
    "# Adaptez selon votre configuration (avec ou sans s√©curit√©)\n",
    "ES_HOST = \"https://localhost:9200\"\n",
    "ES_USER = \"elastic\"  # Modifiez si n√©cessaire\n",
    "ES_PASSWORD = \"changeme\"  # D√©finissez votre mot de passe si s√©curit√© activ√©e\n",
    "\n",
    "# Connexion au cluster Elasticsearch\n",
    "if ES_PASSWORD:\n",
    "    es = Elasticsearch(\n",
    "        [ES_HOST],\n",
    "        basic_auth=(ES_USER, ES_PASSWORD),\n",
    "        verify_certs=False  # D√©sactiver la v√©rification SSL pour le d√©veloppement\n",
    "    )\n",
    "else:\n",
    "    # Pour un cluster sans s√©curit√© (d√©veloppement uniquement)\n",
    "    es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "# V√©rification de la connexion\n",
    "try:\n",
    "    health = es.cluster.health()\n",
    "    print(\"‚úÖ Connexion √©tablie avec Elasticsearch\")\n",
    "    print(f\"   Statut du cluster: {health['status']}\")\n",
    "    print(f\"   Nombre de n≈ìuds: {health['number_of_nodes']}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur de connexion: {e}\")\n",
    "    print(\"   V√©rifiez que votre cluster Elasticsearch est d√©marr√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Configuration de Suricata\n",
    "\n",
    "### 1.1 V√©rification de l'installation de Suricata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:40.096986Z",
     "iopub.status.busy": "2026-01-17T14:32:40.096678Z",
     "iopub.status.idle": "2026-01-17T14:32:40.104468Z",
     "shell.execute_reply": "2026-01-17T14:32:40.102751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ R√©pertoire cr√©√©/v√©rifi√©: ./suricata/logs\n",
      "‚úÖ R√©pertoire cr√©√©/v√©rifi√©: ./suricata/config\n",
      "‚úÖ R√©pertoire cr√©√©/v√©rifi√©: ./suricata/rules\n",
      "‚úÖ R√©pertoire cr√©√©/v√©rifi√©: ./suricata_logs\n",
      "\n",
      "üìù Les r√©pertoires sont pr√™ts pour Suricata\n"
     ]
    }
   ],
   "source": [
    "# Cr√©ation des r√©pertoires n√©cessaires pour Suricata\n",
    "import os\n",
    "\n",
    "# Cr√©er les r√©pertoires si n√©cessaire\n",
    "directories = [\n",
    "    './suricata/logs',\n",
    "    './suricata/config',\n",
    "    './suricata/rules',\n",
    "    './suricata_logs'\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"‚úÖ R√©pertoire cr√©√©/v√©rifi√©: {directory}\")\n",
    "\n",
    "print(\"\\nüìù Les r√©pertoires sont pr√™ts pour Suricata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Configuration de Suricata pour g√©n√©rer des logs JSON\n",
    "\n",
    "Suricata g√©n√®re des logs dans diff√©rents formats. Pour ce TD, nous allons configurer Suricata pour g√©n√©rer des logs au format JSON (EVE logs) qui sont plus faciles √† parser.\n",
    "\n",
    "**Avec Docker :** La configuration se trouve dans `./suricata/config/suricata.yaml` (mont√© dans le conteneur)\n",
    "\n",
    "**Fichier de configuration :** `./suricata/config/suricata.yaml` (dans le r√©pertoire du projet)\n",
    "\n",
    "**Configuration recommand√©e :**\n",
    "```yaml\n",
    "# Activer les logs EVE (JSON)\n",
    "- eve-log:\n",
    "    enabled: yes\n",
    "    filetype: regular\n",
    "    filename: eve.json\n",
    "    types:\n",
    "      - alert\n",
    "      - http\n",
    "      - dns\n",
    "      - tls\n",
    "      - files\n",
    "      - ssh\n",
    "      - stats\n",
    "      - flow\n",
    "      - netflow\n",
    "    # Format JSON pour faciliter le parsing\n",
    "    json: yes\n",
    "```\n",
    "\n",
    "**Note :** \n",
    "- Pour ce TD, nous allons cr√©er des logs de test qui seront utilis√©s m√™me si Suricata Docker n'est pas configur√©\n",
    "- Les logs seront g√©n√©r√©s dans `./suricata/logs/eve.json` (mont√© dans le conteneur)\n",
    "- Pour une utilisation r√©elle, vous devrez configurer l'interface r√©seau dans `suricata.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:40.110851Z",
     "iopub.status.busy": "2026-01-17T14:32:40.109883Z",
     "iopub.status.idle": "2026-01-17T14:32:40.132538Z",
     "shell.execute_reply": "2026-01-17T14:32:40.130591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Utilisation du r√©pertoire alternatif: ./suricata_logs_local\n",
      "‚úÖ Logs de test cr√©√©s dans ./suricata_logs_local/eve.json\n",
      "   Nombre de logs: 5\n"
     ]
    }
   ],
   "source": [
    "# Cr√©ation de logs Suricata de test (format EVE JSON)\n",
    "# Ces logs simulent des alertes Suricata typiques\n",
    "\n",
    "import os\n",
    "import builtins\n",
    "\n",
    "# Cr√©er un r√©pertoire pour les logs si n√©cessaire (utiliser un r√©pertoire accessible)\n",
    "log_dir = \"./suricata_logs\"\n",
    "try:\n",
    "    os.makedirs(log_dir, exist_ok=True, mode=0o755)\n",
    "    # Essayer de cr√©er un fichier test pour v√©rifier les permissions\n",
    "    test_file = os.path.join(log_dir, \".test_write\")\n",
    "    with builtins.open(test_file, 'w') as f:\n",
    "        f.write(\"test\")\n",
    "    os.remove(test_file)\n",
    "except (PermissionError, OSError) as e:\n",
    "    # Si on ne peut pas √©crire dans suricata_logs, utiliser un autre r√©pertoire\n",
    "    log_dir = \"./suricata_logs_local\"\n",
    "    os.makedirs(log_dir, exist_ok=True, mode=0o755)\n",
    "    print(f\"‚ö†Ô∏è  Utilisation du r√©pertoire alternatif: {log_dir}\")\n",
    "\n",
    "# Exemple de logs Suricata au format EVE JSON\n",
    "sample_logs = [\n",
    "    {\n",
    "        \"timestamp\": datetime.now().isoformat(),\n",
    "        \"event_type\": \"alert\",\n",
    "        \"src_ip\": \"192.168.1.100\",\n",
    "        \"src_port\": 54321,\n",
    "        \"dest_ip\": \"10.0.0.50\",\n",
    "        \"dest_port\": 80,\n",
    "        \"proto\": \"TCP\",\n",
    "        \"alert\": {\n",
    "            \"action\": \"allowed\",\n",
    "            \"gid\": 1,\n",
    "            \"signature_id\": 2012896,\n",
    "            \"rev\": 1,\n",
    "            \"signature\": \"ET POLICY Suspicious inbound to mySQL port 3306\",\n",
    "            \"category\": \"Potentially Bad Traffic\",\n",
    "            \"severity\": 2\n",
    "        },\n",
    "        \"flow_id\": 1234567890,\n",
    "        \"in_iface\": \"eth0\"\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": (datetime.now() - timedelta(minutes=5)).isoformat(),\n",
    "        \"event_type\": \"alert\",\n",
    "        \"src_ip\": \"203.0.113.45\",\n",
    "        \"src_port\": 44321,\n",
    "        \"dest_ip\": \"10.0.0.50\",\n",
    "        \"dest_port\": 22,\n",
    "        \"proto\": \"TCP\",\n",
    "        \"alert\": {\n",
    "            \"action\": \"allowed\",\n",
    "            \"gid\": 1,\n",
    "            \"signature_id\": 2012897,\n",
    "            \"rev\": 1,\n",
    "            \"signature\": \"ET SCAN Potential SSH Scan\",\n",
    "            \"category\": \"Attempted Information Leak\",\n",
    "            \"severity\": 2\n",
    "        },\n",
    "        \"flow_id\": 1234567891,\n",
    "        \"in_iface\": \"eth0\"\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": (datetime.now() - timedelta(minutes=10)).isoformat(),\n",
    "        \"event_type\": \"http\",\n",
    "        \"src_ip\": \"192.168.1.100\",\n",
    "        \"src_port\": 54322,\n",
    "        \"dest_ip\": \"10.0.0.50\",\n",
    "        \"dest_port\": 80,\n",
    "        \"proto\": \"TCP\",\n",
    "        \"http\": {\n",
    "            \"hostname\": \"example.com\",\n",
    "            \"url\": \"/admin/login.php\",\n",
    "            \"http_user_agent\": \"Mozilla/5.0\",\n",
    "            \"http_method\": \"POST\",\n",
    "            \"status\": 200\n",
    "        },\n",
    "        \"flow_id\": 1234567892\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": (datetime.now() - timedelta(minutes=15)).isoformat(),\n",
    "        \"event_type\": \"dns\",\n",
    "        \"src_ip\": \"192.168.1.100\",\n",
    "        \"src_port\": 54323,\n",
    "        \"dest_ip\": \"8.8.8.8\",\n",
    "        \"dest_port\": 53,\n",
    "        \"proto\": \"UDP\",\n",
    "        \"dns\": {\n",
    "            \"type\": \"query\",\n",
    "            \"id\": 12345,\n",
    "            \"rrname\": \"malicious-domain.com\",\n",
    "            \"rrtype\": \"A\"\n",
    "        },\n",
    "        \"flow_id\": 1234567893\n",
    "    },\n",
    "    {\n",
    "        \"timestamp\": (datetime.now() - timedelta(minutes=20)).isoformat(),\n",
    "        \"event_type\": \"alert\",\n",
    "        \"src_ip\": \"198.51.100.10\",\n",
    "        \"src_port\": 44324,\n",
    "        \"dest_ip\": \"10.0.0.50\",\n",
    "        \"dest_port\": 443,\n",
    "        \"proto\": \"TCP\",\n",
    "        \"alert\": {\n",
    "            \"action\": \"allowed\",\n",
    "            \"gid\": 1,\n",
    "            \"signature_id\": 2012898,\n",
    "            \"rev\": 1,\n",
    "            \"signature\": \"ET MALWARE Known Malware IP\",\n",
    "            \"category\": \"A Network Trojan was detected\",\n",
    "            \"severity\": 1\n",
    "        },\n",
    "        \"flow_id\": 1234567894,\n",
    "        \"in_iface\": \"eth0\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# √âcrire les logs dans un fichier (utiliser builtins.open pour √©viter le probl√®me IPython)\n",
    "log_file = os.path.join(log_dir, \"eve.json\")\n",
    "with builtins.open(log_file, 'w') as f:\n",
    "    for log in sample_logs:\n",
    "        f.write(json.dumps(log) + '\\n')\n",
    "\n",
    "print(f\"‚úÖ Logs de test cr√©√©s dans {log_file}\")\n",
    "print(f\"   Nombre de logs: {len(sample_logs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:40.138040Z",
     "iopub.status.busy": "2026-01-17T14:32:40.137710Z",
     "iopub.status.idle": "2026-01-17T14:32:40.143108Z",
     "shell.execute_reply": "2026-01-17T14:32:40.141150Z"
    }
   },
   "outputs": [],
   "source": [
    "# Note: Les permissions ont √©t√© g√©r√©es dans la cellule pr√©c√©dente\n",
    "# Si vous avez besoin de modifier les permissions, utilisez:\n",
    "# chmod -R 755 ./suricata_logs/\n",
    "# (sans sudo si vous √™tes propri√©taire du r√©pertoire)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:40.147570Z",
     "iopub.status.busy": "2026-01-17T14:32:40.147269Z",
     "iopub.status.idle": "2026-01-17T14:32:40.246561Z",
     "shell.execute_reply": "2026-01-17T14:32:40.244764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è  Suppression du r√©pertoire filebeat_suricata.yml (sera remplac√© par un fichier)\n",
      "‚úÖ Configuration Filebeat cr√©√©e: filebeat_suricata.yml\n",
      "\n",
      "üìù Note: Cette configuration sera utilis√©e automatiquement par le service Filebeat\n",
      "   dans docker-compose.yml. Le mot de passe sera inject√© via la variable\n",
      "   d'environnement ELASTICSEARCH_PASSWORD.\n"
     ]
    }
   ],
   "source": [
    "# Cr√©ation de la configuration Filebeat pour Suricata\n",
    "# Cette configuration utilise HTTPS et l'authentification pour se connecter √† Elasticsearch\n",
    "filebeat_config = {\n",
    "    \"filebeat.inputs\": [\n",
    "        {\n",
    "            \"type\": \"log\",\n",
    "            \"enabled\": True,\n",
    "            \"paths\": [\n",
    "                \"/var/log/suricata/eve.json\"\n",
    "            ],\n",
    "            \"json.keys_under_root\": True,\n",
    "            \"json.add_error_key\": True,\n",
    "            \"json.message_key\": \"message\",\n",
    "            \"fields\": {\n",
    "                \"log_type\": \"suricata\"\n",
    "            },\n",
    "            \"fields_under_root\": False\n",
    "        }\n",
    "    ],\n",
    "    \"output.elasticsearch\": {\n",
    "        \"hosts\": [\"https://es01:9200\"],\n",
    "        \"index\": \"suricata-%{+yyyy.MM.dd}\",\n",
    "        \"username\": \"elastic\",\n",
    "        \"password\": \"${ELASTICSEARCH_PASSWORD}\",\n",
    "        \"ssl\": {\n",
    "            \"certificate_authorities\": [\"/usr/share/filebeat/config/certs/ca/ca.crt\"],\n",
    "            \"verification_mode\": \"certificate\"\n",
    "        }\n",
    "    },\n",
    "    \"setup.template.name\": \"suricata\",\n",
    "    \"setup.template.pattern\": \"suricata-*\",\n",
    "    \"setup.template.settings\": {\n",
    "        \"index.number_of_shards\": 1,\n",
    "        \"index.codec\": \"best_compression\"\n",
    "    },\n",
    "    \"processors\": [\n",
    "        {\n",
    "            \"timestamp\": {\n",
    "                \"field\": \"timestamp\",\n",
    "                \"layouts\": [\n",
    "                    \"2006-01-02T15:04:05.000000-0700\",\n",
    "                    \"2006-01-02T15:04:05.000000Z\",\n",
    "                    \"2006-01-02T15:04:05Z\"\n",
    "                ],\n",
    "                \"test\": [\n",
    "                    \"2024-01-15T10:30:45.123456Z\"\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Sauvegarder la configuration\n",
    "import builtins\n",
    "config_file = \"filebeat_suricata.yml\"\n",
    "# V√©rifier si c'est un r√©pertoire et le supprimer si n√©cessaire\n",
    "if os.path.exists(config_file) and os.path.isdir(config_file):\n",
    "    import shutil\n",
    "    shutil.rmtree(config_file)\n",
    "    print(f\"‚ö†Ô∏è  Suppression du r√©pertoire {config_file} (sera remplac√© par un fichier)\")\n",
    "with builtins.open(config_file, 'w') as f:\n",
    "    import yaml\n",
    "    try:\n",
    "        yaml.dump(filebeat_config, f, default_flow_style=False, sort_keys=False, allow_unicode=True)\n",
    "    except ImportError:\n",
    "        # Si PyYAML n'est pas install√©, sauvegarder en JSON\n",
    "        json.dump(filebeat_config, f, indent=2)\n",
    "        print(\"‚ö†Ô∏è  PyYAML non install√©, configuration sauvegard√©e en JSON\")\n",
    "        print(\"   Pour installer PyYAML: pip install pyyaml\")\n",
    "\n",
    "print(f\"‚úÖ Configuration Filebeat cr√©√©e: {config_file}\")\n",
    "print(\"\\nüìù Note: Cette configuration sera utilis√©e automatiquement par le service Filebeat\")\n",
    "print(\"   dans docker-compose.yml. Le mot de passe sera inject√© via la variable\")\n",
    "print(\"   d'environnement ELASTICSEARCH_PASSWORD.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Indexation manuelle des logs dans Elasticsearch\n",
    "\n",
    "Pour ce TD, nous allons indexer directement les logs dans Elasticsearch via l'API Python, ce qui √©vite d'avoir √† installer et configurer Filebeat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:40.249953Z",
     "iopub.status.busy": "2026-01-17T14:32:40.249691Z",
     "iopub.status.idle": "2026-01-17T14:32:41.195874Z",
     "shell.execute_reply": "2026-01-17T14:32:41.194297Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Index 'suricata-logs' cr√©√© avec mapping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 5 logs index√©s dans 'suricata-logs'\n",
      "   Nombre total de documents: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Indexation des logs Suricata dans Elasticsearch\n",
    "import os\n",
    "\n",
    "# Lire les logs depuis le fichier (chercher dans les deux r√©pertoires possibles)\n",
    "log_file = \"./suricata_logs/eve.json\"\n",
    "if not os.path.exists(log_file):\n",
    "    log_file = \"./suricata_logs_local/eve.json\"\n",
    "index_name = \"suricata-logs\"\n",
    "\n",
    "# Cr√©er un index avec mapping appropri√© pour les logs Suricata\n",
    "mapping = {\n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"timestamp\": {\"type\": \"date\"},\n",
    "            \"event_type\": {\"type\": \"keyword\"},\n",
    "            \"src_ip\": {\"type\": \"ip\"},\n",
    "            \"src_port\": {\"type\": \"integer\"},\n",
    "            \"dest_ip\": {\"type\": \"ip\"},\n",
    "            \"dest_port\": {\"type\": \"integer\"},\n",
    "            \"proto\": {\"type\": \"keyword\"},\n",
    "            \"alert\": {\n",
    "                \"properties\": {\n",
    "                    \"action\": {\"type\": \"keyword\"},\n",
    "                    \"gid\": {\"type\": \"integer\"},\n",
    "                    \"signature_id\": {\"type\": \"integer\"},\n",
    "                    \"signature\": {\"type\": \"text\", \"fields\": {\"keyword\": {\"type\": \"keyword\"}}},\n",
    "                    \"category\": {\"type\": \"keyword\"},\n",
    "                    \"severity\": {\"type\": \"integer\"}\n",
    "                }\n",
    "            },\n",
    "            \"http\": {\n",
    "                \"properties\": {\n",
    "                    \"hostname\": {\"type\": \"keyword\"},\n",
    "                    \"url\": {\"type\": \"text\"},\n",
    "                    \"http_method\": {\"type\": \"keyword\"},\n",
    "                    \"status\": {\"type\": \"integer\"}\n",
    "                }\n",
    "            },\n",
    "            \"dns\": {\n",
    "                \"properties\": {\n",
    "                    \"type\": {\"type\": \"keyword\"},\n",
    "                    \"rrname\": {\"type\": \"keyword\"},\n",
    "                    \"rrtype\": {\"type\": \"keyword\"}\n",
    "                }\n",
    "            },\n",
    "            \"flow_id\": {\"type\": \"long\"},\n",
    "            \"in_iface\": {\"type\": \"keyword\"}\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Supprimer l'index s'il existe\n",
    "if es.indices.exists(index=index_name):\n",
    "    es.indices.delete(index=index_name)\n",
    "    print(f\"üóëÔ∏è  Index '{index_name}' supprim√©\")\n",
    "\n",
    "# Cr√©er l'index avec le mapping\n",
    "es.indices.create(index=index_name, body=mapping)\n",
    "print(f\"‚úÖ Index '{index_name}' cr√©√© avec mapping\")\n",
    "\n",
    "# Indexer les logs\n",
    "if os.path.exists(log_file):\n",
    "    with open(log_file, 'r') as f:\n",
    "        logs = [json.loads(line) for line in f if line.strip()]\n",
    "    \n",
    "    # Indexer chaque log\n",
    "    for i, log in enumerate(logs):\n",
    "        # Convertir le timestamp en format date si n√©cessaire\n",
    "        if 'timestamp' in log:\n",
    "            try:\n",
    "                # Essayer de parser le timestamp\n",
    "                log['@timestamp'] = log['timestamp']\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        es.index(index=index_name, document=log, id=i+1)\n",
    "    \n",
    "    # Rafra√Æchir l'index pour que les donn√©es soient disponibles\n",
    "    es.indices.refresh(index=index_name)\n",
    "    \n",
    "    print(f\"‚úÖ {len(logs)} logs index√©s dans '{index_name}'\")\n",
    "    \n",
    "    # V√©rifier le nombre de documents\n",
    "    count = es.count(index=index_name)\n",
    "    print(f\"   Nombre total de documents: {count['count']}\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Fichier {log_file} non trouv√©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 : Exploration des donn√©es dans Elasticsearch\n",
    "\n",
    "### 3.1 Recherche de base dans les logs Suricata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.199543Z",
     "iopub.status.busy": "2026-01-17T14:32:41.199277Z",
     "iopub.status.idle": "2026-01-17T14:32:41.224547Z",
     "shell.execute_reply": "2026-01-17T14:32:41.221800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Total de documents: 5\n",
      "   Documents retourn√©s: 5\n",
      "\n",
      "üìÑ Document 1:\n",
      "   Type: alert\n",
      "   Alerte: ET POLICY Suspicious inbound to mySQL port 3306\n",
      "   Source IP: 192.168.1.100 ‚Üí Dest IP: 10.0.0.50\n",
      "\n",
      "üìÑ Document 2:\n",
      "   Type: alert\n",
      "   Alerte: ET SCAN Potential SSH Scan\n",
      "   Source IP: 203.0.113.45 ‚Üí Dest IP: 10.0.0.50\n",
      "\n",
      "üìÑ Document 3:\n",
      "   Type: http\n",
      "   Source IP: 192.168.1.100 ‚Üí Dest IP: 10.0.0.50\n",
      "\n",
      "üìÑ Document 4:\n",
      "   Type: dns\n",
      "   Source IP: 192.168.1.100 ‚Üí Dest IP: 8.8.8.8\n",
      "\n",
      "üìÑ Document 5:\n",
      "   Type: alert\n",
      "   Alerte: ET MALWARE Known Malware IP\n",
      "   Source IP: 198.51.100.10 ‚Üí Dest IP: 10.0.0.50\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Recherche de tous les logs\n",
    "query_all = {\n",
    "    \"match_all\": {}\n",
    "}\n",
    "\n",
    "result = es.search(index=index_name, query=query_all, size=10)\n",
    "print(f\"üìä Total de documents: {result['hits']['total']['value']}\")\n",
    "print(f\"   Documents retourn√©s: {len(result['hits']['hits'])}\\n\")\n",
    "\n",
    "for hit in result['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    print(f\"üìÑ Document {hit['_id']}:\")\n",
    "    print(f\"   Type: {source.get('event_type', 'N/A')}\")\n",
    "    if 'alert' in source:\n",
    "        print(f\"   Alerte: {source['alert'].get('signature', 'N/A')}\")\n",
    "    print(f\"   Source IP: {source.get('src_ip', 'N/A')} ‚Üí Dest IP: {source.get('dest_ip', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Recherche d'alertes sp√©cifiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.228788Z",
     "iopub.status.busy": "2026-01-17T14:32:41.228474Z",
     "iopub.status.idle": "2026-01-17T14:32:41.259295Z",
     "shell.execute_reply": "2026-01-17T14:32:41.257804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® Nombre d'alertes trouv√©es: 3\n",
      "\n",
      "‚ö†Ô∏è  Alerte ID: 2012896\n",
      "   Signature: ET POLICY Suspicious inbound to mySQL port 3306\n",
      "   Cat√©gorie: Potentially Bad Traffic\n",
      "   S√©v√©rit√©: 2\n",
      "   Source: 192.168.1.100:54321\n",
      "   Destination: 10.0.0.50:80\n",
      "\n",
      "‚ö†Ô∏è  Alerte ID: 2012897\n",
      "   Signature: ET SCAN Potential SSH Scan\n",
      "   Cat√©gorie: Attempted Information Leak\n",
      "   S√©v√©rit√©: 2\n",
      "   Source: 203.0.113.45:44321\n",
      "   Destination: 10.0.0.50:22\n",
      "\n",
      "‚ö†Ô∏è  Alerte ID: 2012898\n",
      "   Signature: ET MALWARE Known Malware IP\n",
      "   Cat√©gorie: A Network Trojan was detected\n",
      "   S√©v√©rit√©: 1\n",
      "   Source: 198.51.100.10:44324\n",
      "   Destination: 10.0.0.50:443\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Rechercher toutes les alertes (event_type = \"alert\")\n",
    "query_alerts = {\n",
    "    \"bool\": {\n",
    "        \"must\": [\n",
    "            {\"term\": {\"event_type\": \"alert\"}}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "result = es.search(index=index_name, query=query_alerts, size=100)\n",
    "print(f\"üö® Nombre d'alertes trouv√©es: {result['hits']['total']['value']}\\n\")\n",
    "\n",
    "for hit in result['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    alert = source.get('alert', {})\n",
    "    print(f\"‚ö†Ô∏è  Alerte ID: {alert.get('signature_id', 'N/A')}\")\n",
    "    print(f\"   Signature: {alert.get('signature', 'N/A')}\")\n",
    "    print(f\"   Cat√©gorie: {alert.get('category', 'N/A')}\")\n",
    "    print(f\"   S√©v√©rit√©: {alert.get('severity', 'N/A')}\")\n",
    "    print(f\"   Source: {source.get('src_ip', 'N/A')}:{source.get('src_port', 'N/A')}\")\n",
    "    print(f\"   Destination: {source.get('dest_ip', 'N/A')}:{source.get('dest_port', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Recherche d'alertes de haute s√©v√©rit√©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.262269Z",
     "iopub.status.busy": "2026-01-17T14:32:41.261987Z",
     "iopub.status.idle": "2026-01-17T14:32:41.292386Z",
     "shell.execute_reply": "2026-01-17T14:32:41.291020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¥ Alertes de haute s√©v√©rit√© (‚â§1): 1\n",
      "\n",
      "üî¥ CRITIQUE - S√©v√©rit√© 1\n",
      "   ET MALWARE Known Malware IP\n",
      "   Source IP suspecte: 198.51.100.10\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Rechercher les alertes de haute s√©v√©rit√© (severity <= 1)\n",
    "query_high_severity = {\n",
    "    \"bool\": {\n",
    "        \"must\": [\n",
    "            {\"term\": {\"event_type\": \"alert\"}},\n",
    "            {\"range\": {\"alert.severity\": {\"lte\": 1}}}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "result = es.search(index=index_name, query=query_high_severity, size=100)\n",
    "print(f\"üî¥ Alertes de haute s√©v√©rit√© (‚â§1): {result['hits']['total']['value']}\\n\")\n",
    "\n",
    "for hit in result['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    alert = source.get('alert', {})\n",
    "    print(f\"üî¥ CRITIQUE - S√©v√©rit√© {alert.get('severity', 'N/A')}\")\n",
    "    print(f\"   {alert.get('signature', 'N/A')}\")\n",
    "    print(f\"   Source IP suspecte: {source.get('src_ip', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Agr√©gations : Statistiques sur les alertes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.295378Z",
     "iopub.status.busy": "2026-01-17T14:32:41.294896Z",
     "iopub.status.idle": "2026-01-17T14:32:41.426228Z",
     "shell.execute_reply": "2026-01-17T14:32:41.424749Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Statistiques sur les alertes\n",
      "\n",
      "==================================================\n",
      "\n",
      "üìÅ Alertes par cat√©gorie:\n",
      "   A Network Trojan was detected: 1\n",
      "   Attempted Information Leak: 1\n",
      "   Potentially Bad Traffic: 1\n",
      "\n",
      "‚ö†Ô∏è  Alertes par s√©v√©rit√©:\n",
      "   S√©v√©rit√© 2: 2\n",
      "   S√©v√©rit√© 1: 1\n",
      "\n",
      "üåê Top 10 IPs sources:\n",
      "   192.168.1.100: 3 √©v√©nements\n",
      "   198.51.100.10: 1 √©v√©nements\n",
      "   203.0.113.45: 1 √©v√©nements\n",
      "\n",
      "üîç Top 10 signatures:\n",
      "   ET MALWARE Known Malware IP: 1\n",
      "   ET POLICY Suspicious inbound to mySQL port 3306: 1\n",
      "   ET SCAN Potential SSH Scan: 1\n"
     ]
    }
   ],
   "source": [
    "# Agr√©gations pour analyser les donn√©es\n",
    "aggs_query = {\n",
    "    \"size\": 0,\n",
    "    \"aggs\": {\n",
    "        \"alertes_par_categorie\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"alert.category\",\n",
    "                \"size\": 10\n",
    "            }\n",
    "        },\n",
    "        \"alertes_par_severite\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"alert.severity\",\n",
    "                \"size\": 5\n",
    "            }\n",
    "        },\n",
    "        \"top_source_ips\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"src_ip\",\n",
    "                \"size\": 10\n",
    "            }\n",
    "        },\n",
    "        \"top_dest_ips\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"dest_ip\",\n",
    "                \"size\": 10\n",
    "            }\n",
    "        },\n",
    "        \"top_signatures\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"alert.signature.keyword\",\n",
    "                \"size\": 10\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "result = es.search(index=index_name, body=aggs_query)\n",
    "\n",
    "print(\"üìä Statistiques sur les alertes\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Alertes par cat√©gorie\n",
    "if 'alertes_par_categorie' in result['aggregations']:\n",
    "    print(\"\\nüìÅ Alertes par cat√©gorie:\")\n",
    "    for bucket in result['aggregations']['alertes_par_categorie']['buckets']:\n",
    "        print(f\"   {bucket['key']}: {bucket['doc_count']}\")\n",
    "\n",
    "# Alertes par s√©v√©rit√©\n",
    "if 'alertes_par_severite' in result['aggregations']:\n",
    "    print(\"\\n‚ö†Ô∏è  Alertes par s√©v√©rit√©:\")\n",
    "    for bucket in result['aggregations']['alertes_par_severite']['buckets']:\n",
    "        print(f\"   S√©v√©rit√© {bucket['key']}: {bucket['doc_count']}\")\n",
    "\n",
    "# Top IPs sources\n",
    "if 'top_source_ips' in result['aggregations']:\n",
    "    print(\"\\nüåê Top 10 IPs sources:\")\n",
    "    for bucket in result['aggregations']['top_source_ips']['buckets']:\n",
    "        print(f\"   {bucket['key']}: {bucket['doc_count']} √©v√©nements\")\n",
    "\n",
    "# Top signatures\n",
    "if 'top_signatures' in result['aggregations']:\n",
    "    print(\"\\nüîç Top 10 signatures:\")\n",
    "    for bucket in result['aggregations']['top_signatures']['buckets']:\n",
    "        print(f\"   {bucket['key']}: {bucket['doc_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 4 : Visualisation dans Kibana\n",
    "\n",
    "### 4.1 Acc√®s √† Kibana\n",
    "\n",
    "1. Ouvrez votre navigateur et allez sur `http://localhost:5601`\n",
    "2. Connectez-vous avec les identifiants d√©finis dans votre fichier `.env` (si s√©curit√© activ√©e)\n",
    "3. Si c'est la premi√®re fois, vous devrez peut-√™tre accepter les termes de licence\n",
    "\n",
    "### 4.2 Cr√©ation d'un index pattern\n",
    "\n",
    "Pour visualiser les donn√©es dans Kibana, vous devez cr√©er un **index pattern** :\n",
    "\n",
    "1. Allez dans **Management** ‚Üí **Stack Management** ‚Üí **Index Patterns**\n",
    "2. Cliquez sur **Create index pattern**\n",
    "3. Entrez le pattern : `suricata-logs` ou `suricata-*` (si vous utilisez des dates)\n",
    "4. S√©lectionnez le champ de temps : `@timestamp` ou `timestamp`\n",
    "5. Cliquez sur **Create index pattern**\n",
    "\n",
    "### 4.3 Cr√©ation de visualisations\n",
    "\n",
    "Dans Kibana, cr√©ez les visualisations suivantes :\n",
    "\n",
    "#### Visualisation 1 : Timeline des alertes\n",
    "- **Type** : Line chart ou Area chart\n",
    "- **M√©trique** : Count\n",
    "- **Buckets** : Date Histogram sur `@timestamp`\n",
    "- **Filtre** : `event_type: alert`\n",
    "\n",
    "#### Visualisation 2 : Top 10 signatures d'alertes\n",
    "- **Type** : Horizontal Bar chart\n",
    "- **M√©trique** : Count\n",
    "- **Buckets** : Terms sur `alert.signature.keyword` (Top 10)\n",
    "\n",
    "#### Visualisation 3 : R√©partition par s√©v√©rit√©\n",
    "- **Type** : Pie chart\n",
    "- **M√©trique** : Count\n",
    "- **Buckets** : Terms sur `alert.severity`\n",
    "\n",
    "#### Visualisation 4 : Carte des IPs sources\n",
    "- **Type** : Coordinate Map ou Tile Map\n",
    "- **M√©trique** : Count\n",
    "- **Buckets** : Geohash sur `src_ip` (si g√©olocalisation activ√©e)\n",
    "\n",
    "### 4.4 Cr√©ation d'un Dashboard\n",
    "\n",
    "1. Allez dans **Dashboard** ‚Üí **Create dashboard**\n",
    "2. Ajoutez les visualisations cr√©√©es pr√©c√©demment\n",
    "3. Configurez les filtres temporels\n",
    "4. Sauvegardez le dashboard\n",
    "\n",
    "**Note :** Pour ce TD, nous allons √©galement cr√©er des visualisations programmatiquement via l'API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.429291Z",
     "iopub.status.busy": "2026-01-17T14:32:41.429031Z",
     "iopub.status.idle": "2026-01-17T14:32:41.458835Z",
     "shell.execute_reply": "2026-01-17T14:32:41.457388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Kibana est accessible\n",
      "   Version: N/A\n"
     ]
    }
   ],
   "source": [
    "# V√©rification de l'acc√®s √† Kibana (via l'API REST)\n",
    "import requests\n",
    "import urllib3\n",
    "\n",
    "# D√©sactiver les avertissements SSL pour le d√©veloppement\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "KIBANA_URL = \"http://localhost:5601\"\n",
    "KIBANA_USER = \"elastic\"  # Modifiez si n√©cessaire\n",
    "KIBANA_PASSWORD = None  # D√©finissez votre mot de passe si s√©curit√© activ√©e\n",
    "\n",
    "# Test de connexion √† Kibana\n",
    "try:\n",
    "    if KIBANA_PASSWORD:\n",
    "        response = requests.get(\n",
    "            f\"{KIBANA_URL}/api/status\",\n",
    "            auth=(KIBANA_USER, KIBANA_PASSWORD),\n",
    "            verify=False,\n",
    "            timeout=5\n",
    "        )\n",
    "    else:\n",
    "        response = requests.get(f\"{KIBANA_URL}/api/status\", timeout=5)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"‚úÖ Kibana est accessible\")\n",
    "        status = response.json()\n",
    "        print(f\"   Version: {status.get('version', {}).get('number', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Kibana r√©pond mais avec le code: {response.status_code}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"‚ùå Impossible de se connecter √† Kibana\")\n",
    "    print(\"   V√©rifiez que Kibana est d√©marr√© sur http://localhost:5601\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 5 : Alerting dans Kibana\n",
    "\n",
    "### 5.1 Cr√©ation de r√®gles d'alerte\n",
    "\n",
    "Kibana permet de cr√©er des r√®gles d'alerte bas√©es sur des requ√™tes Elasticsearch. Voici quelques exemples de r√®gles utiles pour un SIEM :\n",
    "\n",
    "#### R√®gle 1 : Alerte sur haute s√©v√©rit√©\n",
    "- **Condition** : Nombre d'alertes avec `severity <= 1` > 0\n",
    "- **Action** : Envoyer une notification (email, Slack, etc.)\n",
    "\n",
    "#### R√®gle 2 : Alerte sur scan de ports\n",
    "- **Condition** : Plus de 10 alertes de type \"SCAN\" en 5 minutes\n",
    "- **Action** : Notification imm√©diate\n",
    "\n",
    "#### R√®gle 3 : Alerte sur IP suspecte\n",
    "- **Condition** : Plus de 5 alertes depuis la m√™me IP source en 10 minutes\n",
    "- **Action** : Bloquer l'IP (si int√©gration avec firewall)\n",
    "\n",
    "### 5.2 Configuration des alertes via l'API\n",
    "\n",
    "Pour cr√©er des alertes programmatiquement, utilisez l'API Kibana Alerting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.461563Z",
     "iopub.status.busy": "2026-01-17T14:32:41.461236Z",
     "iopub.status.idle": "2026-01-17T14:32:41.468439Z",
     "shell.execute_reply": "2026-01-17T14:32:41.467045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Exemple de r√®gle d'alerte cr√©√©e:\n",
      "{\n",
      "  \"name\": \"Alerte haute s\\u00e9v\\u00e9rit\\u00e9 Suricata\",\n",
      "  \"consumer\": \"alerts\",\n",
      "  \"enabled\": true,\n",
      "  \"rule_type_id\": \".es-query\",\n",
      "  \"schedule\": {\n",
      "    \"interval\": \"1m\"\n",
      "  },\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"group\": \"query matched\",\n",
      "      \"id\": \"my-connector-id\",\n",
      "      \"params\": {\n",
      "        \"message\": \"Alerte: Alerte haute s\\u00e9v\\u00e9rit\\u00e9 Suricata - Seuil d\\u00e9pass\\u00e9!\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"params\": {\n",
      "    \"index\": [\n",
      "      \"suricata-logs\"\n",
      "    ],\n",
      "    \"query\": {\n",
      "      \"bool\": {\n",
      "        \"must\": [\n",
      "          {\n",
      "            \"term\": {\n",
      "              \"event_type\": \"alert\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"range\": {\n",
      "              \"alert.severity\": {\n",
      "                \"lte\": 1\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    \"size\": 100,\n",
      "    \"timeField\": \"@timestamp\",\n",
      "    \"timeWindowSize\": \"5m\",\n",
      "    \"threshold\": [\n",
      "      {\n",
      "        \"field\": \"count\",\n",
      "        \"value\": 0,\n",
      "        \"comparator\": \">\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "üí° Pour cr√©er cette r√®gle dans Kibana:\n",
      "   1. Allez dans Stack Management ‚Üí Rules and Connectors\n",
      "   2. Cr√©ez un connecteur (email, Slack, etc.)\n",
      "   3. Cr√©ez une nouvelle r√®gle avec les param√®tres ci-dessus\n"
     ]
    }
   ],
   "source": [
    "# Exemple de cr√©ation d'une r√®gle d'alerte Kibana\n",
    "# Note: Cette fonctionnalit√© n√©cessite Kibana avec les fonctionnalit√©s d'alerting activ√©es\n",
    "\n",
    "def create_alert_rule(rule_name, query, threshold, time_window=\"5m\"):\n",
    "    \"\"\"\n",
    "    Cr√©e une r√®gle d'alerte Kibana\n",
    "    \n",
    "    Args:\n",
    "        rule_name: Nom de la r√®gle\n",
    "        query: Requ√™te Elasticsearch (dict)\n",
    "        threshold: Seuil d'alerte\n",
    "        time_window: Fen√™tre temporelle (ex: \"5m\", \"1h\")\n",
    "    \"\"\"\n",
    "    alert_rule = {\n",
    "        \"name\": rule_name,\n",
    "        \"consumer\": \"alerts\",\n",
    "        \"enabled\": True,\n",
    "        \"rule_type_id\": \".es-query\",\n",
    "        \"schedule\": {\n",
    "            \"interval\": \"1m\"\n",
    "        },\n",
    "        \"actions\": [\n",
    "            {\n",
    "                \"group\": \"query matched\",\n",
    "                \"id\": \"my-connector-id\",  # √Ä remplacer par un ID de connecteur r√©el\n",
    "                \"params\": {\n",
    "                    \"message\": f\"Alerte: {rule_name} - Seuil d√©pass√©!\"\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"params\": {\n",
    "            \"index\": [index_name],\n",
    "            \"query\": query,\n",
    "            \"size\": 100,\n",
    "            \"timeField\": \"@timestamp\",\n",
    "            \"timeWindowSize\": time_window,\n",
    "            \"threshold\": [\n",
    "                {\n",
    "                    \"field\": \"count\",\n",
    "                    \"value\": threshold,\n",
    "                    \"comparator\": \">\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return alert_rule\n",
    "\n",
    "# Exemple: R√®gle d'alerte pour haute s√©v√©rit√©\n",
    "high_severity_query = {\n",
    "    \"bool\": {\n",
    "        \"must\": [\n",
    "            {\"term\": {\"event_type\": \"alert\"}},\n",
    "            {\"range\": {\"alert.severity\": {\"lte\": 1}}}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "alert_rule = create_alert_rule(\n",
    "    rule_name=\"Alerte haute s√©v√©rit√© Suricata\",\n",
    "    query=high_severity_query,\n",
    "    threshold=0,\n",
    "    time_window=\"5m\"\n",
    ")\n",
    "\n",
    "print(\"üìã Exemple de r√®gle d'alerte cr√©√©e:\")\n",
    "print(json.dumps(alert_rule, indent=2))\n",
    "\n",
    "print(\"\\nüí° Pour cr√©er cette r√®gle dans Kibana:\")\n",
    "print(\"   1. Allez dans Stack Management ‚Üí Rules and Connectors\")\n",
    "print(\"   2. Cr√©ez un connecteur (email, Slack, etc.)\")\n",
    "print(\"   3. Cr√©ez une nouvelle r√®gle avec les param√®tres ci-dessus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.471568Z",
     "iopub.status.busy": "2026-01-17T14:32:41.471319Z",
     "iopub.status.idle": "2026-01-17T14:32:41.558657Z",
     "shell.execute_reply": "2026-01-17T14:32:41.557436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç IPs sources suspectes (‚â•1 alertes):\n",
      "\n",
      "‚ö†Ô∏è  192.168.1.100: 1 alertes\n",
      "   - ET POLICY Suspicious inbound to mySQL port 3306 (S√©v√©rit√©: 2)\n",
      "\n",
      "‚ö†Ô∏è  198.51.100.10: 1 alertes\n",
      "   - ET MALWARE Known Malware IP (S√©v√©rit√©: 1)\n",
      "\n",
      "‚ö†Ô∏è  203.0.113.45: 1 alertes\n",
      "   - ET SCAN Potential SSH Scan (S√©v√©rit√©: 2)\n",
      "\n",
      "\n",
      "============================================================\n",
      "üïê Alertes des derni√®res 60 minutes: 3\n",
      "\n",
      "‚è∞ 2026-01-17T15:32:40.125407\n",
      "   ET POLICY Suspicious inbound to mySQL port 3306\n",
      "   192.168.1.100 ‚Üí 10.0.0.50\n",
      "\n",
      "‚è∞ 2026-01-17T15:27:40.125427\n",
      "   ET SCAN Potential SSH Scan\n",
      "   203.0.113.45 ‚Üí 10.0.0.50\n",
      "\n",
      "‚è∞ 2026-01-17T15:12:40.125446\n",
      "   ET MALWARE Known Malware IP\n",
      "   198.51.100.10 ‚Üí 10.0.0.50\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 10, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 3, 'relation': 'eq'}, 'max_score': None, 'hits': [{'_index': 'suricata-logs', '_id': '1', '_score': None, '_source': {'timestamp': '2026-01-17T15:32:40.125407', 'event_type': 'alert', 'src_ip': '192.168.1.100', 'src_port': 54321, 'dest_ip': '10.0.0.50', 'dest_port': 80, 'proto': 'TCP', 'alert': {'action': 'allowed', 'gid': 1, 'signature_id': 2012896, 'rev': 1, 'signature': 'ET POLICY Suspicious inbound to mySQL port 3306', 'category': 'Potentially Bad Traffic', 'severity': 2}, 'flow_id': 1234567890, 'in_iface': 'eth0', '@timestamp': '2026-01-17T15:32:40.125407'}, 'sort': [1768663960125]}, {'_index': 'suricata-logs', '_id': '2', '_score': None, '_source': {'timestamp': '2026-01-17T15:27:40.125427', 'event_type': 'alert', 'src_ip': '203.0.113.45', 'src_port': 44321, 'dest_ip': '10.0.0.50', 'dest_port': 22, 'proto': 'TCP', 'alert': {'action': 'allowed', 'gid': 1, 'signature_id': 2012897, 'rev': 1, 'signature': 'ET SCAN Potential SSH Scan', 'category': 'Attempted Information Leak', 'severity': 2}, 'flow_id': 1234567891, 'in_iface': 'eth0', '@timestamp': '2026-01-17T15:27:40.125427'}, 'sort': [1768663660125]}, {'_index': 'suricata-logs', '_id': '5', '_score': None, '_source': {'timestamp': '2026-01-17T15:12:40.125446', 'event_type': 'alert', 'src_ip': '198.51.100.10', 'src_port': 44324, 'dest_ip': '10.0.0.50', 'dest_port': 443, 'proto': 'TCP', 'alert': {'action': 'allowed', 'gid': 1, 'signature_id': 2012898, 'rev': 1, 'signature': 'ET MALWARE Known Malware IP', 'category': 'A Network Trojan was detected', 'severity': 1}, 'flow_id': 1234567894, 'in_iface': 'eth0', '@timestamp': '2026-01-17T15:12:40.125446'}, 'sort': [1768662760125]}]}})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# D√©tection de patterns suspects\n",
    "\n",
    "# 1. D√©tection d'IP source avec beaucoup d'alertes (possible scan/attaque)\n",
    "def detect_suspicious_source_ips(min_alerts=3):\n",
    "    \"\"\"D√©tecte les IPs sources avec un nombre √©lev√© d'alertes\"\"\"\n",
    "    query = {\n",
    "        \"size\": 0,\n",
    "        \"query\": {\n",
    "            \"term\": {\"event_type\": \"alert\"}\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"suspicious_ips\": {\n",
    "                \"terms\": {\n",
    "                    \"field\": \"src_ip\",\n",
    "                    \"size\": 20,\n",
    "                    \"min_doc_count\": min_alerts\n",
    "                },\n",
    "                \"aggs\": {\n",
    "                    \"alert_details\": {\n",
    "                        \"top_hits\": {\n",
    "                            \"size\": 5,\n",
    "                            \"_source\": {\n",
    "                                \"includes\": [\"alert.signature\", \"alert.severity\", \"dest_ip\", \"dest_port\"]\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result = es.search(index=index_name, body=query)\n",
    "    \n",
    "    print(f\"üîç IPs sources suspectes (‚â•{min_alerts} alertes):\\n\")\n",
    "    for bucket in result['aggregations']['suspicious_ips']['buckets']:\n",
    "        ip = bucket['key']\n",
    "        count = bucket['doc_count']\n",
    "        print(f\"‚ö†Ô∏è  {ip}: {count} alertes\")\n",
    "        \n",
    "        # Afficher les d√©tails des alertes\n",
    "        for hit in bucket['alert_details']['hits']['hits']:\n",
    "            source = hit['_source']\n",
    "            alert = source.get('alert', {})\n",
    "            print(f\"   - {alert.get('signature', 'N/A')} (S√©v√©rit√©: {alert.get('severity', 'N/A')})\")\n",
    "        print()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 2. D√©tection d'alertes r√©centes (derni√®res 30 minutes)\n",
    "def detect_recent_alerts(minutes=30):\n",
    "    \"\"\"D√©tecte les alertes r√©centes\"\"\"\n",
    "    time_threshold = datetime.now() - timedelta(minutes=minutes)\n",
    "    \n",
    "    query = {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\"term\": {\"event_type\": \"alert\"}}\n",
    "            ],\n",
    "            \"filter\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": time_threshold.isoformat()\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result = es.search(index=index_name, query=query, size=100, sort=[{\"@timestamp\": {\"order\": \"desc\"}}])\n",
    "    \n",
    "    print(f\"üïê Alertes des derni√®res {minutes} minutes: {result['hits']['total']['value']}\\n\")\n",
    "    \n",
    "    for hit in result['hits']['hits']:\n",
    "        source = hit['_source']\n",
    "        alert = source.get('alert', {})\n",
    "        timestamp = source.get('@timestamp', source.get('timestamp', 'N/A'))\n",
    "        print(f\"‚è∞ {timestamp}\")\n",
    "        print(f\"   {alert.get('signature', 'N/A')}\")\n",
    "        print(f\"   {source.get('src_ip', 'N/A')} ‚Üí {source.get('dest_ip', 'N/A')}\")\n",
    "        print()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Ex√©cuter les d√©tections\n",
    "print(\"=\" * 60)\n",
    "detect_suspicious_source_ips(min_alerts=1)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "detect_recent_alerts(minutes=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.561411Z",
     "iopub.status.busy": "2026-01-17T14:32:41.561146Z",
     "iopub.status.idle": "2026-01-17T14:32:41.641979Z",
     "shell.execute_reply": "2026-01-17T14:32:41.640384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìà Analyse des patterns temporels\n",
      "\n",
      "üïê Distribution des alertes par heure:\n",
      "   2026-01-17T15:00:00.000Z: 3 alertes (3 IPs uniques)\n",
      "\n",
      "üìä Total d'alertes analys√©es: 3\n"
     ]
    }
   ],
   "source": [
    "# Exemple de requ√™te pour analyser les patterns temporels (utile pour ML)\n",
    "# Cette requ√™te peut √™tre utilis√©e comme base pour un job ML\n",
    "\n",
    "def analyze_temporal_patterns():\n",
    "    \"\"\"Analyse les patterns temporels dans les alertes\"\"\"\n",
    "    \n",
    "    # Agr√©gation par heure de la journ√©e\n",
    "    query = {\n",
    "        \"size\": 0,\n",
    "        \"query\": {\n",
    "            \"term\": {\"event_type\": \"alert\"}\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"alerts_by_hour\": {\n",
    "                \"date_histogram\": {\n",
    "                    \"field\": \"@timestamp\",\n",
    "                    \"calendar_interval\": \"hour\",\n",
    "                    \"min_doc_count\": 1\n",
    "                },\n",
    "                \"aggs\": {\n",
    "                    \"by_severity\": {\n",
    "                        \"terms\": {\n",
    "                            \"field\": \"alert.severity\",\n",
    "                            \"size\": 5\n",
    "                        }\n",
    "                    },\n",
    "                    \"unique_ips\": {\n",
    "                        \"cardinality\": {\n",
    "                            \"field\": \"src_ip\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"alerts_by_day\": {\n",
    "                \"date_histogram\": {\n",
    "                    \"field\": \"@timestamp\",\n",
    "                    \"calendar_interval\": \"day\",\n",
    "                    \"min_doc_count\": 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result = es.search(index=index_name, body=query)\n",
    "    \n",
    "    print(\"üìà Analyse des patterns temporels\\n\")\n",
    "    \n",
    "    # Afficher les alertes par heure\n",
    "    if 'alerts_by_hour' in result['aggregations']:\n",
    "        print(\"üïê Distribution des alertes par heure:\")\n",
    "        for bucket in result['aggregations']['alerts_by_hour']['buckets']:\n",
    "            time_str = bucket['key_as_string']\n",
    "            count = bucket['doc_count']\n",
    "            unique_ips = bucket['unique_ips']['value']\n",
    "            print(f\"   {time_str}: {count} alertes ({unique_ips} IPs uniques)\")\n",
    "    \n",
    "    print(f\"\\nüìä Total d'alertes analys√©es: {result['hits']['total']['value']}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Ex√©cuter l'analyse\n",
    "try:\n",
    "    analyze_temporal_patterns()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur lors de l'analyse: {e}\")\n",
    "    print(\"   Assurez-vous que les donn√©es contiennent des timestamps valides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 D√©tection d'anomalies basique (sans ML)\n",
    "\n",
    "M√™me sans activer ML, nous pouvons cr√©er des r√®gles de d√©tection d'anomalies basiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.644882Z",
     "iopub.status.busy": "2026-01-17T14:32:41.644538Z",
     "iopub.status.idle": "2026-01-17T14:32:41.686137Z",
     "shell.execute_reply": "2026-01-17T14:32:41.684750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç D√©tection d'anomalies basiques\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® ALERTES CRITIQUES R√âCENTES:\n",
      "   - ET MALWARE Known Malware IP\n",
      "     Source: 198.51.100.10\n",
      "     S√©v√©rit√©: 1\n",
      "\n",
      "‚úÖ Aucune anomalie majeure d√©tect√©e avec les crit√®res actuels\n"
     ]
    }
   ],
   "source": [
    "# D√©tection d'anomalies basique : identifier les comportements inhabituels\n",
    "\n",
    "def detect_anomalies():\n",
    "    \"\"\"D√©tecte des anomalies basiques dans les logs\"\"\"\n",
    "    \n",
    "    anomalies = []\n",
    "    \n",
    "    # 1. IP source avec trop d'alertes diff√©rentes (possible botnet/scan)\n",
    "    query1 = {\n",
    "        \"size\": 0,\n",
    "        \"query\": {\"term\": {\"event_type\": \"alert\"}},\n",
    "        \"aggs\": {\n",
    "            \"ips_with_many_alerts\": {\n",
    "                \"terms\": {\n",
    "                    \"field\": \"src_ip\",\n",
    "                    \"size\": 10\n",
    "                },\n",
    "                \"aggs\": {\n",
    "                    \"unique_signatures\": {\n",
    "                        \"cardinality\": {\n",
    "                            \"field\": \"alert.signature_id\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"unique_dest_ips\": {\n",
    "                        \"cardinality\": {\n",
    "                            \"field\": \"dest_ip\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result1 = es.search(index=index_name, body=query1)\n",
    "    \n",
    "    print(\"üîç D√©tection d'anomalies basiques\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Analyser les r√©sultats\n",
    "    for bucket in result1['aggregations']['ips_with_many_alerts']['buckets']:\n",
    "        ip = bucket['key']\n",
    "        total_alerts = bucket['doc_count']\n",
    "        unique_signatures = bucket['unique_signatures']['value']\n",
    "        unique_dest_ips = bucket['unique_dest_ips']['value']\n",
    "        \n",
    "        # Crit√®res d'anomalie\n",
    "        if unique_signatures > 3 or unique_dest_ips > 5:\n",
    "            anomaly = {\n",
    "                \"type\": \"Suspicious scanning activity\",\n",
    "                \"ip\": ip,\n",
    "                \"total_alerts\": total_alerts,\n",
    "                \"unique_signatures\": unique_signatures,\n",
    "                \"unique_dest_ips\": unique_dest_ips\n",
    "            }\n",
    "            anomalies.append(anomaly)\n",
    "            \n",
    "            print(f\"üö® ANOMALIE D√âTECT√âE:\")\n",
    "            print(f\"   IP: {ip}\")\n",
    "            print(f\"   Type: Activit√© de scan suspecte\")\n",
    "            print(f\"   Raison: {unique_signatures} signatures diff√©rentes, {unique_dest_ips} IPs de destination diff√©rentes\")\n",
    "            print(f\"   Total alertes: {total_alerts}\")\n",
    "            print()\n",
    "    \n",
    "    # 2. Alertes de haute s√©v√©rit√© r√©centes\n",
    "    query2 = {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\"term\": {\"event_type\": \"alert\"}},\n",
    "                {\"range\": {\"alert.severity\": {\"lte\": 1}}}\n",
    "            ],\n",
    "            \"filter\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": (datetime.now() - timedelta(hours=1)).isoformat()\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result2 = es.search(index=index_name, query=query2, size=100)\n",
    "    \n",
    "    if result2['hits']['total']['value'] > 0:\n",
    "        print(\"üö® ALERTES CRITIQUES R√âCENTES:\")\n",
    "        for hit in result2['hits']['hits']:\n",
    "            source = hit['_source']\n",
    "            alert = source.get('alert', {})\n",
    "            print(f\"   - {alert.get('signature', 'N/A')}\")\n",
    "            print(f\"     Source: {source.get('src_ip', 'N/A')}\")\n",
    "            print(f\"     S√©v√©rit√©: {alert.get('severity', 'N/A')}\")\n",
    "        print()\n",
    "    \n",
    "    return anomalies\n",
    "\n",
    "# Ex√©cuter la d√©tection\n",
    "anomalies = detect_anomalies()\n",
    "\n",
    "if not anomalies:\n",
    "    print(\"‚úÖ Aucune anomalie majeure d√©tect√©e avec les crit√®res actuels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 7 : Exercices pratiques\n",
    "\n",
    "### Exercice 1 : Recherche d'IPs malveillantes\n",
    "\n",
    "Cr√©ez une requ√™te pour trouver toutes les alertes provenant d'une IP sp√©cifique et analysez les signatures d√©clench√©es.\n",
    "\n",
    "### Exercice 2 : Analyse de trafic HTTP\n",
    "\n",
    "Recherchez tous les √©v√©nements HTTP et identifiez les requ√™tes suspectes (ex: tentatives d'acc√®s √† `/admin`, `/wp-admin`, etc.).\n",
    "\n",
    "### Exercice 3 : Dashboard personnalis√©\n",
    "\n",
    "Cr√©ez un dashboard Kibana avec :\n",
    "- Timeline des alertes\n",
    "- Top 10 des signatures\n",
    "- Carte des IPs sources\n",
    "- Graphique de s√©v√©rit√©\n",
    "\n",
    "### Exercice 4 : R√®gle d'alerte personnalis√©e\n",
    "\n",
    "Cr√©ez une r√®gle d'alerte qui se d√©clenche lorsqu'une IP g√©n√®re plus de 5 alertes en 10 minutes.\n",
    "\n",
    "### Exercice 5 : D√©tection de patterns\n",
    "\n",
    "√âcrivez une requ√™te pour d√©tecter les scans de ports (plusieurs tentatives de connexion sur diff√©rents ports depuis la m√™me IP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.689363Z",
     "iopub.status.busy": "2026-01-17T14:32:41.689077Z",
     "iopub.status.idle": "2026-01-17T14:32:41.716162Z",
     "shell.execute_reply": "2026-01-17T14:32:41.714521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Test avec l'IP: 192.168.1.100\n",
      "\n",
      "üîç Alertes pour l'IP 192.168.1.100: 1\n",
      "\n",
      "üìã Signatures d√©clench√©es:\n",
      "   [2012896] ET POLICY Suspicious inbound to mySQL port 3306: 1 fois (S√©v√©rit√©: 2)\n"
     ]
    }
   ],
   "source": [
    "# EXERCICE 1 : Recherche d'IPs malveillantes\n",
    "# Compl√©tez cette fonction pour rechercher toutes les alertes d'une IP sp√©cifique\n",
    "\n",
    "def search_alerts_by_ip(ip_address):\n",
    "    \"\"\"\n",
    "    Recherche toutes les alertes pour une IP source donn√©e\n",
    "    \n",
    "    Args:\n",
    "        ip_address: Adresse IP √† rechercher (ex: \"192.168.1.100\")\n",
    "    \n",
    "    Returns:\n",
    "        R√©sultats de la recherche\n",
    "    \"\"\"\n",
    "    # TODO: Cr√©er la requ√™te Elasticsearch\n",
    "    query = {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\"term\": {\"event_type\": \"alert\"}},\n",
    "                {\"term\": {\"src_ip\": ip_address}}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result = es.search(index=index_name, query=query, size=100)\n",
    "    \n",
    "    print(f\"üîç Alertes pour l'IP {ip_address}: {result['hits']['total']['value']}\\n\")\n",
    "    \n",
    "    signatures = {}\n",
    "    for hit in result['hits']['hits']:\n",
    "        source = hit['_source']\n",
    "        alert = source.get('alert', {})\n",
    "        sig_id = alert.get('signature_id', 'N/A')\n",
    "        sig_name = alert.get('signature', 'N/A')\n",
    "        \n",
    "        if sig_id not in signatures:\n",
    "            signatures[sig_id] = {\n",
    "                \"name\": sig_name,\n",
    "                \"count\": 0,\n",
    "                \"severity\": alert.get('severity', 'N/A')\n",
    "            }\n",
    "        signatures[sig_id][\"count\"] += 1\n",
    "    \n",
    "    print(\"üìã Signatures d√©clench√©es:\")\n",
    "    for sig_id, info in signatures.items():\n",
    "        print(f\"   [{sig_id}] {info['name']}: {info['count']} fois (S√©v√©rit√©: {info['severity']})\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test avec une IP de test\n",
    "# R√©cup√©rer d'abord quelques alertes pour obtenir une IP de test\n",
    "test_query = {\n",
    "    \"bool\": {\n",
    "        \"must\": [\n",
    "            {\"term\": {\"event_type\": \"alert\"}}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "test_result = es.search(index=index_name, query=test_query, size=1)\n",
    "\n",
    "if test_result['hits']['total']['value'] > 0:\n",
    "    test_ip = test_result['hits']['hits'][0]['_source'].get('src_ip')\n",
    "    if test_ip:\n",
    "        print(f\"\\nüß™ Test avec l'IP: {test_ip}\\n\")\n",
    "        search_alerts_by_ip(test_ip)\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  Aucune IP source trouv√©e dans les alertes\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Aucune alerte trouv√©e pour le test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.719112Z",
     "iopub.status.busy": "2026-01-17T14:32:41.718858Z",
     "iopub.status.idle": "2026-01-17T14:32:41.749304Z",
     "shell.execute_reply": "2026-01-17T14:32:41.747809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üö® Requ√™tes HTTP suspectes trouv√©es: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EXERCICE 2 : Analyse de trafic HTTP suspect\n",
    "# Recherchez les requ√™tes HTTP suspectes\n",
    "\n",
    "def find_suspicious_http_requests():\n",
    "    \"\"\"Recherche les requ√™tes HTTP suspectes\"\"\"\n",
    "    \n",
    "    # URLs suspectes communes\n",
    "    suspicious_paths = [\"/admin\", \"/wp-admin\", \"/phpmyadmin\", \"/.env\", \"/config.php\"]\n",
    "    \n",
    "    query = {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\"term\": {\"event_type\": \"http\"}}\n",
    "            ],\n",
    "            \"should\": [\n",
    "                {\"wildcard\": {\"http.url\": f\"*{path}*\"}} for path in suspicious_paths\n",
    "            ],\n",
    "            \"minimum_should_match\": 1\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result = es.search(index=index_name, query=query, size=100)\n",
    "    \n",
    "    print(f\"üö® Requ√™tes HTTP suspectes trouv√©es: {result['hits']['total']['value']}\\n\")\n",
    "    \n",
    "    for hit in result['hits']['hits']:\n",
    "        source = hit['_source']\n",
    "        http = source.get('http', {})\n",
    "        print(f\"‚ö†Ô∏è  {source.get('src_ip', 'N/A')} ‚Üí {http.get('hostname', 'N/A')}{http.get('url', 'N/A')}\")\n",
    "        print(f\"   M√©thode: {http.get('http_method', 'N/A')}, Status: {http.get('status', 'N/A')}\")\n",
    "        print()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Ex√©cuter la recherche\n",
    "try:\n",
    "    find_suspicious_http_requests()\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur: {e}\")\n",
    "    print(\"   V√©rifiez que vous avez des √©v√©nements HTTP dans vos logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 8 : R√©sum√© et bonnes pratiques\n",
    "\n",
    "### Bonnes pratiques pour un SIEM\n",
    "\n",
    "1. **Indexation optimale**\n",
    "   - Utilisez des index avec rotation temporelle (ex: `suricata-YYYY.MM.DD`)\n",
    "   - Configurez des index templates pour automatiser la cr√©ation\n",
    "   - D√©finissez des politiques de r√©tention (ILM - Index Lifecycle Management)\n",
    "\n",
    "2. **Mapping des champs**\n",
    "   - D√©finissez correctement les types de champs (IP, date, keyword, text)\n",
    "   - Utilisez des champs `keyword` pour les agr√©gations\n",
    "   - Utilisez des champs `text` pour la recherche full-text\n",
    "\n",
    "3. **S√©curit√©**\n",
    "   - Activez la s√©curit√© Elasticsearch en production\n",
    "   - Utilisez des certificats SSL/TLS\n",
    "   - Configurez des r√¥les et permissions appropri√©s\n",
    "\n",
    "4. **Performance**\n",
    "   - Monitorer la sant√© du cluster\n",
    "   - Ajuster le nombre de shards selon le volume de donn√©es\n",
    "   - Utiliser des alias pour les index\n",
    "\n",
    "5. **Alerting**\n",
    "   - Cr√©ez des r√®gles d'alerte pertinentes (pas trop, pas trop peu)\n",
    "   - Testez r√©guli√®rement les alertes\n",
    "   - Documentez les proc√©dures de r√©ponse aux incidents\n",
    "\n",
    "6. **Maintenance**\n",
    "   - Surveillez les logs Elasticsearch et Kibana\n",
    "   - Effectuez des sauvegardes r√©guli√®res\n",
    "   - Mettez √† jour r√©guli√®rement les r√®gles Suricata\n",
    "\n",
    "### Ressources suppl√©mentaires\n",
    "\n",
    "- **Documentation Suricata** : https://suricata.readthedocs.io/\n",
    "- **Documentation Filebeat** : https://www.elastic.co/guide/en/beats/filebeat/current/index.html\n",
    "- **Documentation Elasticsearch** : https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html\n",
    "- **Documentation Kibana** : https://www.elastic.co/guide/en/kibana/current/index.html\n",
    "- **Elastic Security** : https://www.elastic.co/security\n",
    "\n",
    "### Prochaines √©tapes\n",
    "\n",
    "1. Int√©grer d'autres sources de logs (Apache, Nginx, Windows Event Logs, etc.)\n",
    "2. Configurer des enrichissements (g√©olocalisation IP, threat intelligence)\n",
    "3. Cr√©er des playbooks de r√©ponse aux incidents\n",
    "4. Mettre en place une stack compl√®te avec Logstash si n√©cessaire\n",
    "5. Explorer Elastic Security (anciennement SIEM) pour des fonctionnalit√©s avanc√©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.752219Z",
     "iopub.status.busy": "2026-01-17T14:32:41.751975Z",
     "iopub.status.idle": "2026-01-17T14:32:41.758080Z",
     "shell.execute_reply": "2026-01-17T14:32:41.756502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úÖ TD termin√©!\n",
      "============================================================\n",
      "\n",
      "üìö N'oubliez pas de:\n",
      "   1. Explorer Kibana pour cr√©er vos visualisations\n",
      "   2. Configurer des alertes dans Kibana\n",
      "   3. Tester avec de vrais logs Suricata\n",
      "   4. Documenter vos r√®gles et proc√©dures\n",
      "\n",
      "üéì Bonne continuation avec votre SIEM!\n"
     ]
    }
   ],
   "source": [
    "# Fonction utilitaire : Nettoyage des ressources\n",
    "def cleanup():\n",
    "    \"\"\"Supprime l'index de test (optionnel)\"\"\"\n",
    "    response = input(\"Voulez-vous supprimer l'index 'suricata-logs'? (oui/non): \")\n",
    "    if response.lower() in ['oui', 'o', 'yes', 'y']:\n",
    "        if es.indices.exists(index=index_name):\n",
    "            es.indices.delete(index=index_name)\n",
    "            print(f\"‚úÖ Index '{index_name}' supprim√©\")\n",
    "        else:\n",
    "            print(f\"‚ÑπÔ∏è  L'index '{index_name}' n'existe pas\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è  Index conserv√©\")\n",
    "\n",
    "# D√©commenter pour nettoyer\n",
    "# cleanup()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ TD termin√©!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìö N'oubliez pas de:\")\n",
    "print(\"   1. Explorer Kibana pour cr√©er vos visualisations\")\n",
    "print(\"   2. Configurer des alertes dans Kibana\")\n",
    "print(\"   3. Tester avec de vrais logs Suricata\")\n",
    "print(\"   4. Documenter vos r√®gles et proc√©dures\")\n",
    "print(\"\\nüéì Bonne continuation avec votre SIEM!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
