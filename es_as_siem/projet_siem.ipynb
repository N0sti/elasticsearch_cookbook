{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet SIEM : Suricata, Filebeat, Elasticsearch\n",
    "\n",
    "## Objectifs\n",
    "\n",
    "Ce projet vous permettra de :\n",
    "- VÃ©rifier le bon fonctionnement de la stack SIEM\n",
    "- Analyser les donnÃ©es indexÃ©es par Filebeat (Suricata)\n",
    "- DÃ©tecter des anomalies sans ML\n",
    "- DÃ©tecter des anomalies avec ML (Isolation Forest)\n",
    "\n",
    "## ModalitÃ©\n",
    "- groupe de 3 Ã  4\n",
    "- output : projet git avec ce notebook dÃ©taillÃ© et complÃ©tÃ©\n",
    "\n",
    "## Architecture SIEM\n",
    "\n",
    "```\n",
    "Suricata   â†’   Filebeat   â†’   Elasticsearch   â†’   Kibana\n",
    "(IDS/HIDS)   (Collecteur)      (Stockage)   (Visualisation/Alerting)\n",
    "```\n",
    "\n",
    "## PrÃ©requis\n",
    "\n",
    "1. DÃ©marrer la stack :\n",
    "```bash\n",
    "docker-compose -f docker-compose-siem.yml up -d\n",
    "```\n",
    "\n",
    "2. Attendre quelques minutes que Suricata gÃ©nÃ¨re des logs et que Filebeat les indexe dans Elasticsearch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Cluster Elasticsearch: yellow (1 nÅ“uds)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mel/Documents/JULIE-DATA/projet_data_bis/elasticsearch_cookbook/.venv/lib/python3.12/site-packages/elasticsearch/_sync/client/__init__.py:313: SecurityWarning: Connecting to 'https://localhost:9200' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n"
     ]
    }
   ],
   "source": [
    "# Configuration et connexion Ã  Elasticsearch\n",
    "from elasticsearch import Elasticsearch\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import subprocess\n",
    "import os\n",
    "import warnings\n",
    "from urllib3.exceptions import InsecureRequestWarning\n",
    "\n",
    "warnings.simplefilter(\"ignore\", InsecureRequestWarning)\n",
    "# Configuration\n",
    "ES_HOST = \"https://localhost:9200\"\n",
    "ES_USER = \"elastic\"\n",
    "ES_PASSWORD = \"changeme\"  # Modifiez selon votre .env\n",
    "\n",
    "# Connexion\n",
    "es = Elasticsearch(\n",
    "    [ES_HOST],\n",
    "    basic_auth=(ES_USER, ES_PASSWORD),\n",
    "    verify_certs=False\n",
    ")\n",
    "\n",
    "# VÃ©rification de la connexion\n",
    "health = es.cluster.health()\n",
    "print(f\"âœ… Cluster Elasticsearch: {health['status']} ({health['number_of_nodes']} nÅ“uds)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. VÃ©rification de la stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ es01\n",
      "âŒ es02\n",
      "âŒ es03\n",
      "âŒ kibana\n",
      "âŒ suricata\n",
      "âŒ filebeat\n",
      "\n",
      "âš ï¸  Services dÃ©marrÃ©s: 0/6\n"
     ]
    }
   ],
   "source": [
    "# VÃ©rification des services Docker\n",
    "services = ['es01', 'es02', 'es03', 'kibana', 'suricata', 'filebeat']\n",
    "running = []\n",
    "\n",
    "for service in services:\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['docker', 'ps', '--filter', f'name={service}', '--format', '{{.Names}}'],\n",
    "            capture_output=True, text=True, timeout=5\n",
    "        )\n",
    "        if service in result.stdout:\n",
    "            running.append(service)\n",
    "            print(f\"âœ… {service}\")\n",
    "        else:\n",
    "            print(f\"âŒ {service}\")\n",
    "    except:\n",
    "        print(f\"âŒ {service}\")\n",
    "\n",
    "if len(running) == len(services):\n",
    "    print(f\"\\nâœ… Tous les services sont dÃ©marrÃ©s ({len(running)}/{len(services)})\")\n",
    "else:\n",
    "    print(f\"\\nâš ï¸  Services dÃ©marrÃ©s: {len(running)}/{len(services)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. VÃ©rification de l'injection des donnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Erreur: name 'es' is not defined\n"
     ]
    }
   ],
   "source": [
    "# Recherche des index Suricata\n",
    "def get_suricata_index():\n",
    "    \"\"\"Retourne le nom de l'index Suricata le plus rÃ©cent\"\"\"\n",
    "    try:\n",
    "        indices = es.indices.get(index=\"suricata-*\")\n",
    "        if indices:\n",
    "            return sorted(indices.keys())[-1]\n",
    "    except:\n",
    "        pass\n",
    "    return \"suricata-*\"\n",
    "\n",
    "index_name = get_suricata_index()\n",
    "\n",
    "# Comptage des documents\n",
    "try:\n",
    "    count = es.count(index=index_name)\n",
    "    print(f\"ğŸ“Š Index: {index_name}\")\n",
    "    print(f\"ğŸ“ˆ Nombre de documents: {count['count']:,}\")\n",
    "    \n",
    "    # Exemple de document\n",
    "    if count['count'] > 0:\n",
    "        sample = es.search(index=index_name, size=1, query={\"match_all\": {}})\n",
    "        if sample['hits']['hits']:\n",
    "            doc = sample['hits']['hits'][0]['_source']\n",
    "            print(f\"\\nğŸ“„ Exemple de document:\")\n",
    "            print(f\"   Type: {doc.get('event_type', 'N/A')}\")\n",
    "            print(f\"   Timestamp: {doc.get('@timestamp', doc.get('timestamp', 'N/A'))}\")\n",
    "            if 'src_ip' in doc:\n",
    "                print(f\"   Source: {doc.get('src_ip')}:{doc.get('src_port', 'N/A')}\")\n",
    "                print(f\"   Destination: {doc.get('dest_ip')}:{doc.get('dest_port', 'N/A')}\")\n",
    "            if 'alert' in doc:\n",
    "                alert = doc['alert']\n",
    "                print(f\"   Alerte: {alert.get('signature', 'N/A')}\")\n",
    "                print(f\"   SÃ©vÃ©ritÃ©: {alert.get('severity', 'N/A')}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Simuler des comportements anormaux\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installation des rÃ¨gles de dÃ©tections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ CrÃ©ation des rÃ¨gles de dÃ©tection spÃ©cifiques...\n",
      "\n",
      "âœ“ Fichier copiÃ© dans le container\n",
      "âœ“ Contenu vÃ©rifiÃ© : 1036 caractÃ¨res\n",
      "\n",
      "âœ“ suricata.rules dÃ©jÃ  prÃ©sent\n",
      "ğŸ”„ RedÃ©marrage de Suricata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "no such service: suricata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Attente du redÃ©marrage (8 secondes)...\n",
      "âœ… Configuration terminÃ©e !\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸ“ CrÃ©ation des rÃ¨gles de dÃ©tection spÃ©cifiques...\\n\")\n",
    "\n",
    "rules_content = \"\"\"# Test basique\n",
    "alert http any any -> any any (msg:\"HTTP Traffic\"; sid:1000001; rev:1;)\n",
    "\n",
    "# SQL Injection\n",
    "alert http any any -> any any (msg:\"SQL Injection\"; content:\"' OR '1'='1\"; nocase; sid:1000002; rev:1;)\n",
    "\n",
    "# XSS\n",
    "alert http any any -> any any (msg:\"XSS Attack\"; content:\"<script>\"; nocase; sid:1000003; rev:1;)\n",
    "\n",
    "# User-Agent suspect\n",
    "alert http any any -> any any (msg:\"SQLMap Tool\"; content:\"User-Agent: sqlmap\"; nocase; sid:1000004; rev:1;)\n",
    "\n",
    "# Test IDS\n",
    "alert http any any -> any any (msg:\"IDS Test\"; content:\"uid=0|28|root|29|\"; sid:2100498; rev:7;)\n",
    "\n",
    "# Port Scan\n",
    "alert tcp any any -> any any (msg:\"PORT SCAN DETECTED\"; flags:S; threshold:type both, track by_src, count 10, seconds 10; sid:5000001; rev:1;)\n",
    "\n",
    "# HTTP Burst\n",
    "alert http any any -> any any (msg:\"HTTP BURST DETECTED\"; threshold:type both, track by_src, count 15, seconds 2; sid:5000002; rev:1;)\n",
    "\n",
    "# Brute Force\n",
    "alert http any any -> any any (msg:\"BRUTE FORCE DETECTED\"; content:\"pass=\"; http_uri; threshold:type both, track by_src, count 6, seconds 10; sid:5000003; rev:1;)\n",
    "\"\"\"\n",
    "\n",
    "# 1ï¸âƒ£ CrÃ©er fichier local\n",
    "local_path = Path(\"suricata.rules\")\n",
    "local_path.write_text(rules_content)\n",
    "\n",
    "# 2ï¸âƒ£ Copier dans le container\n",
    "subprocess.run(\"docker cp suricata.rules suricata:/var/lib/suricata/rules/suricata.rules\", shell=True)\n",
    "\n",
    "print(\"âœ“ Fichier copiÃ© dans le container\")\n",
    "\n",
    "# 3ï¸âƒ£ VÃ©rifier\n",
    "result = subprocess.run(\n",
    "    \"docker exec suricata cat /var/lib/suricata/rules/suricata.rules\",\n",
    "    shell=True,\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "print(f\"âœ“ Contenu vÃ©rifiÃ© : {len(result.stdout)} caractÃ¨res\\n\")\n",
    "\n",
    "# 4ï¸âƒ£ Ajouter dans suricata.yaml si nÃ©cessaire\n",
    "check = subprocess.run(\n",
    "    'docker exec suricata grep -q \"suricata.rules\" /etc/suricata/suricata.yaml',\n",
    "    shell=True\n",
    ")\n",
    "\n",
    "if check.returncode != 0:\n",
    "    print(\"Ajout de suricata.rules dans suricata.yaml...\")\n",
    "    subprocess.run(\n",
    "        'docker exec suricata sed -i \"/rule-files:/a\\\\  - suricata.rules\" /etc/suricata/suricata.yaml',\n",
    "        shell=True\n",
    "    )\n",
    "    print(\"âœ“ suricata.rules ajoutÃ© Ã  suricata.yaml\")\n",
    "else:\n",
    "    print(\"âœ“ suricata.rules dÃ©jÃ  prÃ©sent\")\n",
    "\n",
    "# 5ï¸âƒ£ RedÃ©marrage\n",
    "print(\"ğŸ”„ RedÃ©marrage de Suricata...\")\n",
    "subprocess.run(\"docker-compose restart suricata\", shell=True)\n",
    "\n",
    "print(\"â³ Attente du redÃ©marrage (8 secondes)...\")\n",
    "time.sleep(8)\n",
    "\n",
    "print(\"âœ… Configuration terminÃ©e !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation de scans suspects (en ligne de commande ou en python) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ATTAQUE 1 : PORT SCAN\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ Objectif : DÃ©clencher 'PORT SCAN DETECTED'\n",
      "   RÃ¨gle : 10 paquets TCP SYN en 10 secondes\n",
      "\n",
      "ğŸ¯ Cible : scanme.nmap.org\n",
      "ğŸ“¡ Scan de 12 ports...\n",
      "\n",
      "  [ 1/12] Port    21 - SYN envoyÃ©\n",
      "  [ 2/12] Port    22 - SYN envoyÃ©\n",
      "  [ 3/12] Port    23 - SYN envoyÃ©\n",
      "  [ 4/12] Port    25 - SYN envoyÃ©\n",
      "  [ 5/12] Port    53 - SYN envoyÃ©\n",
      "  [ 6/12] Port    80 - SYN envoyÃ©\n",
      "  [ 7/12] Port   110 - SYN envoyÃ©\n",
      "  [ 8/12] Port   143 - SYN envoyÃ©\n",
      "  [ 9/12] Port   443 - SYN envoyÃ©\n",
      "  [10/12] Port  3306 - SYN envoyÃ©\n",
      "  [11/12] Port  3389 - SYN envoyÃ©\n",
      "  [12/12] Port  8080 - SYN envoyÃ©\n",
      "\n",
      "âœ… 12 paquets TCP SYN en 7.2 secondes\n",
      "   Seuil : 10 paquets en 10s â†’ 12 en 7.2s\n",
      "\n",
      "âš ï¸  Devrait dÃ©clencher : PORT SCAN DETECTED\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "ATTAQUE - PORT SCAN\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "Envoie 12 paquets TCP SYN en moins de 10 secondes\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(\"ğŸ” ATTAQUE 1 : PORT SCAN\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nğŸ“‹ Objectif : DÃ©clencher 'PORT SCAN DETECTED'\")\n",
    "print(\"   RÃ¨gle : 10 paquets TCP SYN en 10 secondes\\n\")\n",
    "\n",
    "target = \"scanme.nmap.org\"\n",
    "ports = [21, 22, 23, 25, 53, 80, 110, 143, 443, 3306, 3389, 8080]\n",
    "\n",
    "print(f\"ğŸ¯ Cible : {target}\")\n",
    "print(f\"ğŸ“¡ Scan de {len(ports)} ports...\\n\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i, port in enumerate(ports, 1):\n",
    "    subprocess.run(\n",
    "        [\"docker\", \"exec\", \"suricata\", \"timeout\", \"0.1\", \"telnet\", target, str(port)],\n",
    "        stdout=subprocess.DEVNULL,\n",
    "        stderr=subprocess.DEVNULL\n",
    "    )\n",
    "    \n",
    "    print(f\"  [{i:2d}/12] Port {port:5d} - SYN envoyÃ©\")\n",
    "    time.sleep(0.5)\n",
    "\n",
    "duration = time.time() - start\n",
    "\n",
    "print(f\"\\nâœ… {len(ports)} paquets TCP SYN en {duration:.1f} secondes\")\n",
    "print(f\"   Seuil : 10 paquets en 10s â†’ {len(ports)} en {duration:.1f}s\")\n",
    "print(\"\\nâš ï¸  Devrait dÃ©clencher : PORT SCAN DETECTED\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation de burst HTTP en ligne de commande (en ligne de commande ou en python) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¥ ATTAQUE 2 : HTTP BURST\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ Objectif : DÃ©clencher 'HTTP BURST DETECTED'\n",
      "   RÃ¨gle : 15 requÃªtes HTTP en 2 secondes\n",
      "\n",
      "ğŸ¯ Cible : http://example.com\n",
      "ğŸŒŠ Envoi de 20 requÃªtes HTTP...\n",
      "\n",
      "  [ 5/20] RequÃªtes envoyÃ©es\n",
      "  [10/20] RequÃªtes envoyÃ©es\n",
      "  [15/20] RequÃªtes envoyÃ©es\n",
      "  [20/20] RequÃªtes envoyÃ©es\n",
      "\n",
      "âœ… 20 requÃªtes HTTP en 4.52 secondes\n",
      "   Taux : 4.4 requÃªtes/seconde\n",
      "   Seuil : 15 requÃªtes en 2s â†’ 20 en 4.52s\n",
      "\n",
      "âš ï¸  Devrait dÃ©clencher : HTTP BURST DETECTED\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "ATTAQUE - HTTP BURST\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "Envoie 20 requÃªtes HTTP en 1.5 secondes\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(\"ğŸ’¥ ATTAQUE 2 : HTTP BURST\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nğŸ“‹ Objectif : DÃ©clencher 'HTTP BURST DETECTED'\")\n",
    "print(\"   RÃ¨gle : 15 requÃªtes HTTP en 2 secondes\\n\")\n",
    "\n",
    "target = \"http://example.com\"\n",
    "num_requests = 20  # Plus que le seuil de 15\n",
    "\n",
    "print(f\"ğŸ¯ Cible : {target}\")\n",
    "print(f\"ğŸŒŠ Envoi de {num_requests} requÃªtes HTTP...\\n\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(1, num_requests + 1):\n",
    "    subprocess.run(\n",
    "        f'docker exec suricata curl -s {target}',\n",
    "        shell=True,\n",
    "        capture_output=True,\n",
    "        timeout=1\n",
    "    )\n",
    "    \n",
    "    if i % 5 == 0:\n",
    "        print(f\"  [{i:2d}/20] RequÃªtes envoyÃ©es\")\n",
    "    \n",
    "    time.sleep(0.07)  # 70ms entre chaque = ~14 req/sec\n",
    "\n",
    "duration = time.time() - start\n",
    "\n",
    "print(f\"\\nâœ… {num_requests} requÃªtes HTTP en {duration:.2f} secondes\")\n",
    "print(f\"   Taux : {num_requests/duration:.1f} requÃªtes/seconde\")\n",
    "print(f\"   Seuil : 15 requÃªtes en 2s â†’ {num_requests} en {duration:.2f}s\")\n",
    "print(f\"\\nâš ï¸  Devrait dÃ©clencher : HTTP BURST DETECTED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simulation de brute force"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” ATTAQUE 3 : BRUTE FORCE\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ Objectif : DÃ©clencher 'BRUTE FORCE DETECTED'\n",
      "   RÃ¨gle : 6 requÃªtes avec 'pass=' dans l'URI en 10 secondes\n",
      "\n",
      "ğŸ”“ Tentatives de connexion avec 8 mots de passe...\n",
      "\n",
      "  [1/8] Tentative avec pass=admin\n",
      "  [2/8] Tentative avec pass=password\n",
      "  [3/8] Tentative avec pass=123456\n",
      "  [4/8] Tentative avec pass=qwerty\n",
      "  [5/8] Tentative avec pass=letmein\n",
      "  [6/8] Tentative avec pass=admin123\n",
      "  [7/8] Tentative avec pass=root\n",
      "  [8/8] Tentative avec pass=toor\n",
      "\n",
      "âœ… 8 tentatives avec 'pass=' dans l'URI\n",
      "   DurÃ©e : 7.4 secondes\n",
      "   Seuil : 6 requÃªtes en 10s â†’ 8 en 7.4s\n",
      "\n",
      "âš ï¸  Devrait dÃ©clencher : BRUTE FORCE DETECTED\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "ATTAQUE - BRUTE FORCE\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "Envoie 8 requÃªtes avec \"pass=\" dans l'URI en moins de 10 secondes\n",
    "\"\"\"\n",
    "\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(\"ğŸ” ATTAQUE 3 : BRUTE FORCE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nğŸ“‹ Objectif : DÃ©clencher 'BRUTE FORCE DETECTED'\")\n",
    "print(\"   RÃ¨gle : 6 requÃªtes avec 'pass=' dans l'URI en 10 secondes\\n\")\n",
    "\n",
    "passwords = [\n",
    "    \"admin\",\n",
    "    \"password\",\n",
    "    \"123456\",\n",
    "    \"qwerty\",\n",
    "    \"letmein\",\n",
    "    \"admin123\",\n",
    "    \"root\",\n",
    "    \"toor\"\n",
    "]\n",
    "\n",
    "print(f\"ğŸ”“ Tentatives de connexion avec {len(passwords)} mots de passe...\\n\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i, pwd in enumerate(passwords, 1):\n",
    "    # IMPORTANT : \"pass=\" doit Ãªtre dans l'URI\n",
    "    url = f\"http://example.com/login?user=admin&pass={pwd}\"\n",
    "    \n",
    "    subprocess.run(\n",
    "        f'docker exec suricata curl -s \"{url}\"',\n",
    "        shell=True,\n",
    "        capture_output=True,\n",
    "        timeout=2\n",
    "    )\n",
    "    \n",
    "    print(f\"  [{i}/8] Tentative avec pass={pwd}\")\n",
    "    time.sleep(0.8)  # 0.8s entre chaque = 8 en ~6.4 secondes\n",
    "\n",
    "duration = time.time() - start\n",
    "\n",
    "print(f\"\\nâœ… {len(passwords)} tentatives avec 'pass=' dans l'URI\")\n",
    "print(f\"   DurÃ©e : {duration:.1f} secondes\")\n",
    "print(f\"   Seuil : 6 requÃªtes en 10s â†’ {len(passwords)} en {duration:.1f}s\")\n",
    "print(f\"\\nâš ï¸  Devrait dÃ©clencher : BRUTE FORCE DETECTED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’‰ ATTAQUE 1 : SQL INJECTION\n",
      "[1/5] Payload : '1\n",
      "[2/5] Payload : '1\n",
      "[3/5] Payload : '1\n",
      "[4/5] Payload : '1 --\n",
      "[5/5] Payload : '1\n",
      "âœ… SQL Injection envoyÃ©e\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(\"ğŸ’‰ ATTAQUE 1 : SQL INJECTION\")\n",
    "\n",
    "sql_payloads = [\n",
    "    \"http://example.com/login?user=admin&pass=' OR '1'='1\",\n",
    "    \"http://example.com/search?q=' OR '1'='1\",\n",
    "    \"http://example.com/page?id=1' OR '1'='1\",\n",
    "    \"http://example.com/api?filter=' OR '1'='1 --\",\n",
    "    \"http://example.com/data?name=test' OR '1'='1\",\n",
    "]\n",
    "\n",
    "for i, url in enumerate(sql_payloads, 1):\n",
    "    subprocess.run(\n",
    "        f'docker exec suricata curl -s \"{url}\"',\n",
    "        shell=True,\n",
    "        capture_output=True,\n",
    "        timeout=2\n",
    "    )\n",
    "    payload = url.split('=')[-1]\n",
    "    print(f\"[{i}/5] Payload : {payload}\")\n",
    "    time.sleep(0.3)\n",
    "\n",
    "print(\"âœ… SQL Injection envoyÃ©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XSS injection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ ATTAQUE 2 : XSS\n",
      "[1/4] Payload : <script>alert('XSS')</script>...\n",
      "[2/4] Payload : <script>alert(1)</script>...\n",
      "[3/4] Payload : <script>document.cookie</script>...\n",
      "[4/4] Payload : <script>alert('hack')</script>...\n",
      "âœ… XSS envoyÃ©e\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import time\n",
    "\n",
    "print(\"ğŸ¯ ATTAQUE 2 : XSS\")\n",
    "\n",
    "xss_payloads = [\n",
    "    \"http://example.com/search?q=<script>alert('XSS')</script>\",\n",
    "    \"http://example.com/comment?text=<script>alert(1)</script>\",\n",
    "    \"http://example.com/post?content=<script>document.cookie</script>\",\n",
    "    \"http://example.com/input?data=<script>alert('hack')</script>\",\n",
    "]\n",
    "\n",
    "for i, url in enumerate(xss_payloads, 1):\n",
    "    subprocess.run(\n",
    "        f'docker exec suricata curl -s \"{url}\"',\n",
    "        shell=True,\n",
    "        capture_output=True,\n",
    "        timeout=2\n",
    "    )\n",
    "    payload = url.split('=', 1)[-1]\n",
    "    print(f\"[{i}/4] Payload : {payload[:40]}...\")\n",
    "    time.sleep(0.3)\n",
    "\n",
    "print(\"âœ… XSS envoyÃ©e\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. DÃ©tection d'anomalies sans ML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DÃ©tÃ©ctions et clasifications des attaques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif est de construire des rÃ¨gles qui dÃ©tectent vos simulations de comportements prÃ©cÃ©dents.\n",
    "\n",
    "Un exemple de dÃ©tection d'anomalies basiques basÃ©es sur des rÃ¨gles:     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” DÃ‰TECTION ET CLASSIFICATION DES ATTAQUES\n",
      "==================================================\n",
      "\n",
      "ğŸ“Š Total d'alertes : 352\n",
      "\n",
      "==================================================\n",
      "ğŸ¯ CLASSIFICATION DES ATTAQUES DÃ‰TECTÃ‰ES\n",
      "==================================================\n",
      "\n",
      "ğŸ” SCAN DE PORTS : 2 alertes\n",
      "   CaractÃ©ristiques :\n",
      "   â€¢ Multiples connexions TCP SYN vers diffÃ©rents ports\n",
      "   â€¢ Comportement typique d'un scanner (nmap, masscan)\n",
      "   â€¢ IPs sources dÃ©tectÃ©es : 1\n",
      "     - 172.18.0.2\n",
      "\n",
      "ğŸ’¥ HTTP BURST (FLOOD) : 10 alertes\n",
      "   CaractÃ©ristiques :\n",
      "   â€¢ Volume anormalement Ã©levÃ© de requÃªtes HTTP\n",
      "   â€¢ Peut indiquer un DDoS ou un stress test\n",
      "   â€¢ IPs sources : 3\n",
      "   â€¢ Cibles : 3\n",
      "     - 104.18.26.120\n",
      "     - 172.18.0.2\n",
      "     - 104.18.27.120\n",
      "\n",
      "ğŸ” BRUTE FORCE : 1 alertes\n",
      "   CaractÃ©ristiques :\n",
      "   â€¢ Tentatives rÃ©pÃ©tÃ©es de connexion\n",
      "   â€¢ RequÃªtes vers /login, /admin, /auth\n",
      "   â€¢ Comportement typique de credential stuffing\n",
      "   â€¢ IPs sources suspectes : 1\n",
      "     - 172.18.0.2 : 1 tentatives\n",
      "\n",
      "ğŸ“Œ AUTRES ALERTES : 339 alertes\n",
      "\n",
      "==================================================\n",
      "ğŸ“‹ RÃ‰SUMÃ‰ DES MENACES DÃ‰TECTÃ‰ES\n",
      "==================================================\n",
      "\n",
      "âœ… 13 menaces identifiÃ©es et classifiÃ©es :\n",
      "   â€¢ 2 tentatives de scan de ports\n",
      "   â€¢ 10 attaques par flood HTTP\n",
      "   â€¢ 1 tentatives de brute force\n",
      "============================================================\n",
      "ğŸ¯ EXPORT DES ALERTES IDENTIFIÃ‰ES\n",
      "============================================================\n",
      "\n",
      "âœ… 13 alertes exportÃ©es dans : detected_attacks.json\n",
      "\n",
      "DÃ©tail :\n",
      "   â€¢ Port Scan : 2\n",
      "   â€¢ HTTP Burst : 10\n",
      "   â€¢ Brute Force : 1\n",
      "\n",
      "ğŸ“ TerminÃ©.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import subprocess\n",
    "from collections import defaultdict\n",
    "\n",
    "# Fichier de sortie ou l'on stoker les alertes classifiÃ©s\n",
    "output_file = \"detected_attacks.json\" \n",
    "\n",
    "print(\"ğŸ” DÃ‰TECTION ET CLASSIFICATION DES ATTAQUES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Charger les logs\n",
    "result = subprocess.run(\n",
    "    [\"docker\", \"exec\", \"suricata\", \"cat\", \"/var/log/suricata/eve.json\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "logs = [json.loads(line) for line in result.stdout.splitlines()]\n",
    "alerts = [log for log in logs if log.get(\"event_type\") == \"alert\"]\n",
    "\n",
    "print(f\"\\nğŸ“Š Total d'alertes : {len(alerts)}\\n\")\n",
    "\n",
    "# Classification des attaques\n",
    "attack_types = {\n",
    "    \"port_scan\": [],\n",
    "    \"http_burst\": [],\n",
    "    \"brute_force\": [],\n",
    "    \"other\": []\n",
    "}\n",
    "\n",
    "for alert in alerts:\n",
    "    signature = alert.get(\"alert\", {}).get(\"signature\", \"\")\n",
    "    \n",
    "    if \"PORT SCAN\" in signature:\n",
    "        attack_types[\"port_scan\"].append(alert)\n",
    "    elif \"HTTP BURST\" in signature:\n",
    "        attack_types[\"http_burst\"].append(alert)\n",
    "    elif \"BRUTE FORCE\" in signature:\n",
    "        attack_types[\"brute_force\"].append(alert)\n",
    "    else:\n",
    "        attack_types[\"other\"].append(alert)\n",
    "\n",
    "# Afficher les rÃ©sultats\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ¯ CLASSIFICATION DES ATTAQUES DÃ‰TECTÃ‰ES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Port Scan\n",
    "if attack_types[\"port_scan\"]:\n",
    "    print(f\"\\nğŸ” SCAN DE PORTS : {len(attack_types['port_scan'])} alertes\")\n",
    "    print(\"   CaractÃ©ristiques :\")\n",
    "    print(\"   â€¢ Multiples connexions TCP SYN vers diffÃ©rents ports\")\n",
    "    print(\"   â€¢ Comportement typique d'un scanner (nmap, masscan)\")\n",
    "    \n",
    "    # Analyser les dÃ©tails\n",
    "    sources = set([a.get(\"src_ip\") for a in attack_types[\"port_scan\"]])\n",
    "    print(f\"   â€¢ IPs sources dÃ©tectÃ©es : {len(sources)}\")\n",
    "    for src in list(sources)[:3]:\n",
    "        print(f\"     - {src}\")\n",
    "\n",
    "# HTTP Burst\n",
    "if attack_types[\"http_burst\"]:\n",
    "    print(f\"\\nğŸ’¥ HTTP BURST (FLOOD) : {len(attack_types['http_burst'])} alertes\")\n",
    "    print(\"   CaractÃ©ristiques :\")\n",
    "    print(\"   â€¢ Volume anormalement Ã©levÃ© de requÃªtes HTTP\")\n",
    "    print(\"   â€¢ Peut indiquer un DDoS ou un stress test\")\n",
    "    \n",
    "    # Analyser les dÃ©tails\n",
    "    sources = set([a.get(\"src_ip\") for a in attack_types[\"http_burst\"]])\n",
    "    destinations = set([a.get(\"dest_ip\") for a in attack_types[\"http_burst\"]])\n",
    "    print(f\"   â€¢ IPs sources : {len(sources)}\")\n",
    "    print(f\"   â€¢ Cibles : {len(destinations)}\")\n",
    "    for dst in list(destinations)[:3]:\n",
    "        print(f\"     - {dst}\")\n",
    "\n",
    "# Brute Force\n",
    "if attack_types[\"brute_force\"]:\n",
    "    print(f\"\\nğŸ” BRUTE FORCE : {len(attack_types['brute_force'])} alertes\")\n",
    "    print(\"   CaractÃ©ristiques :\")\n",
    "    print(\"   â€¢ Tentatives rÃ©pÃ©tÃ©es de connexion\")\n",
    "    print(\"   â€¢ RequÃªtes vers /login, /admin, /auth\")\n",
    "    print(\"   â€¢ Comportement typique de credential stuffing\")\n",
    "    \n",
    "    # Analyser les dÃ©tails\n",
    "    sources = set([a.get(\"src_ip\") for a in attack_types[\"brute_force\"]])\n",
    "    print(f\"   â€¢ IPs sources suspectes : {len(sources)}\")\n",
    "    for src in list(sources)[:3]:\n",
    "        count = len([a for a in attack_types[\"brute_force\"] if a.get(\"src_ip\") == src])\n",
    "        print(f\"     - {src} : {count} tentatives\")\n",
    "\n",
    "# Autres\n",
    "if attack_types[\"other\"]:\n",
    "    print(f\"\\nğŸ“Œ AUTRES ALERTES : {len(attack_types['other'])} alertes\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ“‹ RÃ‰SUMÃ‰ DES MENACES DÃ‰TECTÃ‰ES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "total_threats = sum([\n",
    "    len(attack_types[\"port_scan\"]),\n",
    "    len(attack_types[\"http_burst\"]),\n",
    "    len(attack_types[\"brute_force\"])\n",
    "])\n",
    "\n",
    "if total_threats > 0:\n",
    "    print(f\"\\nâœ… {total_threats} menaces identifiÃ©es et classifiÃ©es :\")\n",
    "    if attack_types[\"port_scan\"]:\n",
    "        print(f\"   â€¢ {len(attack_types['port_scan'])} tentatives de scan de ports\")\n",
    "    if attack_types[\"http_burst\"]:\n",
    "        print(f\"   â€¢ {len(attack_types['http_burst'])} attaques par flood HTTP\")\n",
    "    if attack_types[\"brute_force\"]:\n",
    "        print(f\"   â€¢ {len(attack_types['brute_force'])} tentatives de brute force\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸  Aucune menace spÃ©cifique dÃ©tectÃ©e\")\n",
    "    print(\"   VÃ©rifier que les rÃ¨gles sont bien chargÃ©es\")\n",
    "# Fusionner uniquement les attaques identifiÃ©es\n",
    "filtered_attacks = (\n",
    "    attack_types[\"port_scan\"] +\n",
    "    attack_types[\"http_burst\"] +\n",
    "    attack_types[\"brute_force\"]\n",
    ")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ¯ EXPORT DES ALERTES IDENTIFIÃ‰ES\")\n",
    "print(\"=\" * 60)\n",
    "if filtered_attacks:\n",
    "\n",
    "    # CrÃ©er le fichier sâ€™il nâ€™existe pas\n",
    "    mode = \"w\"  # Ã©crase l'ancien contenu (tu peux mettre \"a\" pour append)\n",
    "\n",
    "    with open(output_file, mode) as f:\n",
    "        for attack in filtered_attacks:\n",
    "            f.write(json.dumps(attack) + \"\\n\")\n",
    "\n",
    "    print(f\"\\nâœ… {len(filtered_attacks)} alertes exportÃ©es dans : {output_file}\")\n",
    "\n",
    "    print(\"\\nDÃ©tail :\")\n",
    "    print(f\"   â€¢ Port Scan : {len(attack_types['port_scan'])}\")\n",
    "    print(f\"   â€¢ HTTP Burst : {len(attack_types['http_burst'])}\")\n",
    "    print(f\"   â€¢ Brute Force : {len(attack_types['brute_force'])}\")\n",
    "\n",
    "else:\n",
    "    print(\"âš ï¸ Aucune attaque spÃ©cifique Ã  exporter.\")\n",
    "\n",
    "print(\"\\nğŸ“ TerminÃ©.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Affichage des 5 derniÃ¨res alertes gÃ©nÃ©rÃ©s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total : 352 alertes\n",
      "{'timestamp': '2026-02-15T16:49:46.366865+0000', 'src_ip': '104.18.26.120', 'dest_ip': '172.18.0.2', 'signature': 'HTTP Traffic'}\n",
      "{'timestamp': '2026-02-15T16:49:46.366894+0000', 'src_ip': '172.18.0.2', 'dest_ip': '104.18.26.120', 'signature': 'HTTP Traffic'}\n",
      "{'timestamp': '2026-02-15T16:49:46.367058+0000', 'src_ip': '172.18.0.2', 'dest_ip': '104.18.26.120', 'signature': 'HTTP Traffic'}\n",
      "{'timestamp': '2026-02-15T16:49:46.384037+0000', 'src_ip': '104.18.26.120', 'dest_ip': '172.18.0.2', 'signature': 'HTTP Traffic'}\n",
      "{'timestamp': '2026-02-15T16:49:46.384063+0000', 'src_ip': '172.18.0.2', 'dest_ip': '104.18.26.120', 'signature': 'HTTP Traffic'}\n",
      "{'timestamp': '2026-02-15T16:49:46.366865+0000', 'flow_id': 573360068869170, 'in_iface': 'eth0', 'event_type': 'alert', 'src_ip': '104.18.26.120', 'src_port': 80, 'dest_ip': '172.18.0.2', 'dest_port': 39816, 'proto': 'TCP', 'ip_v': 4, 'pkt_src': 'wire/pcap', 'alert': {'action': 'allowed', 'gid': 1, 'signature_id': 1000001, 'rev': 1, 'signature': 'HTTP Traffic', 'category': '', 'severity': 3}, 'app_proto': 'http', 'direction': 'to_client', 'flow': {'pkts_toserver': 4, 'pkts_toclient': 4, 'bytes_toserver': 388, 'bytes_toclient': 1034, 'start': '2026-02-15T16:49:46.330103+0000', 'src_ip': '172.18.0.2', 'dest_ip': '104.18.26.120', 'src_port': 39816, 'dest_port': 80}}\n",
      "{'timestamp': '2026-02-15T16:49:46.366894+0000', 'flow_id': 573360068869170, 'in_iface': 'eth0', 'event_type': 'alert', 'src_ip': '172.18.0.2', 'src_port': 39816, 'dest_ip': '104.18.26.120', 'dest_port': 80, 'proto': 'TCP', 'ip_v': 4, 'pkt_src': 'wire/pcap', 'alert': {'action': 'allowed', 'gid': 1, 'signature_id': 1000001, 'rev': 1, 'signature': 'HTTP Traffic', 'category': '', 'severity': 3}, 'app_proto': 'http', 'direction': 'to_server', 'flow': {'pkts_toserver': 5, 'pkts_toclient': 4, 'bytes_toserver': 454, 'bytes_toclient': 1034, 'start': '2026-02-15T16:49:46.330103+0000', 'src_ip': '172.18.0.2', 'dest_ip': '104.18.26.120', 'src_port': 39816, 'dest_port': 80}}\n",
      "{'timestamp': '2026-02-15T16:49:46.367058+0000', 'flow_id': 573360068869170, 'in_iface': 'eth0', 'event_type': 'alert', 'src_ip': '172.18.0.2', 'src_port': 39816, 'dest_ip': '104.18.26.120', 'dest_port': 80, 'proto': 'TCP', 'ip_v': 4, 'pkt_src': 'wire/pcap', 'alert': {'action': 'allowed', 'gid': 1, 'signature_id': 1000001, 'rev': 1, 'signature': 'HTTP Traffic', 'category': '', 'severity': 3}, 'app_proto': 'http', 'direction': 'to_server', 'flow': {'pkts_toserver': 6, 'pkts_toclient': 4, 'bytes_toserver': 520, 'bytes_toclient': 1034, 'start': '2026-02-15T16:49:46.330103+0000', 'src_ip': '172.18.0.2', 'dest_ip': '104.18.26.120', 'src_port': 39816, 'dest_port': 80}}\n",
      "{'timestamp': '2026-02-15T16:49:46.384037+0000', 'flow_id': 573360068869170, 'in_iface': 'eth0', 'event_type': 'alert', 'src_ip': '104.18.26.120', 'src_port': 80, 'dest_ip': '172.18.0.2', 'dest_port': 39816, 'proto': 'TCP', 'ip_v': 4, 'pkt_src': 'wire/pcap', 'alert': {'action': 'allowed', 'gid': 1, 'signature_id': 1000001, 'rev': 1, 'signature': 'HTTP Traffic', 'category': '', 'severity': 3}, 'app_proto': 'http', 'direction': 'to_client', 'flow': {'pkts_toserver': 6, 'pkts_toclient': 5, 'bytes_toserver': 520, 'bytes_toclient': 1100, 'start': '2026-02-15T16:49:46.330103+0000', 'src_ip': '172.18.0.2', 'dest_ip': '104.18.26.120', 'src_port': 39816, 'dest_port': 80}}\n",
      "{'timestamp': '2026-02-15T16:49:46.384063+0000', 'flow_id': 573360068869170, 'in_iface': 'eth0', 'event_type': 'alert', 'src_ip': '172.18.0.2', 'src_port': 39816, 'dest_ip': '104.18.26.120', 'dest_port': 80, 'proto': 'TCP', 'ip_v': 4, 'pkt_src': 'wire/pcap', 'alert': {'action': 'allowed', 'gid': 1, 'signature_id': 1000001, 'rev': 1, 'signature': 'HTTP Traffic', 'category': '', 'severity': 3}, 'app_proto': 'http', 'direction': 'to_server', 'flow': {'pkts_toserver': 7, 'pkts_toclient': 5, 'bytes_toserver': 586, 'bytes_toclient': 1100, 'start': '2026-02-15T16:49:46.330103+0000', 'src_ip': '172.18.0.2', 'dest_ip': '104.18.26.120', 'src_port': 39816, 'dest_port': 80}}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import subprocess\n",
    "\n",
    "# RÃ©cupÃ¨re le contenu du fichier eve.json depuis le conteneur\n",
    "result = subprocess.run(\n",
    "    [\"docker\", \"exec\", \"suricata\", \"cat\", \"/var/log/suricata/eve.json\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "# Chaque ligne du fichier est un JSON indÃ©pendant\n",
    "logs = [json.loads(line) for line in result.stdout.splitlines()]\n",
    "\n",
    "# Filtrer uniquement les alertes\n",
    "alerts = [log for log in logs if log.get(\"event_type\") == \"alert\"]\n",
    "\n",
    "print(f\"Total : {len(alerts)} alertes\")\n",
    "\n",
    "# Affiche les 5 derniÃ¨res alertes\n",
    "for alert in alerts[-5:]:\n",
    "    print({\n",
    "        \"timestamp\": alert.get(\"timestamp\"),\n",
    "        \"src_ip\": alert.get(\"src_ip\"),\n",
    "        \"dest_ip\": alert.get(\"dest_ip\"),\n",
    "        \"signature\": alert.get(\"alert\", {}).get(\"signature\")\n",
    "    })\n",
    "\n",
    "for alert in alerts[-5:]:\n",
    "    print(alert)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. DÃ©tection d'anomalies avec ML\n",
    "\n",
    "L'objectif est d'Ã  partir de donnÃ©es labelisÃ©es comme Ã©tant anomarles ou non, construire un jeu de donnÃ©e et entrainer un algorithme de machine learning (classifier binaire) sur ces donnÃ©es. Le modÃ¨le devra ensuite etre appelÃ© pour prÃ©dire les futurs comportements anormaux.\n",
    "\n",
    "Indice: le modÃ¨le Isolation Forest pourrait etre utile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š EXTRACTION DES DONNÃ‰ES DEPUIS EVE.JSON\n",
      "============================================================\n",
      "\n",
      "[1] Chargement des logs...\n",
      "âœ“ 3572 Ã©vÃ©nements chargÃ©s\n",
      "\n",
      "[2] Filtrage des Ã©vÃ©nements...\n",
      "âœ“ 70 flows\n",
      "âœ“ 352 alertes\n",
      "\n",
      "[3] Construction du dataset...\n",
      "âœ“ Dataset crÃ©Ã© : 70 lignes\n",
      "\n",
      "[4] Statistiques du dataset...\n",
      "\n",
      "ğŸ“Š RÃ©partition des classes :\n",
      "is_anomaly\n",
      "1    37\n",
      "0    33\n",
      "Name: count, dtype: int64\n",
      "\n",
      "   Normal   : 33 (47.1%)\n",
      "   Anomalie : 37 (52.9%)\n",
      "\n",
      "ğŸ“Š Types d'attaques :\n",
      "   â€¢ HTTP Traffic                   :   35\n",
      "   â€¢ PORT SCAN DETECTED             :    2\n",
      "\n",
      "[5] Ã‰chantillon des donnÃ©es...\n",
      "\n",
      "Normales (5 premiÃ¨res) :\n",
      "    pkts_toserver  bytes_toserver  dest_port  is_anomaly\n",
      "37              1              87       5353           0\n",
      "38              1             107       5353           0\n",
      "39              1             107       5353           0\n",
      "40              1              70          0           0\n",
      "41              1             107       5353           0\n",
      "\n",
      "Anomalies (5 premiÃ¨res) :\n",
      "   pkts_toserver  bytes_toserver  dest_port   attack_type\n",
      "0              7             545         80  HTTP Traffic\n",
      "1              8             611         80  HTTP Traffic\n",
      "2              7             545         80  HTTP Traffic\n",
      "3              7             545         80  HTTP Traffic\n",
      "4              8             611         80  HTTP Traffic\n",
      "\n",
      "============================================================\n",
      "âœ… DATASET PRÃŠT POUR L'ENTRAÃNEMENT\n",
      "============================================================\n",
      "\n",
      "ğŸ“‹ Features disponibles : 15 colonnes\n",
      "   Samples : 70\n",
      "   Features numÃ©riques : 14\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "CELLULE 1 : EXTRACTION ET PRÃ‰PARATION DES DONNÃ‰ES\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ“Š EXTRACTION DES DONNÃ‰ES DEPUIS EVE.JSON\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Charger les logs depuis Suricata\n",
    "print(\"\\n[1] Chargement des logs...\")\n",
    "result = subprocess.run(\n",
    "    [\"docker\", \"exec\", \"suricata\", \"cat\", \"/var/log/suricata/eve.json\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "logs = []\n",
    "for line in result.stdout.splitlines():\n",
    "    try:\n",
    "        logs.append(json.loads(line))\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "print(f\"âœ“ {len(logs)} Ã©vÃ©nements chargÃ©s\")\n",
    "\n",
    "# 2. Filtrer les Ã©vÃ©nements pertinents (flow et alert)\n",
    "print(\"\\n[2] Filtrage des Ã©vÃ©nements...\")\n",
    "flows = [log for log in logs if log.get(\"event_type\") == \"flow\"]\n",
    "alerts = [log for log in logs if log.get(\"event_type\") == \"alert\"]\n",
    "\n",
    "print(f\"âœ“ {len(flows)} flows\")\n",
    "print(f\"âœ“ {len(alerts)} alertes\")\n",
    "\n",
    "# 3. CrÃ©er le dataset\n",
    "print(\"\\n[3] Construction du dataset...\")\n",
    "\n",
    "data = []\n",
    "\n",
    "# Traiter les flows\n",
    "for flow in flows:\n",
    "    flow_data = flow.get(\"flow\", {})\n",
    "    \n",
    "    # VÃ©rifier si ce flow a dÃ©clenchÃ© une alerte\n",
    "    flow_id = flow.get(\"flow_id\")\n",
    "    is_anomaly = any(alert.get(\"flow_id\") == flow_id for alert in alerts)\n",
    "    \n",
    "    # Extraire les features\n",
    "    features = {\n",
    "        # MÃ©triques rÃ©seau\n",
    "        \"pkts_toserver\": flow_data.get(\"pkts_toserver\", 0),\n",
    "        \"pkts_toclient\": flow_data.get(\"pkts_toclient\", 0),\n",
    "        \"bytes_toserver\": flow_data.get(\"bytes_toserver\", 0),\n",
    "        \"bytes_toclient\": flow_data.get(\"bytes_toclient\", 0),\n",
    "        \n",
    "        # Ratios\n",
    "        \"total_pkts\": flow_data.get(\"pkts_toserver\", 0) + flow_data.get(\"pkts_toclient\", 0),\n",
    "        \"total_bytes\": flow_data.get(\"bytes_toserver\", 0) + flow_data.get(\"bytes_toclient\", 0),\n",
    "        \n",
    "        # Port et protocole\n",
    "        \"src_port\": flow.get(\"src_port\", 0),\n",
    "        \"dest_port\": flow.get(\"dest_port\", 0),\n",
    "        \"proto\": 6 if flow.get(\"proto\") == \"TCP\" else 17 if flow.get(\"proto\") == \"UDP\" else 0,\n",
    "        \n",
    "        # Label\n",
    "        \"is_anomaly\": 1 if is_anomaly else 0,\n",
    "        \"attack_type\": \"normal\"\n",
    "    }\n",
    "    \n",
    "    # Si anomalie, trouver le type d'attaque\n",
    "    if is_anomaly:\n",
    "        for alert in alerts:\n",
    "            if alert.get(\"flow_id\") == flow_id:\n",
    "                signature = alert.get(\"alert\", {}).get(\"signature\", \"unknown\")\n",
    "                features[\"attack_type\"] = signature\n",
    "                break\n",
    "    \n",
    "    data.append(features)\n",
    "\n",
    "# CrÃ©er le DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Calculer des features dÃ©rivÃ©es\n",
    "df[\"avg_pkt_size_toserver\"] = df[\"bytes_toserver\"] / (df[\"pkts_toserver\"] + 1)\n",
    "df[\"avg_pkt_size_toclient\"] = df[\"bytes_toclient\"] / (df[\"pkts_toclient\"] + 1)\n",
    "df[\"pkt_ratio\"] = df[\"pkts_toserver\"] / (df[\"pkts_toclient\"] + 1)\n",
    "df[\"byte_ratio\"] = df[\"bytes_toserver\"] / (df[\"bytes_toclient\"] + 1)\n",
    "\n",
    "print(f\"âœ“ Dataset crÃ©Ã© : {len(df)} lignes\")\n",
    "\n",
    "# 4. Statistiques\n",
    "print(\"\\n[4] Statistiques du dataset...\")\n",
    "print(f\"\\nğŸ“Š RÃ©partition des classes :\")\n",
    "print(df[\"is_anomaly\"].value_counts())\n",
    "print(f\"\\n   Normal   : {(df['is_anomaly'] == 0).sum()} ({(df['is_anomaly'] == 0).sum() / len(df) * 100:.1f}%)\")\n",
    "print(f\"   Anomalie : {(df['is_anomaly'] == 1).sum()} ({(df['is_anomaly'] == 1).sum() / len(df) * 100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Types d'attaques :\")\n",
    "attack_counts = df[df[\"is_anomaly\"] == 1][\"attack_type\"].value_counts()\n",
    "for attack, count in attack_counts.items():\n",
    "    print(f\"   â€¢ {attack:30s} : {count:4d}\")\n",
    "\n",
    "# 5. Afficher un Ã©chantillon\n",
    "print(f\"\\n[5] Ã‰chantillon des donnÃ©es...\")\n",
    "print(\"\\nNormales (5 premiÃ¨res) :\")\n",
    "print(df[df[\"is_anomaly\"] == 0][[\"pkts_toserver\", \"bytes_toserver\", \"dest_port\", \"is_anomaly\"]].head())\n",
    "\n",
    "print(\"\\nAnomalies (5 premiÃ¨res) :\")\n",
    "print(df[df[\"is_anomaly\"] == 1][[\"pkts_toserver\", \"bytes_toserver\", \"dest_port\", \"attack_type\"]].head())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… DATASET PRÃŠT POUR L'ENTRAÃNEMENT\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nğŸ“‹ Features disponibles : {len(df.columns)} colonnes\")\n",
    "print(f\"   Samples : {len(df)}\")\n",
    "print(f\"   Features numÃ©riques : {len(df.select_dtypes(include=[np.number]).columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– ENTRAÃNEMENT DU MODÃˆLE ISOLATION FOREST\n",
      "============================================================\n",
      "\n",
      "[1] SÃ©lection des features...\n",
      "âœ“ 13 features sÃ©lectionnÃ©es\n",
      "âœ“ 70 samples\n",
      "\n",
      "[2] Nettoyage des donnÃ©es...\n",
      "âœ“ Valeurs infinies et manquantes traitÃ©es\n",
      "\n",
      "[3] Split train/test...\n",
      "âœ“ Train : 49 samples\n",
      "âœ“ Test  : 21 samples\n",
      "\n",
      "   Train - Normal: 23, Anomalie: 26\n",
      "   Test  - Normal: 10, Anomalie: 11\n",
      "\n",
      "[4] Normalisation des donnÃ©es...\n",
      "âœ“ DonnÃ©es normalisÃ©es (mean=0, std=1)\n",
      "\n",
      "[5] EntraÃ®nement de l'Isolation Forest...\n",
      "   Contamination observÃ©e : 0.531 (53.1%)\n",
      "   âš ï¸  Trop Ã©levÃ© ! Limitation Ã  : 0.500 (50%)\n",
      "   ğŸ’¡ Cela signifie que votre dataset a BEAUCOUP d'anomalies\n",
      "âœ“ ModÃ¨le entraÃ®nÃ© avec 100 arbres\n",
      "\n",
      "[6] PrÃ©dictions sur le test set...\n",
      "âœ“ 21 prÃ©dictions effectuÃ©es\n",
      "\n",
      "[7] Ã‰valuation du modÃ¨le...\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š MÃ‰TRIQUES DE PERFORMANCE\n",
      "============================================================\n",
      "\n",
      "ğŸ¯ Accuracy : 0.429 (42.9%)\n",
      "\n",
      "ğŸ“‹ Rapport de classification :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Normal       0.38      0.30      0.33        10\n",
      "    Anomalie       0.46      0.55      0.50        11\n",
      "\n",
      "    accuracy                           0.43        21\n",
      "   macro avg       0.42      0.42      0.42        21\n",
      "weighted avg       0.42      0.43      0.42        21\n",
      "\n",
      "ğŸ”¢ Matrice de confusion :\n",
      "                 PrÃ©dit Normal  PrÃ©dit Anomalie\n",
      "Vrai Normal                 3                7\n",
      "Vrai Anomalie               5                6\n",
      "\n",
      "ğŸ“ˆ MÃ©triques dÃ©taillÃ©es :\n",
      "   â€¢ Vrais Positifs  (TP) :    6 - Anomalies correctement dÃ©tectÃ©es\n",
      "   â€¢ Vrais NÃ©gatifs  (TN) :    3 - Normal correctement identifiÃ©\n",
      "   â€¢ Faux Positifs   (FP) :    7 - Fausses alarmes\n",
      "   â€¢ Faux NÃ©gatifs   (FN) :    5 - Anomalies manquÃ©es\n",
      "\n",
      "   â€¢ PrÃ©cision : 0.462 - 46.2% des alertes sont vraies\n",
      "   â€¢ Rappel    : 0.545 - 54.5% des anomalies dÃ©tectÃ©es\n",
      "   â€¢ F1-Score  : 0.500\n",
      "\n",
      "============================================================\n",
      "âš ï¸  ATTENTION : DATASET DÃ‰SÃ‰QUILIBRÃ‰\n",
      "============================================================\n",
      "\n",
      "Votre dataset contient 53.1% d'anomalies.\n",
      "Cela signifie que la majoritÃ© des connexions sont anormales !\n",
      "\n",
      "ğŸ’¡ Recommandations :\n",
      "   1. GÃ©nÃ©rer plus de trafic NORMAL pour Ã©quilibrer\n",
      "   2. Utiliser un autre algorithme (Random Forest supervisÃ©)\n",
      "   3. Sous-Ã©chantillonner les anomalies\n",
      "   4. Utiliser class_weight='balanced' avec d'autres modÃ¨les\n",
      "\n",
      "Le modÃ¨le actuel est limitÃ© Ã  50% de contamination max.\n",
      "    \n",
      "\n",
      "============================================================\n",
      "âœ… MODÃˆLE ENTRAÃNÃ‰ ET Ã‰VALUÃ‰\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "CELLULE 2 CORRIGÃ‰E : ENTRAÃNEMENT DU MODÃˆLE ISOLATION FOREST\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"ğŸ¤– ENTRAÃNEMENT DU MODÃˆLE ISOLATION FOREST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. SÃ©lection des features\n",
    "print(\"\\n[1] SÃ©lection des features...\")\n",
    "\n",
    "feature_columns = [\n",
    "    \"pkts_toserver\",\n",
    "    \"pkts_toclient\",\n",
    "    \"bytes_toserver\",\n",
    "    \"bytes_toclient\",\n",
    "    \"total_pkts\",\n",
    "    \"total_bytes\",\n",
    "    \"src_port\",\n",
    "    \"dest_port\",\n",
    "    \"proto\",\n",
    "    \"avg_pkt_size_toserver\",\n",
    "    \"avg_pkt_size_toclient\",\n",
    "    \"pkt_ratio\",\n",
    "    \"byte_ratio\"\n",
    "]\n",
    "\n",
    "X = df[feature_columns].copy()\n",
    "y = df[\"is_anomaly\"].copy()\n",
    "\n",
    "print(f\"âœ“ {len(feature_columns)} features sÃ©lectionnÃ©es\")\n",
    "print(f\"âœ“ {len(X)} samples\")\n",
    "\n",
    "# 2. Gestion des valeurs manquantes et infinies\n",
    "print(\"\\n[2] Nettoyage des donnÃ©es...\")\n",
    "\n",
    "# Remplacer les inf par NaN puis par 0\n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.fillna(0)\n",
    "\n",
    "print(f\"âœ“ Valeurs infinies et manquantes traitÃ©es\")\n",
    "\n",
    "# 3. Split train/test\n",
    "print(\"\\n[3] Split train/test...\")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"âœ“ Train : {len(X_train)} samples\")\n",
    "print(f\"âœ“ Test  : {len(X_test)} samples\")\n",
    "print(f\"\\n   Train - Normal: {(y_train == 0).sum()}, Anomalie: {(y_train == 1).sum()}\")\n",
    "print(f\"   Test  - Normal: {(y_test == 0).sum()}, Anomalie: {(y_test == 1).sum()}\")\n",
    "\n",
    "# 4. Normalisation\n",
    "print(\"\\n[4] Normalisation des donnÃ©es...\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"âœ“ DonnÃ©es normalisÃ©es (mean=0, std=1)\")\n",
    "\n",
    "# 5. EntraÃ®nement de l'Isolation Forest\n",
    "print(\"\\n[5] EntraÃ®nement de l'Isolation Forest...\")\n",
    "\n",
    "# Calculer le taux de contamination\n",
    "contamination_raw = y_train.sum() / len(y_train)\n",
    "print(f\"   Contamination observÃ©e : {contamination_raw:.3f} ({contamination_raw*100:.1f}%)\")\n",
    "\n",
    "# âš ï¸ CORRECTION : Limiter la contamination Ã  0.5 (50%) max\n",
    "if contamination_raw > 0.5:\n",
    "    contamination = 0.5\n",
    "    print(f\"   âš ï¸  Trop Ã©levÃ© ! Limitation Ã  : {contamination:.3f} (50%)\")\n",
    "    print(f\"   ğŸ’¡ Cela signifie que votre dataset a BEAUCOUP d'anomalies\")\n",
    "else:\n",
    "    contamination = contamination_raw\n",
    "    print(f\"   Contamination utilisÃ©e : {contamination:.3f}\")\n",
    "\n",
    "# CrÃ©er et entraÃ®ner le modÃ¨le\n",
    "iso_forest = IsolationForest(\n",
    "    n_estimators=100,\n",
    "    max_samples='auto',\n",
    "    contamination=contamination,  # Maintenant entre 0 et 0.5\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "iso_forest.fit(X_train_scaled)\n",
    "\n",
    "print(f\"âœ“ ModÃ¨le entraÃ®nÃ© avec {iso_forest.n_estimators} arbres\")\n",
    "\n",
    "# 6. PrÃ©diction\n",
    "print(\"\\n[6] PrÃ©dictions sur le test set...\")\n",
    "\n",
    "# Isolation Forest retourne -1 pour anomalies, 1 pour normal\n",
    "y_pred_iso = iso_forest.predict(X_test_scaled)\n",
    "\n",
    "# Convertir en 0/1 (0=normal, 1=anomalie)\n",
    "y_pred = np.where(y_pred_iso == -1, 1, 0)\n",
    "\n",
    "print(f\"âœ“ {len(y_pred)} prÃ©dictions effectuÃ©es\")\n",
    "\n",
    "# 7. Ã‰valuation\n",
    "print(\"\\n[7] Ã‰valuation du modÃ¨le...\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š MÃ‰TRIQUES DE PERFORMANCE\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nğŸ¯ Accuracy : {accuracy:.3f} ({accuracy*100:.1f}%)\")\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nğŸ“‹ Rapport de classification :\")\n",
    "print(classification_report(y_test, y_pred, target_names=[\"Normal\", \"Anomalie\"], zero_division=0))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"ğŸ”¢ Matrice de confusion :\")\n",
    "print(f\"                 PrÃ©dit Normal  PrÃ©dit Anomalie\")\n",
    "print(f\"Vrai Normal      {cm[0][0]:12d}  {cm[0][1]:15d}\")\n",
    "print(f\"Vrai Anomalie    {cm[1][0]:12d}  {cm[1][1]:15d}\")\n",
    "\n",
    "# Calculs supplÃ©mentaires\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "print(f\"\\nğŸ“ˆ MÃ©triques dÃ©taillÃ©es :\")\n",
    "print(f\"   â€¢ Vrais Positifs  (TP) : {tp:4d} - Anomalies correctement dÃ©tectÃ©es\")\n",
    "print(f\"   â€¢ Vrais NÃ©gatifs  (TN) : {tn:4d} - Normal correctement identifiÃ©\")\n",
    "print(f\"   â€¢ Faux Positifs   (FP) : {fp:4d} - Fausses alarmes\")\n",
    "print(f\"   â€¢ Faux NÃ©gatifs   (FN) : {fn:4d} - Anomalies manquÃ©es\")\n",
    "print(f\"\\n   â€¢ PrÃ©cision : {precision:.3f} - {precision*100:.1f}% des alertes sont vraies\")\n",
    "print(f\"   â€¢ Rappel    : {recall:.3f} - {recall*100:.1f}% des anomalies dÃ©tectÃ©es\")\n",
    "print(f\"   â€¢ F1-Score  : {f1:.3f}\")\n",
    "\n",
    "# 8. Analyse spÃ©cifique si contamination Ã©levÃ©e\n",
    "if contamination_raw > 0.5:\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âš ï¸  ATTENTION : DATASET DÃ‰SÃ‰QUILIBRÃ‰\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"\"\"\n",
    "Votre dataset contient {contamination_raw*100:.1f}% d'anomalies.\n",
    "Cela signifie que la majoritÃ© des connexions sont anormales !\n",
    "\n",
    "ğŸ’¡ Recommandations :\n",
    "   1. GÃ©nÃ©rer plus de trafic NORMAL pour Ã©quilibrer\n",
    "   2. Utiliser un autre algorithme (Random Forest supervisÃ©)\n",
    "   3. Sous-Ã©chantillonner les anomalies\n",
    "   4. Utiliser class_weight='balanced' avec d'autres modÃ¨les\n",
    "\n",
    "Le modÃ¨le actuel est limitÃ© Ã  50% de contamination max.\n",
    "    \"\"\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… MODÃˆLE ENTRAÃNÃ‰ ET Ã‰VALUÃ‰\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”® PRÃ‰DICTION SUR NOUVELLES DONNÃ‰ES\n",
      "============================================================\n",
      "\n",
      "[1] GÃ©nÃ©ration de nouvelles donnÃ©es de test...\n",
      "    (En production, cela viendrait de eve.json en temps rÃ©el)\n",
      "\n",
      "âœ“ 5 nouvelles connexions Ã  analyser\n",
      "\n",
      "[2] Normalisation...\n",
      "âœ“ DonnÃ©es normalisÃ©es\n",
      "\n",
      "[3] PrÃ©diction avec Isolation Forest...\n",
      "âœ“ PrÃ©dictions effectuÃ©es\n",
      "\n",
      "============================================================\n",
      "ğŸ¯ RÃ‰SULTATS DES PRÃ‰DICTIONS\n",
      "============================================================\n",
      "\n",
      "[1] Navigation HTTP normale\n",
      "    PrÃ©diction : âš ï¸  ANOMALIE\n",
      "    Score      : -0.534\n",
      "    Niveau     : ğŸ”´ TRÃˆS SUSPECT\n",
      "    DÃ©tails    : 5 pkts â†’ / 5 pkts â† / Port 80\n",
      "\n",
      "[2] HTTPS normal\n",
      "    PrÃ©diction : âš ï¸  ANOMALIE\n",
      "    Score      : -0.579\n",
      "    Niveau     : ğŸ”´ TRÃˆS SUSPECT\n",
      "    DÃ©tails    : 3 pkts â†’ / 3 pkts â† / Port 443\n",
      "\n",
      "[3] Burst HTTP suspect (beaucoup de paquets sortants)\n",
      "    PrÃ©diction : âš ï¸  ANOMALIE\n",
      "    Score      : -0.666\n",
      "    Niveau     : ğŸ”´ TRÃˆS SUSPECT\n",
      "    DÃ©tails    : 50 pkts â†’ / 2 pkts â† / Port 80\n",
      "\n",
      "[4] Port scan possible (paquets SYN sans rÃ©ponse)\n",
      "    PrÃ©diction : âš ï¸  ANOMALIE\n",
      "    Score      : -0.677\n",
      "    Niveau     : ğŸ”´ TRÃˆS SUSPECT\n",
      "    DÃ©tails    : 100 pkts â†’ / 0 pkts â† / Port 22\n",
      "\n",
      "[5] Brute force suspect (nombreuses petites requÃªtes)\n",
      "    PrÃ©diction : âš ï¸  ANOMALIE\n",
      "    Score      : -0.648\n",
      "    Niveau     : ğŸ”´ TRÃˆS SUSPECT\n",
      "    DÃ©tails    : 30 pkts â†’ / 30 pkts â† / Port 80\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š RÃ‰SUMÃ‰\n",
      "============================================================\n",
      "\n",
      "âœ“ Connexions normales  : 0/5\n",
      "âš ï¸  Anomalies dÃ©tectÃ©es : 5/5\n",
      "\n",
      "ğŸš¨ ALERTE : 5 comportements anormaux dÃ©tectÃ©s !\n",
      "   Actions recommandÃ©es :\n",
      "   â€¢ Bloquer les IPs sources\n",
      "   â€¢ Analyser les logs en dÃ©tail\n",
      "   â€¢ VÃ©rifier les rÃ¨gles firewall\n",
      "\n",
      "============================================================\n",
      "ğŸ’¡ UTILISATION EN PRODUCTION\n",
      "============================================================\n",
      "\n",
      "Pour utiliser ce modÃ¨le en temps rÃ©el :\n",
      "\n",
      "1. Capturer les nouveaux flows de eve.json\n",
      "2. Extraire les features (pkts, bytes, ports, etc.)\n",
      "3. Normaliser avec le scaler\n",
      "4. PrÃ©dire avec iso_forest.predict()\n",
      "5. Si anomalie dÃ©tectÃ©e, dÃ©clencher une alerte\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "CELLULE 3 : PRÃ‰DICTION SUR NOUVELLES DONNÃ‰ES\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\"\n",
    "\n",
    "import time\n",
    "\n",
    "print(\"ğŸ”® PRÃ‰DICTION SUR NOUVELLES DONNÃ‰ES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 1. Simuler de nouvelles connexions rÃ©seau\n",
    "print(\"\\n[1] GÃ©nÃ©ration de nouvelles donnÃ©es de test...\")\n",
    "print(\"    (En production, cela viendrait de eve.json en temps rÃ©el)\\n\")\n",
    "\n",
    "# CrÃ©er des exemples de connexions normales et suspectes\n",
    "new_data = [\n",
    "    # Connexions normales\n",
    "    {\n",
    "        \"pkts_toserver\": 5, \"pkts_toclient\": 5,\n",
    "        \"bytes_toserver\": 400, \"bytes_toclient\": 1000,\n",
    "        \"src_port\": 54321, \"dest_port\": 80, \"proto\": 6,\n",
    "        \"description\": \"Navigation HTTP normale\"\n",
    "    },\n",
    "    {\n",
    "        \"pkts_toserver\": 3, \"pkts_toclient\": 3,\n",
    "        \"bytes_toserver\": 200, \"bytes_toclient\": 300,\n",
    "        \"src_port\": 49152, \"dest_port\": 443, \"proto\": 6,\n",
    "        \"description\": \"HTTPS normal\"\n",
    "    },\n",
    "    \n",
    "    # Connexions suspectes\n",
    "    {\n",
    "        \"pkts_toserver\": 50, \"pkts_toclient\": 2,\n",
    "        \"bytes_toserver\": 5000, \"bytes_toclient\": 100,\n",
    "        \"src_port\": 12345, \"dest_port\": 80, \"proto\": 6,\n",
    "        \"description\": \"Burst HTTP suspect (beaucoup de paquets sortants)\"\n",
    "    },\n",
    "    {\n",
    "        \"pkts_toserver\": 100, \"pkts_toclient\": 0,\n",
    "        \"bytes_toserver\": 6000, \"bytes_toclient\": 0,\n",
    "        \"src_port\": 54321, \"dest_port\": 22, \"proto\": 6,\n",
    "        \"description\": \"Port scan possible (paquets SYN sans rÃ©ponse)\"\n",
    "    },\n",
    "    {\n",
    "        \"pkts_toserver\": 30, \"pkts_toclient\": 30,\n",
    "        \"bytes_toserver\": 3000, \"bytes_toclient\": 500,\n",
    "        \"src_port\": 60000, \"dest_port\": 80, \"proto\": 6,\n",
    "        \"description\": \"Brute force suspect (nombreuses petites requÃªtes)\"\n",
    "    },\n",
    "]\n",
    "\n",
    "# Convertir en DataFrame\n",
    "import pandas as pd\n",
    "new_df = pd.DataFrame(new_data)\n",
    "\n",
    "# Calculer les features dÃ©rivÃ©es\n",
    "new_df[\"total_pkts\"] = new_df[\"pkts_toserver\"] + new_df[\"pkts_toclient\"]\n",
    "new_df[\"total_bytes\"] = new_df[\"bytes_toserver\"] + new_df[\"bytes_toclient\"]\n",
    "new_df[\"avg_pkt_size_toserver\"] = new_df[\"bytes_toserver\"] / (new_df[\"pkts_toserver\"] + 1)\n",
    "new_df[\"avg_pkt_size_toclient\"] = new_df[\"bytes_toclient\"] / (new_df[\"pkts_toclient\"] + 1)\n",
    "new_df[\"pkt_ratio\"] = new_df[\"pkts_toserver\"] / (new_df[\"pkts_toclient\"] + 1)\n",
    "new_df[\"byte_ratio\"] = new_df[\"bytes_toserver\"] / (new_df[\"bytes_toclient\"] + 1)\n",
    "\n",
    "# SÃ©lectionner les features (mÃªmes que pour l'entraÃ®nement)\n",
    "X_new = new_df[feature_columns].copy()\n",
    "X_new = X_new.replace([np.inf, -np.inf], np.nan).fillna(0)\n",
    "\n",
    "print(f\"âœ“ {len(new_df)} nouvelles connexions Ã  analyser\")\n",
    "\n",
    "# 2. Normaliser avec le mÃªme scaler\n",
    "print(\"\\n[2] Normalisation...\")\n",
    "X_new_scaled = scaler.transform(X_new)\n",
    "print(\"âœ“ DonnÃ©es normalisÃ©es\")\n",
    "\n",
    "# 3. PrÃ©diction\n",
    "print(\"\\n[3] PrÃ©diction avec Isolation Forest...\")\n",
    "\n",
    "# PrÃ©dire\n",
    "predictions_iso = iso_forest.predict(X_new_scaled)\n",
    "predictions = np.where(predictions_iso == -1, 1, 0)\n",
    "\n",
    "# Obtenir les scores d'anomalie\n",
    "anomaly_scores = iso_forest.score_samples(X_new_scaled)\n",
    "\n",
    "print(\"âœ“ PrÃ©dictions effectuÃ©es\")\n",
    "\n",
    "# 4. Afficher les rÃ©sultats\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ¯ RÃ‰SULTATS DES PRÃ‰DICTIONS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for i, row in new_df.iterrows():\n",
    "    is_anomaly = predictions[i]\n",
    "    score = anomaly_scores[i]\n",
    "    \n",
    "    # DÃ©terminer le niveau de confiance\n",
    "    if score < -0.5:\n",
    "        confidence = \"ğŸ”´ TRÃˆS SUSPECT\"\n",
    "    elif score < -0.2:\n",
    "        confidence = \"ğŸŸ  SUSPECT\"\n",
    "    elif score < 0:\n",
    "        confidence = \"ğŸŸ¡ DOUTEUX\"\n",
    "    else:\n",
    "        confidence = \"ğŸŸ¢ NORMAL\"\n",
    "    \n",
    "    print(f\"\\n[{i+1}] {row['description']}\")\n",
    "    print(f\"    PrÃ©diction : {'âš ï¸  ANOMALIE' if is_anomaly else 'âœ“ NORMAL'}\")\n",
    "    print(f\"    Score      : {score:.3f}\")\n",
    "    print(f\"    Niveau     : {confidence}\")\n",
    "    print(f\"    DÃ©tails    : {row['pkts_toserver']} pkts â†’ / {row['pkts_toclient']} pkts â† / Port {row['dest_port']}\")\n",
    "\n",
    "# 5. RÃ©sumÃ©\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š RÃ‰SUMÃ‰\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "normal_count = (predictions == 0).sum()\n",
    "anomaly_count = (predictions == 1).sum()\n",
    "\n",
    "print(f\"\\nâœ“ Connexions normales  : {normal_count}/{len(predictions)}\")\n",
    "print(f\"âš ï¸  Anomalies dÃ©tectÃ©es : {anomaly_count}/{len(predictions)}\")\n",
    "\n",
    "if anomaly_count > 0:\n",
    "    print(f\"\\nğŸš¨ ALERTE : {anomaly_count} comportements anormaux dÃ©tectÃ©s !\")\n",
    "    print(\"   Actions recommandÃ©es :\")\n",
    "    print(\"   â€¢ Bloquer les IPs sources\")\n",
    "    print(\"   â€¢ Analyser les logs en dÃ©tail\")\n",
    "    print(\"   â€¢ VÃ©rifier les rÃ¨gles firewall\")\n",
    "else:\n",
    "    print(f\"\\nâœ… Aucune anomalie dÃ©tectÃ©e, tout semble normal\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ’¡ UTILISATION EN PRODUCTION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\"\"\n",
    "Pour utiliser ce modÃ¨le en temps rÃ©el :\n",
    "\n",
    "1. Capturer les nouveaux flows de eve.json\n",
    "2. Extraire les features (pkts, bytes, ports, etc.)\n",
    "3. Normaliser avec le scaler\n",
    "4. PrÃ©dire avec iso_forest.predict()\n",
    "5. Si anomalie dÃ©tectÃ©e, dÃ©clencher une alerte\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus\n",
    "- amÃ©liorer la stack (ex: ajout de Wazuh)\n",
    "- dashboard Kibana pour voir en live les simulations de comportements anormaux et les dÃ©tection d'anomalie (timeline des alertes, etc.)\n",
    "- analyse statistique avancÃ©e\n",
    "- simulations de comportement anormaux avancÃ©e\n",
    "- utilisation du module de dÃ©tection d'anomalie d'Elasticsearch (https://www.elastic.co/docs/explore-analyze/machine-learning/anomaly-detection)\n",
    "- collaboration en groupe sur le projet Git (Pull requests, commits, etc.)\n",
    "- utilisation de docker / docker compose / devcontainer\n",
    "- etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
