{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD SIEM : Suricata, Filebeat, Elasticsearch et Kibana\n",
    "\n",
    "## Objectifs du TD\n",
    "\n",
    "Ce TD vous permettra de :\n",
    "- Configurer Suricata (systÃ¨me de dÃ©tection d'intrusion) pour gÃ©nÃ©rer des logs EVE JSON\n",
    "- Utiliser Filebeat pour collecter et envoyer automatiquement les logs vers Elasticsearch\n",
    "- Explorer et analyser les donnÃ©es dans Elasticsearch\n",
    "- CrÃ©er des visualisations dans Kibana\n",
    "- Configurer des alertes pour la dÃ©tection de menaces\n",
    "\n",
    "## Architecture SIEM\n",
    "\n",
    "```\n",
    "Suricata â†’ Filebeat â†’ Elasticsearch â†’ Kibana\n",
    "   (IDS)    (Collecteur)   (Stockage)   (Visualisation/Alerting)\n",
    "```\n",
    "\n",
    "## PrÃ©requis\n",
    "\n",
    "### 1. Installation des dÃ©pendances\n",
    "\n",
    "Assurez-vous d'avoir installÃ© les dÃ©pendances du projet :\n",
    "```bash\n",
    "uv sync\n",
    "```\n",
    "\n",
    "### 2. PrÃ©paration des rÃ©pertoires\n",
    "\n",
    "Avant de dÃ©marrer la stack, crÃ©ez les rÃ©pertoires nÃ©cessaires pour Suricata :\n",
    "\n",
    "```bash\n",
    "mkdir -p suricata/{logs,config,rules}\n",
    "```\n",
    "\n",
    "### 3. Configuration de Suricata\n",
    "\n",
    "CrÃ©ez le fichier `suricata/config/suricata.yaml` avec la configuration minimale suivante :\n",
    "\n",
    "```yaml\n",
    "# Configuration des logs EVE (JSON)\n",
    "- eve-log:\n",
    "    enabled: yes\n",
    "    filetype: regular\n",
    "    filename: eve.json\n",
    "    types:\n",
    "      - alert\n",
    "      - http\n",
    "      - dns\n",
    "      - tls\n",
    "      - files\n",
    "      - ssh\n",
    "      - stats\n",
    "      - flow\n",
    "    json: yes\n",
    "\n",
    "# Interface rÃ©seau\n",
    "af-packet:\n",
    "  - interface: eth0\n",
    "    cluster-id: 99\n",
    "    cluster-type: cluster_flow\n",
    "    defrag: yes\n",
    "\n",
    "# RÃ¨gles\n",
    "default-rule-path: /var/lib/suricata/rules\n",
    "rule-files:\n",
    "  - suricata.rules\n",
    "```\n",
    "\n",
    "### 4. DÃ©marrage de la stack complÃ¨te SIEM\n",
    "\n",
    "Le fichier `docker-compose-siem.yml` inclut toute la stack nÃ©cessaire pour ce TD :\n",
    "- Cluster Elasticsearch (3 nÅ“uds)\n",
    "- Kibana\n",
    "- Suricata (IDS/IPS) - gÃ©nÃ¨re des logs dans `./suricata/logs/eve.json`\n",
    "- Filebeat (collecteur de logs) - lit depuis `./suricata/logs` et indexe dans Elasticsearch\n",
    "\n",
    "**DÃ©marrage de la stack complÃ¨te :**\n",
    "```bash\n",
    "docker-compose -f docker-compose-siem.yml up -d\n",
    "```\n",
    "\n",
    "**VÃ©rification :**\n",
    "- Elasticsearch : `https://localhost:9200` (ou le port configurÃ© dans `.env`)\n",
    "- Kibana : `http://localhost:5601` (ou le port configurÃ© dans `.env`)\n",
    "\n",
    "**Note :** Si vous utilisez un cluster avec sÃ©curitÃ© activÃ©e, vous devrez utiliser les identifiants dÃ©finis dans le fichier `.env` (ELASTIC_PASSWORD).\n",
    "\n",
    "**Important :** Filebeat indexe automatiquement les logs Suricata dans des index nommÃ©s `suricata-YYYY.MM.DD`. Les donnÃ©es seront disponibles aprÃ¨s que Suricata ait gÃ©nÃ©rÃ© des logs et que Filebeat les ait collectÃ©s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. VÃ©rification de la stack\n",
    "\n",
    "La cellule suivante vÃ©rifie que tous les services sont correctement dÃ©marrÃ©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:39.271628Z",
     "iopub.status.busy": "2026-01-17T14:32:39.271292Z",
     "iopub.status.idle": "2026-01-17T14:32:39.788237Z",
     "shell.execute_reply": "2026-01-17T14:32:39.786629Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Docker est installÃ©\n",
      "âœ… Docker Compose est disponible\n",
      "\n",
      "ðŸ“¦ Statut des services:\n",
      "   âœ… es01: en cours d'exÃ©cution\n",
      "   âœ… es02: en cours d'exÃ©cution\n",
      "   âœ… es03: en cours d'exÃ©cution\n",
      "   âœ… kibana: en cours d'exÃ©cution\n",
      "   âœ… suricata: en cours d'exÃ©cution\n",
      "   âœ… filebeat: en cours d'exÃ©cution\n",
      "\n",
      "ðŸ“ Pour arrÃªter:\n",
      "   docker-compose down\n"
     ]
    }
   ],
   "source": [
    "# VÃ©rification de la stack Docker\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def check_docker_container(container_name):\n",
    "    \"\"\"VÃ©rifie si un conteneur Docker est en cours d'exÃ©cution\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            ['docker', 'ps', '--filter', f'name={container_name}', '--format', '{{.Names}}'],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=5\n",
    "        )\n",
    "        return container_name in result.stdout\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def check_docker_compose():\n",
    "    \"\"\"VÃ©rifie si docker-compose est disponible\"\"\"\n",
    "    try:\n",
    "        subprocess.run(['docker', 'compose', 'version'], capture_output=True, check=True, timeout=5)\n",
    "        return True\n",
    "    except:\n",
    "        try:\n",
    "            subprocess.run(['docker-compose', 'version'], capture_output=True, check=True, timeout=5)\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "\n",
    "# VÃ©rifier Docker\n",
    "try:\n",
    "    subprocess.run(['docker', '--version'], capture_output=True, check=True, timeout=5)\n",
    "    print(\"âœ… Docker est installÃ©\")\n",
    "except (FileNotFoundError, subprocess.CalledProcessError):\n",
    "    print(\"âŒ Docker n'est pas installÃ©\")\n",
    "    print(\"   Installez Docker: https://docs.docker.com/get-docker/\")\n",
    "    exit(1)\n",
    "\n",
    "# VÃ©rifier docker-compose\n",
    "if check_docker_compose():\n",
    "    print(\"âœ… Docker Compose est disponible\")\n",
    "else:\n",
    "    print(\"âŒ Docker Compose n'est pas disponible\")\n",
    "\n",
    "# VÃ©rifier les conteneurs\n",
    "services = ['es01', 'es02', 'es03', 'kibana', 'suricata', 'filebeat']\n",
    "print(\"\\nðŸ“¦ Statut des services:\")\n",
    "for service in services:\n",
    "    if check_docker_container(service):\n",
    "        print(f\"   âœ… {service}: en cours d'exÃ©cution\")\n",
    "    else:\n",
    "        print(f\"   âš ï¸  {service}: arrÃªtÃ©\")\n",
    "\n",
    "print(\"\\nðŸ“ Pour arrÃªter:\")\n",
    "print(\"   docker-compose down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:39.791483Z",
     "iopub.status.busy": "2026-01-17T14:32:39.791149Z",
     "iopub.status.idle": "2026-01-17T14:32:40.092396Z",
     "shell.execute_reply": "2026-01-17T14:32:40.089342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Connexion Ã©tablie avec Elasticsearch\n",
      "   Statut du cluster: green\n",
      "   Nombre de nÅ“uds: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/elasticsearch/_sync/client/__init__.py:313: SecurityWarning: Connecting to 'https://localhost:9200' using TLS with verify_certs=False is insecure\n",
      "  _transport = transport_class(\n",
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Import des librairies nÃ©cessaires\n",
    "from elasticsearch import Elasticsearch\n",
    "from pprint import pprint\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Configuration de la connexion Elasticsearch\n",
    "# Adaptez selon votre configuration (avec ou sans sÃ©curitÃ©)\n",
    "ES_HOST = \"https://localhost:9200\"\n",
    "ES_USER = \"elastic\"  # Modifiez si nÃ©cessaire\n",
    "ES_PASSWORD = \"changeme\"  # DÃ©finissez votre mot de passe si sÃ©curitÃ© activÃ©e\n",
    "\n",
    "# Connexion au cluster Elasticsearch\n",
    "if ES_PASSWORD:\n",
    "    es = Elasticsearch(\n",
    "        [ES_HOST],\n",
    "        basic_auth=(ES_USER, ES_PASSWORD),\n",
    "        verify_certs=False  # DÃ©sactiver la vÃ©rification SSL pour le dÃ©veloppement\n",
    "    )\n",
    "else:\n",
    "    # Pour un cluster sans sÃ©curitÃ© (dÃ©veloppement uniquement)\n",
    "    es = Elasticsearch(\"http://localhost:9200\")\n",
    "\n",
    "# VÃ©rification de la connexion\n",
    "try:\n",
    "    health = es.cluster.health()\n",
    "    print(\"âœ… Connexion Ã©tablie avec Elasticsearch\")\n",
    "    print(f\"   Statut du cluster: {health['status']}\")\n",
    "    print(f\"   Nombre de nÅ“uds: {health['number_of_nodes']}\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur de connexion: {e}\")\n",
    "    print(\"   VÃ©rifiez que votre cluster Elasticsearch est dÃ©marrÃ©\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Configuration de Suricata\n",
    "\n",
    "### 1.1 VÃ©rification de l'installation de Suricata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:40.096986Z",
     "iopub.status.busy": "2026-01-17T14:32:40.096678Z",
     "iopub.status.idle": "2026-01-17T14:32:40.104468Z",
     "shell.execute_reply": "2026-01-17T14:32:40.102751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RÃ©pertoire crÃ©Ã©/vÃ©rifiÃ©: ./suricata/logs\n",
      "âœ… RÃ©pertoire crÃ©Ã©/vÃ©rifiÃ©: ./suricata/config\n",
      "âœ… RÃ©pertoire crÃ©Ã©/vÃ©rifiÃ©: ./suricata/rules\n",
      "âœ… RÃ©pertoire crÃ©Ã©/vÃ©rifiÃ©: ./suricata_logs\n",
      "\n",
      "ðŸ“ Les rÃ©pertoires sont prÃªts pour Suricata\n"
     ]
    }
   ],
   "source": [
    "# CrÃ©ation des rÃ©pertoires nÃ©cessaires pour Suricata\n",
    "import os\n",
    "\n",
    "# CrÃ©er les rÃ©pertoires si nÃ©cessaire\n",
    "directories = [\n",
    "    './suricata/logs',\n",
    "    './suricata/config',\n",
    "    './suricata/rules',\n",
    "    './suricata_logs'\n",
    "]\n",
    "\n",
    "for directory in directories:\n",
    "    os.makedirs(directory, exist_ok=True)\n",
    "    print(f\"âœ… RÃ©pertoire crÃ©Ã©/vÃ©rifiÃ©: {directory}\")\n",
    "\n",
    "print(\"\\nðŸ“ Les rÃ©pertoires sont prÃªts pour Suricata\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 VÃ©rification des logs Suricata\n",
    "\n",
    "Suricata gÃ©nÃ¨re des logs au format JSON (EVE logs) dans `./suricata/logs/eve.json`. \n",
    "Filebeat lit automatiquement ces logs et les indexe dans Elasticsearch.\n",
    "\n",
    "VÃ©rifions que les logs sont gÃ©nÃ©rÃ©s et que Filebeat les collecte correctement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:40.110851Z",
     "iopub.status.busy": "2026-01-17T14:32:40.109883Z",
     "iopub.status.idle": "2026-01-17T14:32:40.132538Z",
     "shell.execute_reply": "2026-01-17T14:32:40.130591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Fichier de logs trouvÃ©: ./suricata/logs/eve.json\n",
      "   Nombre de lignes (logs): 64741\n",
      "\n",
      "ðŸ“„ Derniers logs (3 derniÃ¨res lignes):\n",
      "   - flow Ã  2026-01-17T16:33:56.263903+0000\n",
      "   - flow Ã  2026-01-17T16:33:56.263916+0000\n",
      "   - stats Ã  2026-01-17T16:33:56.656711+0000\n",
      "\n",
      "ðŸ” VÃ©rification de Filebeat:\n",
      "âœ… Filebeat est en cours d'exÃ©cution\n",
      "   âš ï¸  Des erreurs dÃ©tectÃ©es dans les logs Filebeat\n"
     ]
    }
   ],
   "source": [
    "# VÃ©rification des logs Suricata et de Filebeat\n",
    "import subprocess\n",
    "import time\n",
    "\n",
    "# VÃ©rifier que le fichier de logs existe\n",
    "log_file = \"./suricata/logs/eve.json\"\n",
    "if os.path.exists(log_file):\n",
    "    # Compter le nombre de lignes (logs)\n",
    "    with open(log_file, 'r') as f:\n",
    "        log_count = sum(1 for line in f if line.strip())\n",
    "    print(f\"âœ… Fichier de logs trouvÃ©: {log_file}\")\n",
    "    print(f\"   Nombre de lignes (logs): {log_count}\")\n",
    "    \n",
    "    # Afficher les derniÃ¨res lignes\n",
    "    if log_count > 0:\n",
    "        print(\"\\nðŸ“„ Derniers logs (3 derniÃ¨res lignes):\")\n",
    "        with open(log_file, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines[-3:]:\n",
    "                try:\n",
    "                    log_entry = json.loads(line.strip())\n",
    "                    print(f\"   - {log_entry.get('event_type', 'unknown')} Ã  {log_entry.get('timestamp', 'N/A')}\")\n",
    "                except:\n",
    "                    print(f\"   - (ligne non-JSON)\")\n",
    "else:\n",
    "    print(f\"âš ï¸  Fichier de logs non trouvÃ©: {log_file}\")\n",
    "    print(\"   Assurez-vous que Suricata est dÃ©marrÃ© et gÃ©nÃ¨re des logs\")\n",
    "    print(\"   Les logs seront crÃ©Ã©s automatiquement quand Suricata dÃ©tecte du trafic\")\n",
    "\n",
    "# VÃ©rifier le statut de Filebeat\n",
    "print(\"\\nðŸ” VÃ©rification de Filebeat:\")\n",
    "try:\n",
    "    result = subprocess.run(\n",
    "        ['docker', 'logs', '--tail', '10', 'filebeat'],\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        timeout=5\n",
    "    )\n",
    "    if result.returncode == 0:\n",
    "        print(\"âœ… Filebeat est en cours d'exÃ©cution\")\n",
    "        # Chercher des erreurs dans les logs\n",
    "        if 'error' in result.stdout.lower() or 'error' in result.stderr.lower():\n",
    "            print(\"   âš ï¸  Des erreurs dÃ©tectÃ©es dans les logs Filebeat\")\n",
    "        else:\n",
    "            print(\"   âœ… Aucune erreur dÃ©tectÃ©e\")\n",
    "    else:\n",
    "        print(\"   âš ï¸  Impossible de rÃ©cupÃ©rer les logs Filebeat\")\n",
    "except Exception as e:\n",
    "    print(f\"   âš ï¸  Erreur lors de la vÃ©rification: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:40.138040Z",
     "iopub.status.busy": "2026-01-17T14:32:40.137710Z",
     "iopub.status.idle": "2026-01-17T14:32:40.143108Z",
     "shell.execute_reply": "2026-01-17T14:32:40.141150Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Recherche des index Suricata crÃ©Ã©s par Filebeat...\n",
      "   Patterns attendus: suricata-* ou .ds-suricata-*\n",
      "   Date du jour: 2026.01.17\n",
      "\n",
      "âœ… 2 index(s) trouvÃ©(s):\n",
      "   - .ds-suricata-2026.01.17-2026.01.17-000001: 121272 documents\n",
      "   - .ds-suricata-2026.01.17-2026.01.17-000001: 121272 documents\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# VÃ©rification des index crÃ©Ã©s par Filebeat\n",
    "# Filebeat 9.x crÃ©e des data streams avec le pattern: .ds-suricata-YYYY.MM.DD-*\n",
    "# ou des index normaux avec le pattern: suricata-YYYY.MM.DD\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Obtenir la date actuelle pour construire le nom d'index\n",
    "today = datetime.now().strftime(\"%Y.%m.%d\")\n",
    "\n",
    "print(f\"ðŸ” Recherche des index Suricata crÃ©Ã©s par Filebeat...\")\n",
    "print(f\"   Patterns attendus: suricata-* ou .ds-suricata-*\")\n",
    "print(f\"   Date du jour: {today}\\n\")\n",
    "\n",
    "# Lister tous les index qui correspondent aux patterns\n",
    "all_indices = []\n",
    "try:\n",
    "    # Chercher les index normaux (utiliser get qui fonctionne mieux)\n",
    "    try:\n",
    "        indices_normal = es.indices.get(index=\"suricata-*\")\n",
    "        if indices_normal:\n",
    "            all_indices.extend(indices_normal.keys())\n",
    "    except:\n",
    "        # Fallback sur get_alias si get Ã©choue\n",
    "        try:\n",
    "            indices_normal = es.indices.get_alias(index=\"suricata-*\")\n",
    "            if indices_normal:\n",
    "                all_indices.extend(indices_normal.keys())\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Chercher les data streams (commencent par .ds-) - get_alias ne fonctionne pas avec les data streams\n",
    "    try:\n",
    "        indices_ds = es.indices.get(index=\".ds-suricata-*\")\n",
    "        if indices_ds:\n",
    "            all_indices.extend(indices_ds.keys())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if all_indices:\n",
    "        print(f\"âœ… {len(all_indices)} index(s) trouvÃ©(s):\")\n",
    "        for index_name in sorted(all_indices):\n",
    "            try:\n",
    "                count = es.count(index=index_name)\n",
    "                print(f\"   - {index_name}: {count['count']} documents\")\n",
    "            except:\n",
    "                print(f\"   - {index_name}: (erreur lors du comptage)\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Aucun index trouvÃ© avec les patterns 'suricata-*' ou '.ds-suricata-*'\")\n",
    "        print(\"   Cela peut signifier que:\")\n",
    "        print(\"   1. Filebeat n'a pas encore indexÃ© de donnÃ©es\")\n",
    "        print(\"   2. Suricata n'a pas encore gÃ©nÃ©rÃ© de logs\")\n",
    "        print(\"   3. Il y a un problÃ¨me de configuration\")\n",
    "        print(\"   VÃ©rifiez les logs Filebeat: docker logs filebeat\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Erreur lors de la recherche des index: {e}\")\n",
    "    print(\"   VÃ©rifiez que Elasticsearch est accessible et que Filebeat fonctionne\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 2 : Utilisation des donnÃ©es indexÃ©es par Filebeat\n",
    "\n",
    "Filebeat indexe automatiquement les logs Suricata dans des index nommÃ©s `suricata-YYYY.MM.DD`. \n",
    "Nous allons maintenant explorer ces donnÃ©es dans Elasticsearch.\n",
    "\n",
    "**Note importante :** Les donnÃ©es doivent Ãªtre indexÃ©es par Filebeat. Si vous ne voyez pas d'index, \n",
    "attendez quelques instants que Suricata gÃ©nÃ¨re des logs et que Filebeat les collecte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:40.147570Z",
     "iopub.status.busy": "2026-01-17T14:32:40.147269Z",
     "iopub.status.idle": "2026-01-17T14:32:40.246561Z",
     "shell.execute_reply": "2026-01-17T14:32:40.244764Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Index dÃ©tectÃ©: .ds-suricata-2026.01.17-2026.01.17-000001\n",
      "âœ… 2 index(s) trouvÃ©(s):\n",
      "   - .ds-suricata-2026.01.17-2026.01.17-000001: 124107 document(s)\n",
      "   - .ds-suricata-2026.01.17-2026.01.17-000001: 124107 document(s)\n"
     ]
    }
   ],
   "source": [
    "# Fonction utilitaire pour obtenir le nom de l'index Ã  utiliser\n",
    "def get_suricata_index():\n",
    "    \"\"\"Retourne le nom de l'index Suricata le plus rÃ©cent ou un pattern\"\"\"\n",
    "    try:\n",
    "        all_indices = []\n",
    "        # Chercher les index normaux (utiliser get qui fonctionne mieux)\n",
    "        try:\n",
    "            indices_normal = es.indices.get(index=\"suricata-*\")\n",
    "            if indices_normal:\n",
    "                all_indices.extend(indices_normal.keys())\n",
    "        except:\n",
    "            # Fallback sur get_alias si get Ã©choue\n",
    "            try:\n",
    "                indices_normal = es.indices.get_alias(index=\"suricata-*\")\n",
    "                if indices_normal:\n",
    "                    all_indices.extend(indices_normal.keys())\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Chercher les data streams (commencent par .ds-) - get_alias ne fonctionne pas avec les data streams\n",
    "        try:\n",
    "            indices_ds = es.indices.get(index=\".ds-suricata-*\")\n",
    "            if indices_ds:\n",
    "                all_indices.extend(indices_ds.keys())\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        if all_indices:\n",
    "            # Retourner l'index le plus rÃ©cent\n",
    "            return sorted(all_indices)[-1]\n",
    "        else:\n",
    "            # Si aucun index n'existe, utiliser le pattern\n",
    "            return \"suricata-*\"\n",
    "    except:\n",
    "        # En cas d'erreur, utiliser le pattern\n",
    "        return \"suricata-*\"\n",
    "\n",
    "# Fonction pour obtenir l'index de recherche (utilise le pattern si l'index spÃ©cifique n'existe pas)\n",
    "def get_search_index():\n",
    "    \"\"\"Retourne l'index Ã  utiliser pour les recherches (inclut les data streams)\"\"\"\n",
    "    index_name = get_suricata_index()\n",
    "    if index_name == \"suricata-*\":\n",
    "        # Utiliser les deux patterns pour couvrir index normaux et data streams\n",
    "        return \"suricata-*,.ds-suricata-*\"\n",
    "    # VÃ©rifier si l'index existe\n",
    "    try:\n",
    "        if es.indices.exists(index=index_name):\n",
    "            return index_name\n",
    "        else:\n",
    "            return \"suricata-*,.ds-suricata-*\"\n",
    "    except:\n",
    "        return \"suricata-*,.ds-suricata-*\"\n",
    "\n",
    "# DÃ©terminer l'index Ã  utiliser\n",
    "index_name = get_suricata_index()\n",
    "print(f\"ðŸ“Š Index dÃ©tectÃ©: {index_name}\")\n",
    "\n",
    "# VÃ©rifier si des index existent (chercher les deux types)\n",
    "try:\n",
    "    all_indices_found = []\n",
    "    \n",
    "    # Chercher les index normaux\n",
    "    try:\n",
    "        indices_normal = es.indices.get(index=\"suricata-*\")\n",
    "        if indices_normal:\n",
    "            all_indices_found.extend(indices_normal.keys())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    # Chercher les data streams\n",
    "    try:\n",
    "        indices_ds = es.indices.get(index=\".ds-suricata-*\")\n",
    "        if indices_ds:\n",
    "            all_indices_found.extend(indices_ds.keys())\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    if all_indices_found:\n",
    "        print(f\"âœ… {len(all_indices_found)} index(s) trouvÃ©(s):\")\n",
    "        for idx in sorted(all_indices_found):\n",
    "            try:\n",
    "                count = es.count(index=idx)\n",
    "                print(f\"   - {idx}: {count['count']} document(s)\")\n",
    "            except:\n",
    "                print(f\"   - {idx}: (erreur lors du comptage)\")\n",
    "    else:\n",
    "        print(\"âš ï¸  Aucun index trouvÃ© avec les patterns 'suricata-*' ou '.ds-suricata-*'\")\n",
    "        print(\"   Filebeat crÃ©era des index automatiquement lors de la premiÃ¨re indexation\")\n",
    "        print(\"   Assurez-vous que:\")\n",
    "        print(\"   1. Suricata gÃ©nÃ¨re des logs dans ./suricata/logs/eve.json\")\n",
    "        print(\"   2. Filebeat est dÃ©marrÃ© et fonctionne correctement\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Erreur lors de la vÃ©rification des index: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# affiche le nombre de documents dans l'index\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindex_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/elasticsearch/_sync/client/utils.py:415\u001b[39m, in \u001b[36m_rewrite_parameters.<locals>.wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    412\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[32m    413\u001b[39m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mapi\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/elasticsearch/_sync/client/__init__.py:1017\u001b[39m, in \u001b[36mElasticsearch.count\u001b[39m\u001b[34m(self, index, allow_no_indices, analyze_wildcard, analyzer, default_operator, df, error_trace, expand_wildcards, filter_path, human, ignore_throttled, ignore_unavailable, lenient, min_score, preference, pretty, project_routing, q, query, routing, terminate_after, body)\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m __body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1016\u001b[39m     __headers[\u001b[33m\"\u001b[39m\u001b[33mcontent-type\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mapplication/json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1017\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]\u001b[39;49;00m\n\u001b[32m   1018\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m    \u001b[49m\u001b[43m__path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1023\u001b[39m \u001b[43m    \u001b[49m\u001b[43mendpoint_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_parts\u001b[49m\u001b[43m=\u001b[49m\u001b[43m__path_parts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/elasticsearch/_sync/client/_base.py:271\u001b[39m, in \u001b[36mBaseClient.perform_request\u001b[39m\u001b[34m(self, method, path, params, headers, body, endpoint_id, path_parts)\u001b[39m\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mperform_request\u001b[39m(\n\u001b[32m    256\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    257\u001b[39m     method: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    264\u001b[39m     path_parts: Optional[Mapping[\u001b[38;5;28mstr\u001b[39m, Any]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    265\u001b[39m ) -> ApiResponse[Any]:\n\u001b[32m    266\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._otel.span(\n\u001b[32m    267\u001b[39m         method,\n\u001b[32m    268\u001b[39m         endpoint_id=endpoint_id,\n\u001b[32m    269\u001b[39m         path_parts=path_parts \u001b[38;5;129;01mor\u001b[39;00m {},\n\u001b[32m    270\u001b[39m     ) \u001b[38;5;28;01mas\u001b[39;00m otel_span:\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_perform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m            \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m            \u001b[49m\u001b[43motel_span\u001b[49m\u001b[43m=\u001b[49m\u001b[43motel_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    279\u001b[39m         otel_span.set_elastic_cloud_metadata(response.meta.headers)\n\u001b[32m    280\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/elasticsearch/_sync/client/_base.py:315\u001b[39m, in \u001b[36mBaseClient._perform_request\u001b[39m\u001b[34m(self, method, path, params, headers, body, otel_span)\u001b[39m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    313\u001b[39m     target = path\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m meta, resp_body = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_max_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_on_status\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_on_status\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_on_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_retry_on_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient_meta\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client_meta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43motel_span\u001b[49m\u001b[43m=\u001b[49m\u001b[43motel_span\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[38;5;66;03m# HEAD with a 404 is returned as a normal response\u001b[39;00m\n\u001b[32m    329\u001b[39m \u001b[38;5;66;03m# since this is used as an 'exists' functionality.\u001b[39;00m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (method == \u001b[33m\"\u001b[39m\u001b[33mHEAD\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m meta.status == \u001b[32m404\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m    331\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[32m200\u001b[39m <= meta.status < \u001b[32m299\u001b[39m\n\u001b[32m    332\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[32m   (...)\u001b[39m\u001b[32m    336\u001b[39m     )\n\u001b[32m    337\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/elastic_transport/_transport.py:344\u001b[39m, in \u001b[36mTransport.perform_request\u001b[39m\u001b[34m(self, method, target, body, headers, max_retries, retry_on_status, retry_on_timeout, request_timeout, client_meta, otel_span)\u001b[39m\n\u001b[32m    340\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    341\u001b[39m     otel_span.set_node_metadata(\n\u001b[32m    342\u001b[39m         node.host, node.port, node.base_url, target, method\n\u001b[32m    343\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m344\u001b[39m     resp = \u001b[43mnode\u001b[49m\u001b[43m.\u001b[49m\u001b[43mperform_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    351\u001b[39m     _logger.info(\n\u001b[32m    352\u001b[39m         \u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m [status:\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m duration:\u001b[39m\u001b[38;5;132;01m%.3f\u001b[39;00m\u001b[33ms]\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    353\u001b[39m         % (\n\u001b[32m   (...)\u001b[39m\u001b[32m    359\u001b[39m         )\n\u001b[32m    360\u001b[39m     )\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m method != \u001b[33m\"\u001b[39m\u001b[33mHEAD\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/elastic_transport/_node/_http_urllib3.py:167\u001b[39m, in \u001b[36mUrllib3HttpNode.perform_request\u001b[39m\u001b[34m(self, method, target, body, headers, request_timeout)\u001b[39m\n\u001b[32m    164\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    165\u001b[39m     body_to_send = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpool\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody_to_send\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRetry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m    174\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m response_headers = HttpHeaders(response.headers)\n\u001b[32m    176\u001b[39m data = response.data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    532\u001b[39m \u001b[38;5;66;03m# Receive the response from the server\u001b[39;00m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    536\u001b[39m     \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=read_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connection.py:571\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    568\u001b[39m _shutdown = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.sock, \u001b[33m\"\u001b[39m\u001b[33mshutdown\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    570\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    574\u001b[39m     assert_header_parsing(httplib_response.msg)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.14.2-linux-x86_64-gnu/lib/python3.14/http/client.py:1450\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1448\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1449\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1450\u001b[39m         \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1451\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n\u001b[32m   1452\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.14.2-linux-x86_64-gnu/lib/python3.14/http/client.py:336\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    334\u001b[39m \u001b[38;5;66;03m# read until we get a non-100 response\u001b[39;00m\n\u001b[32m    335\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n\u001b[32m    338\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.14.2-linux-x86_64-gnu/lib/python3.14/http/client.py:297\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n\u001b[32m    299\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m LineTooLong(\u001b[33m\"\u001b[39m\u001b[33mstatus line\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.14.2-linux-x86_64-gnu/lib/python3.14/socket.py:725\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    723\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    724\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m725\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    726\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    727\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.14.2-linux-x86_64-gnu/lib/python3.14/ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.14.2-linux-x86_64-gnu/lib/python3.14/ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# affiche le nombre de documents dans l'index\n",
    "es.count(index=index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Exploration des donnÃ©es indexÃ©es\n",
    "\n",
    "Les donnÃ©es sont dÃ©jÃ  indexÃ©es par Filebeat. Explorons-les maintenant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:40.249953Z",
     "iopub.status.busy": "2026-01-17T14:32:40.249691Z",
     "iopub.status.idle": "2026-01-17T14:32:41.195874Z",
     "shell.execute_reply": "2026-01-17T14:32:41.194297Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Total de documents dans l'index '.ds-suricata-2026.01.17-2026.01.17-000001': 10000\n",
      "   Documents retournÃ©s: 10\n",
      "\n",
      "ðŸ“„ Exemples de documents indexÃ©s:\n",
      "\n",
      "Document 1:\n",
      "   Type d'Ã©vÃ©nement: flow\n",
      "   Source: 192.168.65.1:41588\n",
      "   Destination: 192.168.65.7:2376\n",
      "   Timestamp: 2026-01-17T16:31:15.700Z\n",
      "\n",
      "Document 2:\n",
      "   Type d'Ã©vÃ©nement: flow\n",
      "   Source: 192.168.65.1:21106\n",
      "   Destination: 192.168.65.7:2376\n",
      "   Timestamp: 2026-01-17T16:31:15.700Z\n",
      "\n",
      "Document 3:\n",
      "   Type d'Ã©vÃ©nement: flow\n",
      "   Source: 192.168.65.1:33296\n",
      "   Destination: 192.168.65.7:2376\n",
      "   Timestamp: 2026-01-17T16:31:15.700Z\n",
      "\n",
      "Document 4:\n",
      "   Type d'Ã©vÃ©nement: flow\n",
      "   Source: 192.168.65.1:63138\n",
      "   Destination: 192.168.65.7:2376\n",
      "   Timestamp: 2026-01-17T16:31:15.700Z\n",
      "\n",
      "Document 5:\n",
      "   Type d'Ã©vÃ©nement: flow\n",
      "   Source: 192.168.65.1:31983\n",
      "   Destination: 192.168.65.7:2376\n",
      "   Timestamp: 2026-01-17T16:31:15.700Z\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n",
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Recherche de tous les logs indexÃ©s par Filebeat\n",
    "# Utiliser le pattern suricata-* pour rechercher dans tous les index\n",
    "\n",
    "try:\n",
    "    # VÃ©rifier d'abord si l'index existe\n",
    "    if not es.indices.exists(index=index_name):\n",
    "        print(f\"âš ï¸  L'index {index_name} n'existe pas encore.\")\n",
    "        print(\"   Attendez que Filebeat indexe les logs de Suricata.\")\n",
    "        print(\"   Vous pouvez vÃ©rifier les logs Filebeat avec: docker logs filebeat\")\n",
    "    else:\n",
    "        # Recherche de base\n",
    "        query_all = {\n",
    "            \"match_all\": {}\n",
    "        }\n",
    "        \n",
    "        result = es.search(index=index_name, query=query_all, size=10)\n",
    "        total = result['hits']['total']['value']\n",
    "        \n",
    "        print(f\"ðŸ“Š Total de documents dans l'index '{index_name}': {total}\")\n",
    "        print(f\"   Documents retournÃ©s: {len(result['hits']['hits'])}\\n\")\n",
    "        \n",
    "        if total > 0:\n",
    "            print(\"ðŸ“„ Exemples de documents indexÃ©s:\\n\")\n",
    "            for i, hit in enumerate(result['hits']['hits'][:5], 1):\n",
    "                source = hit['_source']\n",
    "                print(f\"Document {i}:\")\n",
    "                print(f\"   Type d'Ã©vÃ©nement: {source.get('event_type', 'N/A')}\")\n",
    "                if 'src_ip' in source:\n",
    "                    print(f\"   Source: {source.get('src_ip', 'N/A')}:{source.get('src_port', 'N/A')}\")\n",
    "                    print(f\"   Destination: {source.get('dest_ip', 'N/A')}:{source.get('dest_port', 'N/A')}\")\n",
    "                if 'alert' in source:\n",
    "                    alert = source['alert']\n",
    "                    print(f\"   Alerte: {alert.get('signature', 'N/A')}\")\n",
    "                    print(f\"   SÃ©vÃ©ritÃ©: {alert.get('severity', 'N/A')}\")\n",
    "                if '@timestamp' in source:\n",
    "                    print(f\"   Timestamp: {source.get('@timestamp', 'N/A')}\")\n",
    "                print()\n",
    "        else:\n",
    "            print(\"âš ï¸  L'index existe mais ne contient pas encore de documents.\")\n",
    "            print(\"   VÃ©rifiez que Suricata gÃ©nÃ¨re des logs et que Filebeat les collecte.\")\n",
    "            \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur lors de la recherche: {e}\")\n",
    "    print(\"   VÃ©rifiez que Elasticsearch est accessible et que l'index existe.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 3 : Exploration des donnÃ©es dans Elasticsearch\n",
    "\n",
    "### 3.1 Recherche de base dans les logs Suricata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.199543Z",
     "iopub.status.busy": "2026-01-17T14:32:41.199277Z",
     "iopub.status.idle": "2026-01-17T14:32:41.224547Z",
     "shell.execute_reply": "2026-01-17T14:32:41.221800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Total de documents: 10000\n",
      "   Documents retournÃ©s: 10\n",
      "\n",
      "ðŸ“„ Document VRfMzJsBtz7UXYiikMD4:\n",
      "   Type: flow\n",
      "   Source IP: 192.168.65.1 â†’ Dest IP: 192.168.65.7\n",
      "\n",
      "ðŸ“„ Document VhfMzJsBtz7UXYiikMD4:\n",
      "   Type: flow\n",
      "   Source IP: 192.168.65.1 â†’ Dest IP: 192.168.65.7\n",
      "\n",
      "ðŸ“„ Document VxfMzJsBtz7UXYiikMD4:\n",
      "   Type: flow\n",
      "   Source IP: 192.168.65.1 â†’ Dest IP: 192.168.65.7\n",
      "\n",
      "ðŸ“„ Document WBfMzJsBtz7UXYiikMD4:\n",
      "   Type: flow\n",
      "   Source IP: 192.168.65.1 â†’ Dest IP: 192.168.65.7\n",
      "\n",
      "ðŸ“„ Document WRfMzJsBtz7UXYiikMD4:\n",
      "   Type: flow\n",
      "   Source IP: 192.168.65.1 â†’ Dest IP: 192.168.65.7\n",
      "\n",
      "ðŸ“„ Document WhfMzJsBtz7UXYiikMD4:\n",
      "   Type: flow\n",
      "   Source IP: 192.168.65.1 â†’ Dest IP: 192.168.65.7\n",
      "\n",
      "ðŸ“„ Document WxfMzJsBtz7UXYiikMD4:\n",
      "   Type: flow\n",
      "   Source IP: 192.168.65.1 â†’ Dest IP: 192.168.65.7\n",
      "\n",
      "ðŸ“„ Document XBfMzJsBtz7UXYiikMD4:\n",
      "   Type: flow\n",
      "   Source IP: 192.168.65.1 â†’ Dest IP: 192.168.65.7\n",
      "\n",
      "ðŸ“„ Document XRfMzJsBtz7UXYiikMD4:\n",
      "   Type: flow\n",
      "   Source IP: 192.168.65.1 â†’ Dest IP: 192.168.65.7\n",
      "\n",
      "ðŸ“„ Document XhfMzJsBtz7UXYiikMD4:\n",
      "   Type: flow\n",
      "   Source IP: 192.168.65.1 â†’ Dest IP: 192.168.65.7\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Recherche de tous les logs\n",
    "query_all = {\n",
    "    \"match_all\": {}\n",
    "}\n",
    "\n",
    "result = es.search(index=index_name, query=query_all, size=10)\n",
    "print(f\"ðŸ“Š Total de documents: {result['hits']['total']['value']}\")\n",
    "print(f\"   Documents retournÃ©s: {len(result['hits']['hits'])}\\n\")\n",
    "\n",
    "for hit in result['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    print(f\"ðŸ“„ Document {hit['_id']}:\")\n",
    "    print(f\"   Type: {source.get('event_type', 'N/A')}\")\n",
    "    if 'alert' in source:\n",
    "        print(f\"   Alerte: {source['alert'].get('signature', 'N/A')}\")\n",
    "    print(f\"   Source IP: {source.get('src_ip', 'N/A')} â†’ Dest IP: {source.get('dest_ip', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Recherche d'alertes spÃ©cifiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.228788Z",
     "iopub.status.busy": "2026-01-17T14:32:41.228474Z",
     "iopub.status.idle": "2026-01-17T14:32:41.259295Z",
     "shell.execute_reply": "2026-01-17T14:32:41.257804Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¨ Nombre d'alertes trouvÃ©es: 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Rechercher toutes les alertes (event_type = \"alert\")\n",
    "query_alerts = {\n",
    "    \"bool\": {\n",
    "        \"must\": [\n",
    "            {\"term\": {\"event_type\": \"alert\"}}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "result = es.search(index=index_name, query=query_alerts, size=100)\n",
    "print(f\"ðŸš¨ Nombre d'alertes trouvÃ©es: {result['hits']['total']['value']}\\n\")\n",
    "\n",
    "for hit in result['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    alert = source.get('alert', {})\n",
    "    print(f\"âš ï¸  Alerte ID: {alert.get('signature_id', 'N/A')}\")\n",
    "    print(f\"   Signature: {alert.get('signature', 'N/A')}\")\n",
    "    print(f\"   CatÃ©gorie: {alert.get('category', 'N/A')}\")\n",
    "    print(f\"   SÃ©vÃ©ritÃ©: {alert.get('severity', 'N/A')}\")\n",
    "    print(f\"   Source: {source.get('src_ip', 'N/A')}:{source.get('src_port', 'N/A')}\")\n",
    "    print(f\"   Destination: {source.get('dest_ip', 'N/A')}:{source.get('dest_port', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Recherche d'alertes de haute sÃ©vÃ©ritÃ©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.262269Z",
     "iopub.status.busy": "2026-01-17T14:32:41.261987Z",
     "iopub.status.idle": "2026-01-17T14:32:41.292386Z",
     "shell.execute_reply": "2026-01-17T14:32:41.291020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”´ Alertes de haute sÃ©vÃ©ritÃ© (â‰¤1): 0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Rechercher les alertes de haute sÃ©vÃ©ritÃ© (severity <= 1)\n",
    "query_high_severity = {\n",
    "    \"bool\": {\n",
    "        \"must\": [\n",
    "            {\"term\": {\"event_type\": \"alert\"}},\n",
    "            {\"range\": {\"alert.severity\": {\"lte\": 1}}}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "result = es.search(index=index_name, query=query_high_severity, size=100)\n",
    "print(f\"ðŸ”´ Alertes de haute sÃ©vÃ©ritÃ© (â‰¤1): {result['hits']['total']['value']}\\n\")\n",
    "\n",
    "for hit in result['hits']['hits']:\n",
    "    source = hit['_source']\n",
    "    alert = source.get('alert', {})\n",
    "    print(f\"ðŸ”´ CRITIQUE - SÃ©vÃ©ritÃ© {alert.get('severity', 'N/A')}\")\n",
    "    print(f\"   {alert.get('signature', 'N/A')}\")\n",
    "    print(f\"   Source IP suspecte: {source.get('src_ip', 'N/A')}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 AgrÃ©gations : Statistiques sur les alertes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.295378Z",
     "iopub.status.busy": "2026-01-17T14:32:41.294896Z",
     "iopub.status.idle": "2026-01-17T14:32:41.426228Z",
     "shell.execute_reply": "2026-01-17T14:32:41.424749Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Statistiques sur les alertes\n",
      "\n",
      "==================================================\n",
      "\n",
      "ðŸ“ Alertes par catÃ©gorie:\n",
      "\n",
      "âš ï¸  Alertes par sÃ©vÃ©ritÃ©:\n",
      "\n",
      "ðŸŒ Top 10 IPs sources:\n",
      "   192.168.65.1: 80907 Ã©vÃ©nements\n",
      "   192.168.65.7: 40147 Ã©vÃ©nements\n",
      "   192.168.65.3: 427 Ã©vÃ©nements\n",
      "\n",
      "ðŸ” Top 10 signatures:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mp/code/formations/elasticsearch_cookbook/.venv/lib/python3.14/site-packages/urllib3/connectionpool.py:1097: InsecureRequestWarning: Unverified HTTPS request is being made to host 'localhost'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# AgrÃ©gations pour analyser les donnÃ©es\n",
    "aggs_query = {\n",
    "    \"size\": 0,\n",
    "    \"aggs\": {\n",
    "        \"alertes_par_categorie\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"alert.category\",\n",
    "                \"size\": 10\n",
    "            }\n",
    "        },\n",
    "        \"alertes_par_severite\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"alert.severity\",\n",
    "                \"size\": 5\n",
    "            }\n",
    "        },\n",
    "        \"top_source_ips\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"src_ip\",\n",
    "                \"size\": 10\n",
    "            }\n",
    "        },\n",
    "        \"top_dest_ips\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"dest_ip\",\n",
    "                \"size\": 10\n",
    "            }\n",
    "        },\n",
    "        \"top_signatures\": {\n",
    "            \"terms\": {\n",
    "                \"field\": \"alert.signature.keyword\",\n",
    "                \"size\": 10\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "result = es.search(index=index_name, body=aggs_query)\n",
    "\n",
    "print(\"ðŸ“Š Statistiques sur les alertes\\n\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Alertes par catÃ©gorie\n",
    "if 'alertes_par_categorie' in result['aggregations']:\n",
    "    print(\"\\nðŸ“ Alertes par catÃ©gorie:\")\n",
    "    for bucket in result['aggregations']['alertes_par_categorie']['buckets']:\n",
    "        print(f\"   {bucket['key']}: {bucket['doc_count']}\")\n",
    "\n",
    "# Alertes par sÃ©vÃ©ritÃ©\n",
    "if 'alertes_par_severite' in result['aggregations']:\n",
    "    print(\"\\nâš ï¸  Alertes par sÃ©vÃ©ritÃ©:\")\n",
    "    for bucket in result['aggregations']['alertes_par_severite']['buckets']:\n",
    "        print(f\"   SÃ©vÃ©ritÃ© {bucket['key']}: {bucket['doc_count']}\")\n",
    "\n",
    "# Top IPs sources\n",
    "if 'top_source_ips' in result['aggregations']:\n",
    "    print(\"\\nðŸŒ Top 10 IPs sources:\")\n",
    "    for bucket in result['aggregations']['top_source_ips']['buckets']:\n",
    "        print(f\"   {bucket['key']}: {bucket['doc_count']} Ã©vÃ©nements\")\n",
    "\n",
    "# Top signatures\n",
    "if 'top_signatures' in result['aggregations']:\n",
    "    print(\"\\nðŸ” Top 10 signatures:\")\n",
    "    for bucket in result['aggregations']['top_signatures']['buckets']:\n",
    "        print(f\"   {bucket['key']}: {bucket['doc_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 4 : Visualisation dans Kibana\n",
    "\n",
    "### 4.1 AccÃ¨s Ã  Kibana\n",
    "\n",
    "1. Ouvrez votre navigateur et allez sur `http://localhost:5601`\n",
    "2. Connectez-vous avec les identifiants dÃ©finis dans votre fichier `.env` (si sÃ©curitÃ© activÃ©e)\n",
    "3. Si c'est la premiÃ¨re fois, vous devrez peut-Ãªtre accepter les termes de licence\n",
    "\n",
    "### 4.2 CrÃ©ation d'un index pattern\n",
    "\n",
    "Pour visualiser les donnÃ©es dans Kibana, vous devez crÃ©er un **index pattern** :\n",
    "\n",
    "1. Allez dans **Management** â†’ **Stack Management** â†’ **Index Patterns**\n",
    "2. Cliquez sur **Create index pattern**\n",
    "3. Entrez le pattern : `suricata-*` ou `.ds-suricata-*` (selon la version de Filebeat)\n",
    "   - Filebeat 9.x crÃ©e des **data streams** avec le pattern `.ds-suricata-*`\n",
    "   - Les versions antÃ©rieures crÃ©ent des index normaux avec `suricata-*`\n",
    "4. SÃ©lectionnez le champ de temps : `@timestamp` (ajoutÃ© par Filebeat)\n",
    "5. Cliquez sur **Create index pattern**\n",
    "\n",
    "**Note :** \n",
    "- Filebeat 9.x utilise des data streams (recommandÃ© par Elastic)\n",
    "- Les data streams sont automatiquement gÃ©rÃ©s et optimisÃ©s par Elasticsearch\n",
    "- Utilisez `suricata-*` ou `.ds-suricata-*` selon ce que Filebeat a crÃ©Ã©\n",
    "\n",
    "### 4.3 CrÃ©ation de visualisations\n",
    "\n",
    "Dans Kibana, crÃ©ez les visualisations suivantes :\n",
    "\n",
    "#### Visualisation 1 : Timeline des alertes\n",
    "- **Type** : Line chart ou Area chart\n",
    "- **MÃ©trique** : Count\n",
    "- **Buckets** : Date Histogram sur `@timestamp`\n",
    "- **Filtre** : `event_type: alert`\n",
    "\n",
    "#### Visualisation 2 : Top 10 signatures d'alertes\n",
    "- **Type** : Horizontal Bar chart\n",
    "- **MÃ©trique** : Count\n",
    "- **Buckets** : Terms sur `alert.signature.keyword` (Top 10)\n",
    "\n",
    "#### Visualisation 3 : RÃ©partition par sÃ©vÃ©ritÃ©\n",
    "- **Type** : Pie chart\n",
    "- **MÃ©trique** : Count\n",
    "- **Buckets** : Terms sur `alert.severity`\n",
    "\n",
    "#### Visualisation 4 : Carte des IPs sources\n",
    "- **Type** : Coordinate Map ou Tile Map\n",
    "- **MÃ©trique** : Count\n",
    "- **Buckets** : Geohash sur `src_ip` (si gÃ©olocalisation activÃ©e)\n",
    "\n",
    "### 4.4 CrÃ©ation d'un Dashboard\n",
    "\n",
    "1. Allez dans **Dashboard** â†’ **Create dashboard**\n",
    "2. Ajoutez les visualisations crÃ©Ã©es prÃ©cÃ©demment\n",
    "3. Configurez les filtres temporels\n",
    "4. Sauvegardez le dashboard\n",
    "\n",
    "**Note :** Pour ce TD, nous allons Ã©galement crÃ©er des visualisations programmatiquement via l'API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.429291Z",
     "iopub.status.busy": "2026-01-17T14:32:41.429031Z",
     "iopub.status.idle": "2026-01-17T14:32:41.458835Z",
     "shell.execute_reply": "2026-01-17T14:32:41.457388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Kibana est accessible\n",
      "   Version: N/A\n"
     ]
    }
   ],
   "source": [
    "# VÃ©rification de l'accÃ¨s Ã  Kibana (via l'API REST)\n",
    "import requests\n",
    "import urllib3\n",
    "\n",
    "# DÃ©sactiver les avertissements SSL pour le dÃ©veloppement\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "KIBANA_URL = \"http://localhost:5601\"\n",
    "KIBANA_USER = \"elastic\"  # Modifiez si nÃ©cessaire\n",
    "KIBANA_PASSWORD = None  # DÃ©finissez votre mot de passe si sÃ©curitÃ© activÃ©e\n",
    "\n",
    "# Test de connexion Ã  Kibana\n",
    "try:\n",
    "    if KIBANA_PASSWORD:\n",
    "        response = requests.get(\n",
    "            f\"{KIBANA_URL}/api/status\",\n",
    "            auth=(KIBANA_USER, KIBANA_PASSWORD),\n",
    "            verify=False,\n",
    "            timeout=5\n",
    "        )\n",
    "    else:\n",
    "        response = requests.get(f\"{KIBANA_URL}/api/status\", timeout=5)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"âœ… Kibana est accessible\")\n",
    "        status = response.json()\n",
    "        print(f\"   Version: {status.get('version', {}).get('number', 'N/A')}\")\n",
    "    else:\n",
    "        print(f\"âš ï¸  Kibana rÃ©pond mais avec le code: {response.status_code}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(\"âŒ Impossible de se connecter Ã  Kibana\")\n",
    "    print(\"   VÃ©rifiez que Kibana est dÃ©marrÃ© sur http://localhost:5601\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Erreur: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 5 : Alerting dans Kibana\n",
    "\n",
    "### 5.1 CrÃ©ation de rÃ¨gles d'alerte\n",
    "\n",
    "Kibana permet de crÃ©er des rÃ¨gles d'alerte basÃ©es sur des requÃªtes Elasticsearch. Voici quelques exemples de rÃ¨gles utiles pour un SIEM :\n",
    "\n",
    "#### RÃ¨gle 1 : Alerte sur haute sÃ©vÃ©ritÃ©\n",
    "- **Condition** : Nombre d'alertes avec `severity <= 1` > 0\n",
    "- **Action** : Envoyer une notification (email, Slack, etc.)\n",
    "\n",
    "#### RÃ¨gle 2 : Alerte sur scan de ports\n",
    "- **Condition** : Plus de 10 alertes de type \"SCAN\" en 5 minutes\n",
    "- **Action** : Notification immÃ©diate\n",
    "\n",
    "#### RÃ¨gle 3 : Alerte sur IP suspecte\n",
    "- **Condition** : Plus de 5 alertes depuis la mÃªme IP source en 10 minutes\n",
    "- **Action** : Bloquer l'IP (si intÃ©gration avec firewall)\n",
    "\n",
    "### 5.2 Configuration des alertes via l'API\n",
    "\n",
    "Pour crÃ©er des alertes programmatiquement, utilisez l'API Kibana Alerting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.461563Z",
     "iopub.status.busy": "2026-01-17T14:32:41.461236Z",
     "iopub.status.idle": "2026-01-17T14:32:41.468439Z",
     "shell.execute_reply": "2026-01-17T14:32:41.467045Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‹ Exemple de rÃ¨gle d'alerte crÃ©Ã©e:\n",
      "{\n",
      "  \"name\": \"Alerte haute s\\u00e9v\\u00e9rit\\u00e9 Suricata\",\n",
      "  \"consumer\": \"alerts\",\n",
      "  \"enabled\": true,\n",
      "  \"rule_type_id\": \".es-query\",\n",
      "  \"schedule\": {\n",
      "    \"interval\": \"1m\"\n",
      "  },\n",
      "  \"actions\": [\n",
      "    {\n",
      "      \"group\": \"query matched\",\n",
      "      \"id\": \"my-connector-id\",\n",
      "      \"params\": {\n",
      "        \"message\": \"Alerte: Alerte haute s\\u00e9v\\u00e9rit\\u00e9 Suricata - Seuil d\\u00e9pass\\u00e9!\"\n",
      "      }\n",
      "    }\n",
      "  ],\n",
      "  \"params\": {\n",
      "    \"index\": [\n",
      "      \"suricata-*\"\n",
      "    ],\n",
      "    \"query\": {\n",
      "      \"bool\": {\n",
      "        \"must\": [\n",
      "          {\n",
      "            \"term\": {\n",
      "              \"event_type\": \"alert\"\n",
      "            }\n",
      "          },\n",
      "          {\n",
      "            \"range\": {\n",
      "              \"alert.severity\": {\n",
      "                \"lte\": 1\n",
      "              }\n",
      "            }\n",
      "          }\n",
      "        ]\n",
      "      }\n",
      "    },\n",
      "    \"size\": 100,\n",
      "    \"timeField\": \"@timestamp\",\n",
      "    \"timeWindowSize\": \"5m\",\n",
      "    \"threshold\": [\n",
      "      {\n",
      "        \"field\": \"count\",\n",
      "        \"value\": 0,\n",
      "        \"comparator\": \">\"\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\n",
      "ðŸ’¡ Pour crÃ©er cette rÃ¨gle dans Kibana:\n",
      "   1. Allez dans Stack Management â†’ Rules and Connectors\n",
      "   2. CrÃ©ez un connecteur (email, Slack, etc.)\n",
      "   3. CrÃ©ez une nouvelle rÃ¨gle avec les paramÃ¨tres ci-dessus\n"
     ]
    }
   ],
   "source": [
    "# Exemple de crÃ©ation d'une rÃ¨gle d'alerte Kibana\n",
    "# Note: Cette fonctionnalitÃ© nÃ©cessite Kibana avec les fonctionnalitÃ©s d'alerting activÃ©es\n",
    "\n",
    "def create_alert_rule(rule_name, query, threshold, time_window=\"5m\"):\n",
    "    \"\"\"\n",
    "    CrÃ©e une rÃ¨gle d'alerte Kibana\n",
    "    \n",
    "    Args:\n",
    "        rule_name: Nom de la rÃ¨gle\n",
    "        query: RequÃªte Elasticsearch (dict)\n",
    "        threshold: Seuil d'alerte\n",
    "        time_window: FenÃªtre temporelle (ex: \"5m\", \"1h\")\n",
    "    \"\"\"\n",
    "    alert_rule = {\n",
    "        \"name\": rule_name,\n",
    "        \"consumer\": \"alerts\",\n",
    "        \"enabled\": True,\n",
    "        \"rule_type_id\": \".es-query\",\n",
    "        \"schedule\": {\n",
    "            \"interval\": \"1m\"\n",
    "        },\n",
    "        \"actions\": [\n",
    "            {\n",
    "                \"group\": \"query matched\",\n",
    "                \"id\": \"my-connector-id\",  # Ã€ remplacer par un ID de connecteur rÃ©el\n",
    "                \"params\": {\n",
    "                    \"message\": f\"Alerte: {rule_name} - Seuil dÃ©passÃ©!\"\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"params\": {\n",
    "            \"index\": [\"suricata-*\"],\n",
    "            \"query\": query,\n",
    "            \"size\": 100,\n",
    "            \"timeField\": \"@timestamp\",\n",
    "            \"timeWindowSize\": time_window,\n",
    "            \"threshold\": [\n",
    "                {\n",
    "                    \"field\": \"count\",\n",
    "                    \"value\": threshold,\n",
    "                    \"comparator\": \">\"\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return alert_rule\n",
    "\n",
    "# Exemple: RÃ¨gle d'alerte pour haute sÃ©vÃ©ritÃ©\n",
    "high_severity_query = {\n",
    "    \"bool\": {\n",
    "        \"must\": [\n",
    "            {\"term\": {\"event_type\": \"alert\"}},\n",
    "            {\"range\": {\"alert.severity\": {\"lte\": 1}}}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "alert_rule = create_alert_rule(\n",
    "    rule_name=\"Alerte haute sÃ©vÃ©ritÃ© Suricata\",\n",
    "    query=high_severity_query,\n",
    "    threshold=0,\n",
    "    time_window=\"5m\"\n",
    ")\n",
    "\n",
    "print(\"ðŸ“‹ Exemple de rÃ¨gle d'alerte crÃ©Ã©e:\")\n",
    "print(json.dumps(alert_rule, indent=2))\n",
    "\n",
    "print(\"\\nðŸ’¡ Pour crÃ©er cette rÃ¨gle dans Kibana:\")\n",
    "print(\"   1. Allez dans Stack Management â†’ Rules and Connectors\")\n",
    "print(\"   2. CrÃ©ez un connecteur (email, Slack, etc.)\")\n",
    "print(\"   3. CrÃ©ez une nouvelle rÃ¨gle avec les paramÃ¨tres ci-dessus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.471568Z",
     "iopub.status.busy": "2026-01-17T14:32:41.471319Z",
     "iopub.status.idle": "2026-01-17T14:32:41.558657Z",
     "shell.execute_reply": "2026-01-17T14:32:41.557436Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ðŸ” IPs sources suspectes (â‰¥1 alertes):\n",
      "\n",
      "\n",
      "============================================================\n",
      "ðŸ• Alertes des derniÃ¨res 60 minutes: 0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObjectApiResponse({'took': 9, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 0, 'relation': 'eq'}, 'max_score': None, 'hits': []}})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DÃ©tection de patterns suspects\n",
    "\n",
    "# 1. DÃ©tection d'IP source avec beaucoup d'alertes (possible scan/attaque)\n",
    "def detect_suspicious_source_ips(min_alerts=3):\n",
    "    \"\"\"DÃ©tecte les IPs sources avec un nombre Ã©levÃ© d'alertes\"\"\"\n",
    "    query = {\n",
    "        \"size\": 0,\n",
    "        \"query\": {\n",
    "            \"term\": {\"event_type\": \"alert\"}\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"suspicious_ips\": {\n",
    "                \"terms\": {\n",
    "                    \"field\": \"src_ip\",\n",
    "                    \"size\": 20,\n",
    "                    \"min_doc_count\": min_alerts\n",
    "                },\n",
    "                \"aggs\": {\n",
    "                    \"alert_details\": {\n",
    "                        \"top_hits\": {\n",
    "                            \"size\": 5,\n",
    "                            \"_source\": {\n",
    "                                \"includes\": [\"alert.signature\", \"alert.severity\", \"dest_ip\", \"dest_port\"]\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result = es.search(index=index_name, body=query)\n",
    "    \n",
    "    print(f\"ðŸ” IPs sources suspectes (â‰¥{min_alerts} alertes):\\n\")\n",
    "    for bucket in result['aggregations']['suspicious_ips']['buckets']:\n",
    "        ip = bucket['key']\n",
    "        count = bucket['doc_count']\n",
    "        print(f\"âš ï¸  {ip}: {count} alertes\")\n",
    "        \n",
    "        # Afficher les dÃ©tails des alertes\n",
    "        for hit in bucket['alert_details']['hits']['hits']:\n",
    "            source = hit['_source']\n",
    "            alert = source.get('alert', {})\n",
    "            print(f\"   - {alert.get('signature', 'N/A')} (SÃ©vÃ©ritÃ©: {alert.get('severity', 'N/A')})\")\n",
    "        print()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# 2. DÃ©tection d'alertes rÃ©centes (derniÃ¨res 30 minutes)\n",
    "def detect_recent_alerts(minutes=30):\n",
    "    \"\"\"DÃ©tecte les alertes rÃ©centes\"\"\"\n",
    "    time_threshold = datetime.now() - timedelta(minutes=minutes)\n",
    "    \n",
    "    query = {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\"term\": {\"event_type\": \"alert\"}}\n",
    "            ],\n",
    "            \"filter\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": time_threshold.isoformat()\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result = es.search(index=index_name, query=query, size=100, sort=[{\"@timestamp\": {\"order\": \"desc\"}}])\n",
    "    \n",
    "    print(f\"ðŸ• Alertes des derniÃ¨res {minutes} minutes: {result['hits']['total']['value']}\\n\")\n",
    "    \n",
    "    for hit in result['hits']['hits']:\n",
    "        source = hit['_source']\n",
    "        alert = source.get('alert', {})\n",
    "        timestamp = source.get('@timestamp', source.get('timestamp', 'N/A'))\n",
    "        print(f\"â° {timestamp}\")\n",
    "        print(f\"   {alert.get('signature', 'N/A')}\")\n",
    "        print(f\"   {source.get('src_ip', 'N/A')} â†’ {source.get('dest_ip', 'N/A')}\")\n",
    "        print()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ExÃ©cuter les dÃ©tections\n",
    "print(\"=\" * 60)\n",
    "detect_suspicious_source_ips(min_alerts=1)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "detect_recent_alerts(minutes=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.561411Z",
     "iopub.status.busy": "2026-01-17T14:32:41.561146Z",
     "iopub.status.idle": "2026-01-17T14:32:41.641979Z",
     "shell.execute_reply": "2026-01-17T14:32:41.640384Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“ˆ Analyse des patterns temporels\n",
      "\n",
      "ðŸ• Distribution des alertes par heure:\n",
      "\n",
      "ðŸ“Š Total d'alertes analysÃ©es: 0\n"
     ]
    }
   ],
   "source": [
    "# Exemple de requÃªte pour analyser les patterns temporels (utile pour ML)\n",
    "# Cette requÃªte peut Ãªtre utilisÃ©e comme base pour un job ML\n",
    "\n",
    "def analyze_temporal_patterns():\n",
    "    \"\"\"Analyse les patterns temporels dans les alertes\"\"\"\n",
    "    \n",
    "    # AgrÃ©gation par heure de la journÃ©e\n",
    "    query = {\n",
    "        \"size\": 0,\n",
    "        \"query\": {\n",
    "            \"term\": {\"event_type\": \"alert\"}\n",
    "        },\n",
    "        \"aggs\": {\n",
    "            \"alerts_by_hour\": {\n",
    "                \"date_histogram\": {\n",
    "                    \"field\": \"@timestamp\",\n",
    "                    \"calendar_interval\": \"hour\",\n",
    "                    \"min_doc_count\": 1\n",
    "                },\n",
    "                \"aggs\": {\n",
    "                    \"by_severity\": {\n",
    "                        \"terms\": {\n",
    "                            \"field\": \"alert.severity\",\n",
    "                            \"size\": 5\n",
    "                        }\n",
    "                    },\n",
    "                    \"unique_ips\": {\n",
    "                        \"cardinality\": {\n",
    "                            \"field\": \"src_ip\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"alerts_by_day\": {\n",
    "                \"date_histogram\": {\n",
    "                    \"field\": \"@timestamp\",\n",
    "                    \"calendar_interval\": \"day\",\n",
    "                    \"min_doc_count\": 1\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result = es.search(index=index_name, body=query)\n",
    "    \n",
    "    print(\"ðŸ“ˆ Analyse des patterns temporels\\n\")\n",
    "    \n",
    "    # Afficher les alertes par heure\n",
    "    if 'alerts_by_hour' in result['aggregations']:\n",
    "        print(\"ðŸ• Distribution des alertes par heure:\")\n",
    "        for bucket in result['aggregations']['alerts_by_hour']['buckets']:\n",
    "            time_str = bucket['key_as_string']\n",
    "            count = bucket['doc_count']\n",
    "            unique_ips = bucket['unique_ips']['value']\n",
    "            print(f\"   {time_str}: {count} alertes ({unique_ips} IPs uniques)\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š Total d'alertes analysÃ©es: {result['hits']['total']['value']}\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ExÃ©cuter l'analyse\n",
    "try:\n",
    "    analyze_temporal_patterns()\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Erreur lors de l'analyse: {e}\")\n",
    "    print(\"   Assurez-vous que les donnÃ©es contiennent des timestamps valides\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 DÃ©tection d'anomalies basique (sans ML)\n",
    "\n",
    "MÃªme sans activer ML, nous pouvons crÃ©er des rÃ¨gles de dÃ©tection d'anomalies basiques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.644882Z",
     "iopub.status.busy": "2026-01-17T14:32:41.644538Z",
     "iopub.status.idle": "2026-01-17T14:32:41.686137Z",
     "shell.execute_reply": "2026-01-17T14:32:41.684750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” DÃ©tection d'anomalies basiques\n",
      "\n",
      "============================================================\n",
      "âœ… Aucune anomalie majeure dÃ©tectÃ©e avec les critÃ¨res actuels\n"
     ]
    }
   ],
   "source": [
    "# DÃ©tection d'anomalies basique : identifier les comportements inhabituels\n",
    "\n",
    "def detect_anomalies():\n",
    "    \"\"\"DÃ©tecte des anomalies basiques dans les logs\"\"\"\n",
    "    \n",
    "    anomalies = []\n",
    "    \n",
    "    # 1. IP source avec trop d'alertes diffÃ©rentes (possible botnet/scan)\n",
    "    query1 = {\n",
    "        \"size\": 0,\n",
    "        \"query\": {\"term\": {\"event_type\": \"alert\"}},\n",
    "        \"aggs\": {\n",
    "            \"ips_with_many_alerts\": {\n",
    "                \"terms\": {\n",
    "                    \"field\": \"src_ip\",\n",
    "                    \"size\": 10\n",
    "                },\n",
    "                \"aggs\": {\n",
    "                    \"unique_signatures\": {\n",
    "                        \"cardinality\": {\n",
    "                            \"field\": \"alert.signature_id\"\n",
    "                        }\n",
    "                    },\n",
    "                    \"unique_dest_ips\": {\n",
    "                        \"cardinality\": {\n",
    "                            \"field\": \"dest_ip\"\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result1 = es.search(index=index_name, body=query1)\n",
    "    \n",
    "    print(\"ðŸ” DÃ©tection d'anomalies basiques\\n\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Analyser les rÃ©sultats\n",
    "    for bucket in result1['aggregations']['ips_with_many_alerts']['buckets']:\n",
    "        ip = bucket['key']\n",
    "        total_alerts = bucket['doc_count']\n",
    "        unique_signatures = bucket['unique_signatures']['value']\n",
    "        unique_dest_ips = bucket['unique_dest_ips']['value']\n",
    "        \n",
    "        # CritÃ¨res d'anomalie\n",
    "        if unique_signatures > 3 or unique_dest_ips > 5:\n",
    "            anomaly = {\n",
    "                \"type\": \"Suspicious scanning activity\",\n",
    "                \"ip\": ip,\n",
    "                \"total_alerts\": total_alerts,\n",
    "                \"unique_signatures\": unique_signatures,\n",
    "                \"unique_dest_ips\": unique_dest_ips\n",
    "            }\n",
    "            anomalies.append(anomaly)\n",
    "            \n",
    "            print(f\"ðŸš¨ ANOMALIE DÃ‰TECTÃ‰E:\")\n",
    "            print(f\"   IP: {ip}\")\n",
    "            print(f\"   Type: ActivitÃ© de scan suspecte\")\n",
    "            print(f\"   Raison: {unique_signatures} signatures diffÃ©rentes, {unique_dest_ips} IPs de destination diffÃ©rentes\")\n",
    "            print(f\"   Total alertes: {total_alerts}\")\n",
    "            print()\n",
    "    \n",
    "    # 2. Alertes de haute sÃ©vÃ©ritÃ© rÃ©centes\n",
    "    query2 = {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\"term\": {\"event_type\": \"alert\"}},\n",
    "                {\"range\": {\"alert.severity\": {\"lte\": 1}}}\n",
    "            ],\n",
    "            \"filter\": [\n",
    "                {\n",
    "                    \"range\": {\n",
    "                        \"@timestamp\": {\n",
    "                            \"gte\": (datetime.now() - timedelta(hours=1)).isoformat()\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result2 = es.search(index=index_name, query=query2, size=100)\n",
    "    \n",
    "    if result2['hits']['total']['value'] > 0:\n",
    "        print(\"ðŸš¨ ALERTES CRITIQUES RÃ‰CENTES:\")\n",
    "        for hit in result2['hits']['hits']:\n",
    "            source = hit['_source']\n",
    "            alert = source.get('alert', {})\n",
    "            print(f\"   - {alert.get('signature', 'N/A')}\")\n",
    "            print(f\"     Source: {source.get('src_ip', 'N/A')}\")\n",
    "            print(f\"     SÃ©vÃ©ritÃ©: {alert.get('severity', 'N/A')}\")\n",
    "        print()\n",
    "    \n",
    "    return anomalies\n",
    "\n",
    "# ExÃ©cuter la dÃ©tection\n",
    "anomalies = detect_anomalies()\n",
    "\n",
    "if not anomalies:\n",
    "    print(\"âœ… Aucune anomalie majeure dÃ©tectÃ©e avec les critÃ¨res actuels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 7 : Exercices pratiques\n",
    "\n",
    "### Exercice 1 : Recherche d'IPs malveillantes\n",
    "\n",
    "CrÃ©ez une requÃªte pour trouver toutes les alertes provenant d'une IP spÃ©cifique et analysez les signatures dÃ©clenchÃ©es.\n",
    "\n",
    "### Exercice 2 : Analyse de trafic HTTP\n",
    "\n",
    "Recherchez tous les Ã©vÃ©nements HTTP et identifiez les requÃªtes suspectes (ex: tentatives d'accÃ¨s Ã  `/admin`, `/wp-admin`, etc.).\n",
    "\n",
    "### Exercice 3 : Dashboard personnalisÃ©\n",
    "\n",
    "CrÃ©ez un dashboard Kibana avec :\n",
    "- Timeline des alertes\n",
    "- Top 10 des signatures\n",
    "- Carte des IPs sources\n",
    "- Graphique de sÃ©vÃ©ritÃ©\n",
    "\n",
    "### Exercice 4 : RÃ¨gle d'alerte personnalisÃ©e\n",
    "\n",
    "CrÃ©ez une rÃ¨gle d'alerte qui se dÃ©clenche lorsqu'une IP gÃ©nÃ¨re plus de 5 alertes en 10 minutes.\n",
    "\n",
    "### Exercice 5 : DÃ©tection de patterns\n",
    "\n",
    "Ã‰crivez une requÃªte pour dÃ©tecter les scans de ports (plusieurs tentatives de connexion sur diffÃ©rents ports depuis la mÃªme IP)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.689363Z",
     "iopub.status.busy": "2026-01-17T14:32:41.689077Z",
     "iopub.status.idle": "2026-01-17T14:32:41.716162Z",
     "shell.execute_reply": "2026-01-17T14:32:41.714521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš ï¸  Aucune alerte trouvÃ©e pour le test\n"
     ]
    }
   ],
   "source": [
    "# EXERCICE 1 : Recherche d'IPs malveillantes\n",
    "# ComplÃ©tez cette fonction pour rechercher toutes les alertes d'une IP spÃ©cifique\n",
    "\n",
    "def search_alerts_by_ip(ip_address):\n",
    "    \"\"\"\n",
    "    Recherche toutes les alertes pour une IP source donnÃ©e\n",
    "    \n",
    "    Args:\n",
    "        ip_address: Adresse IP Ã  rechercher (ex: \"192.168.1.100\")\n",
    "    \n",
    "    Returns:\n",
    "        RÃ©sultats de la recherche\n",
    "    \"\"\"\n",
    "    # TODO: CrÃ©er la requÃªte Elasticsearch\n",
    "    query = {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\"term\": {\"event_type\": \"alert\"}},\n",
    "                {\"term\": {\"src_ip\": ip_address}}\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result = es.search(index=index_name, query=query, size=100)\n",
    "    \n",
    "    print(f\"ðŸ” Alertes pour l'IP {ip_address}: {result['hits']['total']['value']}\\n\")\n",
    "    \n",
    "    signatures = {}\n",
    "    for hit in result['hits']['hits']:\n",
    "        source = hit['_source']\n",
    "        alert = source.get('alert', {})\n",
    "        sig_id = alert.get('signature_id', 'N/A')\n",
    "        sig_name = alert.get('signature', 'N/A')\n",
    "        \n",
    "        if sig_id not in signatures:\n",
    "            signatures[sig_id] = {\n",
    "                \"name\": sig_name,\n",
    "                \"count\": 0,\n",
    "                \"severity\": alert.get('severity', 'N/A')\n",
    "            }\n",
    "        signatures[sig_id][\"count\"] += 1\n",
    "    \n",
    "    print(\"ðŸ“‹ Signatures dÃ©clenchÃ©es:\")\n",
    "    for sig_id, info in signatures.items():\n",
    "        print(f\"   [{sig_id}] {info['name']}: {info['count']} fois (SÃ©vÃ©ritÃ©: {info['severity']})\")\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Test avec une IP de test\n",
    "# RÃ©cupÃ©rer d'abord quelques alertes pour obtenir une IP de test\n",
    "test_query = {\n",
    "    \"bool\": {\n",
    "        \"must\": [\n",
    "            {\"term\": {\"event_type\": \"alert\"}}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "test_result = es.search(index=index_name, query=test_query, size=1)\n",
    "\n",
    "if test_result['hits']['total']['value'] > 0:\n",
    "    test_ip = test_result['hits']['hits'][0]['_source'].get('src_ip')\n",
    "    if test_ip:\n",
    "        print(f\"\\nðŸ§ª Test avec l'IP: {test_ip}\\n\")\n",
    "        search_alerts_by_ip(test_ip)\n",
    "    else:\n",
    "        print(\"âš ï¸  Aucune IP source trouvÃ©e dans les alertes\")\n",
    "else:\n",
    "    print(\"âš ï¸  Aucune alerte trouvÃ©e pour le test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.719112Z",
     "iopub.status.busy": "2026-01-17T14:32:41.718858Z",
     "iopub.status.idle": "2026-01-17T14:32:41.749304Z",
     "shell.execute_reply": "2026-01-17T14:32:41.747809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš¨ RequÃªtes HTTP suspectes trouvÃ©es: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# EXERCICE 2 : Analyse de trafic HTTP suspect\n",
    "# Recherchez les requÃªtes HTTP suspectes\n",
    "\n",
    "def find_suspicious_http_requests():\n",
    "    \"\"\"Recherche les requÃªtes HTTP suspectes\"\"\"\n",
    "    \n",
    "    # URLs suspectes communes\n",
    "    suspicious_paths = [\"/admin\", \"/wp-admin\", \"/phpmyadmin\", \"/.env\", \"/config.php\"]\n",
    "    \n",
    "    query = {\n",
    "        \"bool\": {\n",
    "            \"must\": [\n",
    "                {\"term\": {\"event_type\": \"http\"}}\n",
    "            ],\n",
    "            \"should\": [\n",
    "                {\"wildcard\": {\"http.url\": f\"*{path}*\"}} for path in suspicious_paths\n",
    "            ],\n",
    "            \"minimum_should_match\": 1\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    result = es.search(index=index_name, query=query, size=100)\n",
    "    \n",
    "    print(f\"ðŸš¨ RequÃªtes HTTP suspectes trouvÃ©es: {result['hits']['total']['value']}\\n\")\n",
    "    \n",
    "    for hit in result['hits']['hits']:\n",
    "        source = hit['_source']\n",
    "        http = source.get('http', {})\n",
    "        print(f\"âš ï¸  {source.get('src_ip', 'N/A')} â†’ {http.get('hostname', 'N/A')}{http.get('url', 'N/A')}\")\n",
    "        print(f\"   MÃ©thode: {http.get('http_method', 'N/A')}, Status: {http.get('status', 'N/A')}\")\n",
    "        print()\n",
    "    \n",
    "    return result\n",
    "\n",
    "# ExÃ©cuter la recherche\n",
    "try:\n",
    "    find_suspicious_http_requests()\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸  Erreur: {e}\")\n",
    "    print(\"   VÃ©rifiez que vous avez des Ã©vÃ©nements HTTP dans vos logs\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 8 : RÃ©sumÃ© et bonnes pratiques\n",
    "\n",
    "### Bonnes pratiques pour un SIEM\n",
    "\n",
    "1. **Indexation optimale**\n",
    "   - Utilisez des index avec rotation temporelle (ex: `suricata-YYYY.MM.DD`)\n",
    "   - Configurez des index templates pour automatiser la crÃ©ation\n",
    "   - DÃ©finissez des politiques de rÃ©tention (ILM - Index Lifecycle Management)\n",
    "\n",
    "2. **Mapping des champs**\n",
    "   - DÃ©finissez correctement les types de champs (IP, date, keyword, text)\n",
    "   - Utilisez des champs `keyword` pour les agrÃ©gations\n",
    "   - Utilisez des champs `text` pour la recherche full-text\n",
    "\n",
    "3. **SÃ©curitÃ©**\n",
    "   - Activez la sÃ©curitÃ© Elasticsearch en production\n",
    "   - Utilisez des certificats SSL/TLS\n",
    "   - Configurez des rÃ´les et permissions appropriÃ©s\n",
    "\n",
    "4. **Performance**\n",
    "   - Monitorer la santÃ© du cluster\n",
    "   - Ajuster le nombre de shards selon le volume de donnÃ©es\n",
    "   - Utiliser des alias pour les index\n",
    "\n",
    "5. **Alerting**\n",
    "   - CrÃ©ez des rÃ¨gles d'alerte pertinentes (pas trop, pas trop peu)\n",
    "   - Testez rÃ©guliÃ¨rement les alertes\n",
    "   - Documentez les procÃ©dures de rÃ©ponse aux incidents\n",
    "\n",
    "6. **Maintenance**\n",
    "   - Surveillez les logs Elasticsearch et Kibana\n",
    "   - Effectuez des sauvegardes rÃ©guliÃ¨res\n",
    "   - Mettez Ã  jour rÃ©guliÃ¨rement les rÃ¨gles Suricata\n",
    "\n",
    "### Ressources supplÃ©mentaires\n",
    "\n",
    "- **Documentation Suricata** : https://suricata.readthedocs.io/\n",
    "- **Documentation Filebeat** : https://www.elastic.co/guide/en/beats/filebeat/current/index.html\n",
    "- **Documentation Elasticsearch** : https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html\n",
    "- **Documentation Kibana** : https://www.elastic.co/guide/en/kibana/current/index.html\n",
    "- **Elastic Security** : https://www.elastic.co/security\n",
    "\n",
    "### Prochaines Ã©tapes\n",
    "\n",
    "1. IntÃ©grer d'autres sources de logs (Apache, Nginx, Windows Event Logs, etc.)\n",
    "2. Configurer des enrichissements (gÃ©olocalisation IP, threat intelligence)\n",
    "3. CrÃ©er des playbooks de rÃ©ponse aux incidents\n",
    "4. Mettre en place une stack complÃ¨te avec Logstash si nÃ©cessaire\n",
    "5. Explorer Elastic Security (anciennement SIEM) pour des fonctionnalitÃ©s avancÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-17T14:32:41.752219Z",
     "iopub.status.busy": "2026-01-17T14:32:41.751975Z",
     "iopub.status.idle": "2026-01-17T14:32:41.758080Z",
     "shell.execute_reply": "2026-01-17T14:32:41.756502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "âœ… TD terminÃ©!\n",
      "============================================================\n",
      "\n",
      "ðŸ“š N'oubliez pas de:\n",
      "   1. Explorer Kibana pour crÃ©er vos visualisations\n",
      "   2. Configurer des alertes dans Kibana\n",
      "   3. Tester avec de vrais logs Suricata\n",
      "   4. Documenter vos rÃ¨gles et procÃ©dures\n",
      "\n",
      "ðŸŽ“ Bonne continuation avec votre SIEM!\n"
     ]
    }
   ],
   "source": [
    "# Fonction utilitaire : Nettoyage des ressources\n",
    "def cleanup():\n",
    "    \"\"\"Supprime l'index de test (optionnel)\"\"\"\n",
    "    response = input(\"Voulez-vous supprimer l'index 'suricata-logs'? (oui/non): \")\n",
    "    if response.lower() in ['oui', 'o', 'yes', 'y']:\n",
    "        if es.indices.exists(index=index_name):\n",
    "            es.indices.delete(index=index_name)\n",
    "            print(f\"âœ… Index '{index_name}' supprimÃ©\")\n",
    "        else:\n",
    "            print(f\"â„¹ï¸  L'index '{index_name}' n'existe pas\")\n",
    "    else:\n",
    "        print(\"â„¹ï¸  Index conservÃ©\")\n",
    "\n",
    "# DÃ©commenter pour nettoyer\n",
    "# cleanup()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"âœ… TD terminÃ©!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nðŸ“š N'oubliez pas de:\")\n",
    "print(\"   1. Explorer Kibana pour crÃ©er vos visualisations\")\n",
    "print(\"   2. Configurer des alertes dans Kibana\")\n",
    "print(\"   3. Tester avec de vrais logs Suricata\")\n",
    "print(\"   4. Documenter vos rÃ¨gles et procÃ©dures\")\n",
    "print(\"\\nðŸŽ“ Bonne continuation avec votre SIEM!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
